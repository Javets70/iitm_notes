{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"IITM BS Resources","text":"<p>OOGA BOOGA</p>"},{"location":"#foundational-1","title":"Foundational 1","text":""},{"location":"#maths-1","title":"Maths 1","text":"<ul> <li>Week Wise Lecture Playlist</li> <li>Week 1 to Week 4 Notes</li> <li>Week 5 to Week 8 Notes</li> <li>Student Notes<ul> <li>Studify Notes</li> <li>kabironline IIT Notes</li> </ul> </li> <li>Recommended Books:</li> <li>IITM Mathematics for Data Science</li> </ul>"},{"location":"#statistics-1","title":"Statistics 1","text":"<ul> <li>Week Wise Lecture Playlist</li> <li>Student Notes<ul> <li>Studify Notes</li> <li>kabironline IIT Notes</li> </ul> </li> <li>Recommended Books:</li> <li>IITM Descriptive Statistics</li> </ul>"},{"location":"#computational-thinking-ct","title":"Computational Thinking (CT)","text":"<ul> <li>Week Wise Lecture Playlist</li> <li>Student Notes</li> </ul>"},{"location":"#english-1","title":"English 1","text":"<ul> <li>Week Wise Lecture Playlist</li> <li>Student Notes</li> </ul>"},{"location":"#foundational-2","title":"Foundational 2","text":""},{"location":"#maths-2","title":"Maths 2","text":"<ul> <li>Week Wise Lecture Playlist (Login with student ID)</li> <li>Student Notes</li> <li>Recommended Books<ul> <li>Linear Algebra IITM</li> <li>Mathematics For Machine Learning (MML)</li> <li>Vector Calculus</li> </ul> </li> </ul>"},{"location":"#statistics-2","title":"Statistics 2","text":"<ul> <li>Week Wise Lecture Playlist (Login with student ID)</li> <li>Student Notes</li> <li>Recommended Books<ul> <li>Probability and Statistics Using R</li> <li>Probability and Statistics for Engineers</li> </ul> </li> </ul>"},{"location":"#python","title":"Python","text":"<ul> <li>Week Wise Lecture Playlist (Login with student ID)</li> <li>Student Unofficial Lectures (All lectures are in hindi)</li> <li>Recommended Books<ul> <li>pypod github book</li> </ul> </li> </ul>"},{"location":"#english-2","title":"English 2","text":"<ul> <li>Week Wise Lecture Playlist (Login with student ID)</li> </ul>"},{"location":"#other-resources","title":"Other Resources","text":"<ul> <li>Main Website: https://study.iitm.ac.in/ds/</li> <li>Useful links for Students:</li> <li>Measuring Conceptual Clarity and Understanding: Click here<ul> <li>It addresses important issues regarding learning and understanding, and wonderful ways to deal with them. (Must Read)</li> </ul> </li> <li>Breaking Barriers: Click here<ul> <li>The IIT Madras Story</li> </ul> </li> <li>Unoffical guide for Paradox: Click here</li> <li>IITM BS Students Website: https://www.iitmbs.org/</li> <li>IITM BS Students Portal (Unofficial): https://portal.iitmbs.org/</li> <li>Official WhatsApp Bot: Chat Link</li> <li>Unofficial Student Discord: Invite Link<ul> <li>The verification email usually comes in spam. Do check that to verify after you have initiated the process.</li> </ul> </li> <li>IITM BS Student Network: https://portal.iitmbs.org/network</li> <li>IITM BS Placements Committee: Click here</li> <li>Know Your Representatives: Here</li> <li>IITM BS Student Community: Click here</li> <li>It is one place to find most of the groups across different levels of the program or accross different regions of India.</li> <li>Student Dashboard: Click here</li> <li>Tip: It's usually an inconvenience to login into the portal every time you want to access a course. Instead, once you reach the specific course page (NPTEL Seekh), you can save the link (by adding to home screen, to start menu, etc..) and when you open using that link, you won't be asked to login repeatedly.</li> <li>Student Handbook (Important): Handbook</li> <li>Course Calendars: Click here</li> <li>Use this to access all the course calendars at one place. This also contains certain instructions on how to use the calendar.</li> <li>Discourse Forum: https://discourse.onlinedegree.iitm.ac.in/</li> <li>An official place to post queries regarding various academic issues. </li> <li>Github - BS IIT Madras: Github Organisation</li> <li>Proquest ECentral Library: E-Library</li> <li>This mainly contains educational books. Don't expect novels / stories. :)</li> <li>Google Groups: https://groups.google.com/my-groups</li> <li>Used by the team to send out official announcements. You can find all the announcements sent via email at one place here.</li> <li>Resources by students: </li> <li>IITM BS Notes: The Open Notes</li> <li>Grade Calculator: Calculator</li> <li>Studify: Study Space for BS Degree</li> <li>Paradox: https://iitmparadox.org/</li> <li>Needs no introduction! </li> <li>Paradox Saavan: https://saavan.iitmparadox.org/<ul> <li>The Online Fest of IITM BS (August)</li> </ul> </li> <li> <p>Paradox Margazhi: https://margazhi.iitmparadox.org/</p> <ul> <li>The Hybrid Fest of IITM BS (January)</li> </ul> </li> <li> <p>Term Specific Links: (May 2023)</p> </li> <li>Point of Contact: Click here<ul> <li>Use this to know whom to contact for specific course related queries that cannot be solved by others</li> </ul> </li> <li>Grading Document: Document</li> <li>Important Dates:<ul> <li>Quiz 1: July 16</li> <li>Quiz 2: August 6</li> <li>End Term Exam: September 3</li> </ul> </li> </ul>"},{"location":"#how-to-help-by-adding-newer-links-or-updating-older-ones","title":"How to help by adding newer links or updating older ones?","text":"<p>First of all, thanks for doing this. There are 3 ways you could do this:</p> <ul> <li> <p>Pull Request (Preffered): Please submit a pull request (if familiar with GitHub) after adding or editing a link you might want to add or change. This makes it easy for me to approve the changes and the changes are automatically done without me needing to manually change it.</p> </li> <li> <p>Create an Issue: Please head on to the issues tab and click on New Issue. Enter there the link that you'd want me to add to this repository and I will do it ASAP.</p> </li> <li> <p>Post in Discourse: To those who don't know, this page was created because I couldn't edit the Original Post on discourse after 24 hours. You can still however, post a link that you'd like to add here and I'll be sure to update this page.</p> </li> </ul>"},{"location":"about/","title":"Iram et nec","text":""},{"location":"about/#iovis-egreditur-frigoris-heros-notissima-undas-momordit","title":"Iovis egreditur frigoris heros notissima undas momordit","text":"<p>Lorem markdownum aut regem, cumulusque: spiritus gemellam; Titania etiam ire meruisse, sorores! Virus thalamumque Aesaris naturae Iuno, inbutam est iram, temptat sanctasque idem sed ambae autumnos quasque. Vestigia excipit auctor Cinyras oscula.</p>"},{"location":"about/#vestigia-animaeque-cornum","title":"Vestigia animaeque cornum","text":"<p>Suspirat et lynca passim, temperiem in Aeneas thyrso finita, hic Arcade iunguntur, solis: ait. Est tenuitque ne atque mutare cum, finxit, internodia vim poenaeque venti vero. Fervet quis puer, more nec Phocaico lumen parenti nullaque Aenean, nec pater super quoniam: lucem mirabile Ligurum. Fuge dum manus insolida musco; illa virgaque triplicis venatibus protinus inque alis se saxa.</p>"},{"location":"about/#pavet-habuistis-occupat-potentior-ubicumque-pars","title":"Pavet habuistis occupat potentior ubicumque pars","text":"<p>Habuit o animam facies, vel turba clausa tamen finemque. Pars maius cumque plangente et vita amor cautus; Iapygis ingeniis ab nunc serpunt litusque.</p> <ul> <li>Mente virum</li> <li>Melanchaetes genus solus nunc desine errare de</li> <li>Quaque quibus patris venenis vixisti nostro pulmone</li> <li>Quod ante surgere mandat pallidiora mors est</li> <li>Colebat filius</li> <li>Aetas tori dextra Achille</li> </ul>"},{"location":"about/#undis-phoebus-praevius-bracchia-bracchia-foret","title":"Undis Phoebus praevius bracchia bracchia foret","text":"<p>Nec bonis, desuetudine, placet ara virgo excipit. A est dedecus quid nempe et soror ingens tua quae mora corpus notas, tempore. A et felix peragentem et ossibus parabat est quae arcus! Quae mihi parte. Regis meum illa melle bracchia; de Iove tu vivit graves, geniti aliquis mariti.</p> <ul> <li>Mea semper tenaci</li> <li>Vacuae baculum mea de et nunc</li> <li>Equos ipsaque dulcia smaragdis montibus tectis ita</li> <li>Per puer nisi cuncta et in maerens</li> <li>Adunca et parvis timide deae constabat ideoque</li> </ul>"},{"location":"about/#modumque-quoque-acoetes-ad-iam-equos-poenas","title":"Modumque quoque Acoetes ad iam equos poenas","text":"<p>Lumina sub miratur est foret Aegyptia tamen, et petam amplexus quoque. Et dixit alios; tua saepe quod Aetnaeo seque: ebur sed exspectatum.</p> <ul> <li>Virgo humilesque et silicem guttas circumdata quae</li> <li>Et puerum</li> <li>Seu profatur madent</li> <li>Tamen saepe grandaevumque fontes mortis tantum aquas</li> </ul> <p>Urbes gravius ponite. Per arcus humilesque credere tangi non.</p>"},{"location":"BDM/WEEK%201/Consumption/","title":"Consumption and Demand","text":""},{"location":"BDM/WEEK%201/Consumption/#divisions-of-economic-activity","title":"Divisions of Economic Activity","text":"<ul> <li>Production: The making of goods is production.</li> <li>Consumption: The way a consumer uses the goods.</li> <li>Exchange: It is the exchange of goods and services in return of something with monetary value.</li> <li>Distribution: Distribution is not only of the goods produced but also the resources required to produce. It works within exchange.</li> <li>Investment: Saving up money to invest in the future. For a consumer it might be saving up money for a house. For a producer it can be investing in better machines or resources.</li> </ul>"},{"location":"BDM/WEEK%201/Consumption/#production","title":"Production","text":"<ul> <li> <p>Production is the process of converting raw materials into useful good/service. Goods/services become useful as they acquire utility value in the process of  production.</p> </li> <li> <p>Producers have limited capital resources while they have a wide range of goods and services to choose from for their firms and factories to produce.</p> </li> <li> <p>With the given prices of inputs they choose such combinations which minimise cost of  production so that they earn maximum profit.</p> </li> </ul> <p>Note</p> <ul> <li>The production data must be always upto date as the needs of the consumer  change with time.</li> <li>Price determination mechanism also plays a major role in the process of production and consumption.</li> </ul>"},{"location":"BDM/WEEK%201/Consumption/#consumption","title":"Consumption","text":"<ul> <li> <p>Consumption is that economic activity which is concerned with the use of goods and services for the direct satisfaction of individuals and collective wants.</p> </li> <li> <p>A consumer is a person who consumes goods and services for the satisfaction  of his/her wants. (Satisfaction may vary from person to person)</p> </li> <li> <p>Consumption activity is the base of all production activities. (Goods which are not consumed by the consumer would not be produced.)</p> </li> </ul>"},{"location":"BDM/WEEK%201/Consumption/#factors-affecting-consumption","title":"Factors Affecting Consumption","text":"<ul> <li> <p>As a consumer has limited income , while their wants are unlimited.</p> </li> <li> <p>Study of consumption behaviour is concerned with the question \"How people use their given / limited means for the purchase of different goods and services, so that satistfaction is maximized?\"</p> </li> <li> <p>In consumption theory we formulate  a set of standard relationships explaining how customers  tend to behave.</p> <p>Example</p> <pre><code>Indians buying new clothes during the time of diwali.\n</code></pre> </li> </ul>"},{"location":"BDM/WEEK%201/Consumption/#exchange","title":"Exchange","text":"<ul> <li> <p>Exchange is that economic activity which is concenrned with the sale and purchase of commodities.</p> </li> <li> <p>In simple terms barter or buying and selling.</p> </li> </ul>"},{"location":"BDM/WEEK%201/Consumption/#utility-and-prices","title":"Utility and Prices","text":"<ul> <li> <p>When economists talk about consumer choice , what they are refering to is the combination of goods and services a consumer purchases.</p> </li> <li> <p>To understand how a household will make its choices , economists look at what consumers can afford , as shown in a budget constraint and the total utility or satisfaction derived from those choices.</p> </li> <li> <p>Utility is the term economists use to describe satisfaction or  happiness a person gets from consuming a good or service.</p> </li> </ul>"},{"location":"BDM/WEEK%202/Consumer%20Behaviour/","title":"Consumer Behaviour","text":"<p>The principle assumption upon which the theory of consumer behaviour and  demand is built is:</p> <p>A consumer attempts to allocate his/her limited money/resources among  available goods and services so as to maximize his/her utility (satisfaction).</p>"},{"location":"BDM/WEEK%202/Consumer%20Behaviour/#utility-concepts","title":"Utility Concepts","text":""},{"location":"BDM/WEEK%202/Consumer%20Behaviour/#the-cardinal-utility-theory-tuc","title":"The Cardinal Utility Theory (TUC)","text":"<ul> <li>Utility is measurable in a cardinal sense</li> <li> <p>Cardinal utility assumes that we can assign values for utility.</p> <p>Example</p> <pre><code>Derive 100 utils (theoretical unit for utility) from \neating a slice of bread\n</code></pre> </li> </ul>"},{"location":"BDM/WEEK%202/Consumer%20Behaviour/#total-utility","title":"Total Utility","text":"<p>The overall level of satisfaction derived from consuming a good or service.</p>"},{"location":"BDM/WEEK%202/Consumer%20Behaviour/#marginal-utility","title":"Marginal Utility","text":"<p>Additional satisfaction that an individual derives from consuming an  additional unit of a good or service.</p> \\[ \\text{MU} = \\frac{\\text{Change in total utility}}{\\text{Change in quantity}}\\] \\[ \\implies \\frac{\\Delta \\text{TU}}{\\Delta Q} \\]"},{"location":"BDM/WEEK%202/Consumer%20Behaviour/#law-of-diminishing-utility","title":"Law Of Diminishing Utility","text":"<ul> <li>Law of Diminishing Utility (Return) states that as more and more of a good  are consumed , the process of consumption will (at some point) yield smaller  and smaller additions to utility.</li> <li>When the total utility maximum , marginal utility = 0</li> <li> <p>When the total utility begins to decrease , the marginal utility = negative (-ve)</p> <p>Example</p> <p></p> </li> </ul>"},{"location":"BDM/WEEK%202/Consumer%20Behaviour/#consumer-equilibrium","title":"Consumer Equilibrium","text":"<ul> <li>So far , we have assumed that any amount of goods and services are always available for consumption.</li> <li>In reality , consumers face constraints (income and prices).</li> <li> <p>Consumer's objective is to maximize his/her utility subject to income constraint.</p> </li> <li> <p>Suppose there are 2 goods \\(X\\) and \\(Y\\) with fixed prices \\(P_X\\) and \\(P_Y\\). Then consumer will reach an equilibrium when the ratio of marginal utlity to the prices is equal.</p> \\[ \\frac{MU_X}{P_X} = \\frac{MU_Y}{P_Y} \\] <p>Similarly , when the ratio is higher for a good than the other , then the consumer will prefer former.</p> \\[ \\frac{MU_X}{P_X} &gt; \\frac{MU_Y}{P_Y} \\] <p>In this case consumer will prefer \\(X\\) more than \\(Y\\).</p> <p>Example</p> <p>Raj wants to eat a pack of biscuits. Raj goes to a nearby corner shop and sees there are only 2 option available Parle-g and Tiger. Both of them have the same price and same weight.</p> <p>In this case Raj might buy a smaller pack of both or a bigger pack of either of them as , Raj gets an equal amount of utility from both Parle-g and Tiger.</p> <p>Another scenario might be that Raj likes Parle-g more than Tiger so Raj will buy  Parle-g biscuit as it gives him more utility.</p> </li> </ul>"},{"location":"BDM/WEEK%202/Consumer%20Behaviour/#the-ordinal-utility-theory-tuo","title":"The Ordinal Utility Theory (TUO)","text":"<ul> <li>Utility is measurable in an ordinal sense</li> <li>Ordinal utility approach - does not assign values , instead works  with a ranking of preferences.</li> <li> <p>The utlity derived from consuming a good , such as \\(X\\) , is a function of the quantities of \\(X\\) and \\(Y\\) consumed by a consumer.</p> \\[ U = f(X,Y)\\] </li> <li> <p>The ranking of goods according to TUO is done with the help of Indifference Cruves (IC). These curves are representations of combinations of items when the consumer is in an indifferent situation , i.e. certain combinations of goods will give the consumer the same level of satisfaction.</p> </li> <li> <p>In general consumers tend to move to higher IC curves within their budget constraint.</p> <p>Example</p> <p></p> </li> </ul>"},{"location":"BDM/WEEK%202/Consumer%20Behaviour/#properties-of-ic-curves","title":"Properties of IC Curves","text":"<ul> <li>Downward Sloping from left to right: This shows increase in quantity of certain good.</li> <li> <p>Convex to the origin: the marginal rate of substitution (MRS) decreased.     MRS = Quantity of goods \\(Y\\) willing to substitute to obtain one unit of goods \\(X\\) &amp; this      substitution is to maintain its position at the same level of satisfaction.</p> <p>Example</p> <p>Buying 5 Cadburry DairyMilk or getting 1 Premium Dark Chocolate.</p> </li> <li> <p>Do not cross (intersect): Consumer preferences transitive.</p> </li> <li>Different ICs show different level of satisfaction : The farther the curve from origin , the higher the satisfaction.</li> </ul>"},{"location":"BDM/WEEK%202/Cost%20Curves/","title":"Cost Curves","text":""},{"location":"BDM/WEEK%202/Cost%20Curves/#importance-of-relation-between-marginal-and-average-cost-curves","title":"Importance of relation between marginal and average cost curves","text":"<ul> <li>The amount of output/quantity of output is determined by the producer.</li> <li>It is of utmost importance for the producer to decide the range of this output in terms of cost efficiency in terms of quantity output.</li> <li>This can be identified as region around the point of intersection of the Marginal Curve and The Total Cost Curve</li> <li>This forms important decision for a firm</li> </ul> Reasonable Expansion Path of a Firm <p>Start with a small factory as the demand increases, firm moves to medium factory and next with increase in demand again moves to large factory.</p>"},{"location":"BDM/WEEK%202/Cost%20Curves/#economies-of-scale","title":"Economies of Scale","text":"<ul> <li>It is a part of the 'Long Run Total Average Cost Curve'</li> <li>As and when your production (output volume) increase, the average total cost(ATC) keeps falling</li> <li> <p>Reasons for this could be many: bulk purchases(cost advantages), technological innovation, and etc.</p> <p>Example</p> <p>This is the region when 10 units are produced at cost of 1 unit of ATC</p> </li> </ul>"},{"location":"BDM/WEEK%202/Cost%20Curves/#constant-returns-of-scale","title":"Constant Returns of Scale","text":"<ul> <li>This is the region of 'Long Run ATC' for 1 unit of production 1 unit of ATC is incurred.</li> <li>It is a one-one relation</li> <li>Most firms operate in this region</li> </ul>"},{"location":"BDM/WEEK%202/Cost%20Curves/#diseconomies-of-scale","title":"Diseconomies of Scale","text":"<ul> <li>It is a part of the 'Long Run Total Average Cost Curve'</li> <li> <p>As output volume of production is increased, with respect to this; the ATC increase is by a factor of more than that of the production.</p> <p>Example</p> <p>2% increase in output will result in 6% increase in total costs</p> </li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/","title":"Elasticity and Demand","text":""},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#_1","title":"Elasticity and Demand","text":""},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#the-elasticity-of-demand","title":"The Elasticity of Demand","text":"<p>Elasticity is the measure of responsiveness of quantity demanded or  quantity supplied to a change in one of its determinants.</p>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#types-of-elastic-demands","title":"Types of Elastic Demands","text":"<ul> <li> <p>Elastic Demand : It is when quantity demanded responds subtantially to changes in price.</p> </li> <li> <p>Inelastic Demand : It is when quantity demanded responds only slightly to changes in price.</p> </li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#price-elasticity-of-demand","title":"Price Elasticity of Demand","text":"<p>How much much the quantity demanded of a good reponds to a change in  that price of that good.</p> <p>It is the percentage change in quantity demanded divided by the percentage change in price. Only the absolute value of the result is taken into consideration.</p> \\[ \\frac{\\text{Change in Quantity Demanded}}{\\text{Change in Price}}\\]"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#determinants-of-price-elasticity-of-demand","title":"Determinants of Price Elasticity of Demand","text":"<ul> <li> <p>Availability of close substitutes : Goods with close substitutes have more elastic demand.</p> </li> <li> <p>Necessities vs. Luxuries : Necessities have inelastic demand and Luxuries have elastic demand.</p> <p>Example</p> <p>Buying a medicine no matter how costly it is for a family member is a necessity. During the 2nd covid wave , even when the price of oxygen cylinders was sky high , people still bought them as it was a necessity for their loved ones.</p> <p>Luxuries like eating out have elastic demand because , if our favorite resturaunt  suddenly increases prices of all their food , we will most likely look for an alternate option which offers a better price.</p> </li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#types-of-demand-curves","title":"Types of Demand Curves","text":"<ul> <li> <p>When Price elasticity of demand &gt; 1 : It is said that Demand is elastic.</p> <p>Example</p> <p></p> </li> <li> <p>When Price elasticity of demand &lt; 1 : It is said that Demand is inelastic.</p> <p>Example</p> <p></p> </li> <li> <p>When Price elasticity of demand = 1 : It is said that Demand has unit elasticity.</p> <p>Example</p> <p></p> </li> <li> <p>When Price elasticity of demand = 0: The demand curve formed is vertical  and Demand is said to be perfectly inelastic.</p> <p>Example</p> <p></p> </li> <li> <p>When Price elasticity of demand = infinity: The demand curve formed is horizontal and Demand is said to be perfectly elastic.</p> <p>Example</p> <p></p> </li> </ul> <p>Note</p> <p>The flatter the demand curve the greater the elasticity of demand.</p> <p>Moreover , elasticity is not just the slope , but also the position on the curve.</p>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#income-elasticity-of-demand","title":"Income Elasticity of Demand","text":"<p>How much the quantity demanded of a good responds to a change in consumers' income.</p> <p>It is the percentage change in the quantity demanded divided by the percentage change in income.</p> \\[\\frac{\\text{Change in Quantity Demanded}}{\\text{Change in Income}}\\]"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#classification-of-goods","title":"Classification of Goods","text":""},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#normal-goods","title":"Normal Goods","text":"<ul> <li>Positive Income Elasticity</li> <li>Necessities : Smaller income elasticities </li> <li>Luxuries : Large income elasticities </li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#inferior-goods","title":"Inferior Goods","text":"<ul> <li>Negative Income Elasticity</li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#cross-price-elasticity-of-demand","title":"Cross-Price Elasticity of Demand","text":"<p>How much the quantity demanded of one good responds to a change in price of another good.</p> <p>It is the percentage change in quantity of demanded of first good divided by the  percentage change in the price of the second good.</p> \\[\\frac{\\text{Change in Quantity Demanded of Some Good}}{\\text{Change in Price of Second Good}}\\]"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#classification-of-goods_1","title":"Classification of Goods","text":""},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#substitutes","title":"Substitutes","text":"<ul> <li>Goods typically used in place of one another.</li> <li>Positive cross-price elasticity </li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#complements","title":"Complements","text":"<ul> <li>Goods that are typically used together.</li> <li>Negatice cross-price elasticity.</li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#elasticity-of-supply","title":"Elasticity of Supply","text":""},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#price-elasticity-of-supply","title":"Price Elasticity of Supply","text":"<ul> <li>How much the quantity supplied of a good responds to a change in the price of that good.</li> <li>It is the percentage change in quantity supplied divided by the percentage change in price.</li> <li>Depends on the flexibility of sellers to change the amount the goods they produce.</li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#classification-of-goods_2","title":"Classification of Goods","text":"<ul> <li>Elastic Supply Goods : Quantity supplied responds substantially to changes in the price.</li> <li>Inelastic Supply Goods : Quantity supplied responds only slightly to changes in the price.</li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#determinants-of-price-elasticity-of-supply","title":"Determinants of Price Elasticity of Supply","text":"<ul> <li>Time Period : Supply is more elastic in long run</li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#types-of-supply-curves","title":"Types of Supply Curves","text":"<ul> <li>When Price elasticity of Supply &gt; 1 : It is said that Supply is elastic.</li> <li>When Price elasticity of Supply &lt; 1 : It is said that Supply is inelastic.</li> <li>When Price elasticity of Supply = 1 : It is said that Supply is unit elastic.</li> </ul>"},{"location":"BDM/WEEK%202/Elasticity%20and%20Demand/#effects-of-a-price-change","title":"Effects of a Price Change","text":"<ul> <li>Income Effect : A change in a consumer's real purchasing power brought about by a  change in the price of a good.</li> <li>Substitution Effect : An incentive to increase consumption of a good whose price  falls , at the expense of other , now relatively more expensive , goods.</li> </ul>"},{"location":"BDM/WEEK%202/Make%20Buy/","title":"Make vs. Buy","text":""},{"location":"BDM/WEEK%202/Make%20Buy/#what-is-a-make-or-buy-decision-for-a-firm","title":"What is a make or buy decision for a firm?","text":"Sunk Costs <p>A firm entering into an agreement with a marketing agency and need to pay the fee upfront is termed as sunk cost. Here during the course, let's say you do-not yield any results from this and thereby the cost of the fee is sunk (in metaphorical sense)</p> <ul> <li>This is a situation for the firm when it has to decide whether to buy from other source (outsource) and sell (avoids investing in capital) or make it on its own via investing in additional capital that is incurred to do so.</li> <li> <p>Sunk cost also is one of the important factor in make or buy decision for a firm.</p> <p>Example</p> <p>'Bata' decided it is better to outsource its operations of footwear making to several local firms than to produce it on its own. One such model could be it gives specifications of the models to be produced along with the quantity and Bata brands the foot wear with its logo and sells to the customers.So for Bata buy was the decision over make.</p> </li> </ul> Firm Controlling the Market <p>A firm has control of price to fix on the commodity  or quantity to produce or both.</p> <ul> <li>In a monopoly market, a firm can control both price and quantity</li> <li>In a competitive markets, only quantity can be controlled</li> </ul>"},{"location":"BDM/WEEK%202/Markets%20and%20Competiton/","title":"Markets and Competiton","text":"<ul> <li>Market is a group of buyers and sellers of particular good or service.</li> <li>Buyers determine the demand for the product.</li> <li>Sellers determine the supply of the product.</li> </ul>"},{"location":"BDM/WEEK%202/Markets%20and%20Competiton/#demand","title":"Demand","text":"<ul> <li> <p>Quantity Demanded : Amount of a good buyers are willing and able to purchase.</p> <p>Example</p> <p>When price of good is increases , quantity demand of that good decreases.</p> <p>If Amul raises the prices of Toned Milk by 10 ruppees suddenly , then  consumers will switch to a different brand. Hence , decreasing the demand for  Amul Toned Milk.</p> </li> <li> <p>Law Of Demand: When the price of the good increases , quantity demanded of a good falls.</p> </li> <li>Demand Schedule (table): Relationship between the price of a good and quantity demanded.</li> <li>Demand Curve (graph): Relationship between the price of a good and quantity demanded.</li> <li>Individual Demand: Demand of an individual.</li> </ul> <p>Demand Schedule and Demand Curve</p> <p></p>"},{"location":"BDM/WEEK%202/Markets%20and%20Competiton/#market-demand-curve","title":"Market Demand Curve","text":"<p>It is the sum of individual demand curves horizontally.</p> <ul> <li>Total quantity demanded of a good varies<ul> <li>As the price of the good varies</li> <li>Other things constant</li> </ul> </li> </ul> <p>Market Demand as the Sum of Individual Demands</p> <p></p>"},{"location":"BDM/WEEK%202/Markets%20and%20Competiton/#shifts-in-the-demand-curve","title":"Shifts in the Demand Curve","text":"<ul> <li>Increase in demand<ul> <li>Any change that increases the quantity demanded at every price.</li> <li>Demand curve shifts right</li> </ul> </li> <li>Decrease in demand<ul> <li>Any change that decreases the quantity demanded at every price.</li> <li>Demand curve shifts left.</li> </ul> </li> </ul> <p>Shifts in the Demand Curve</p> <p></p>"},{"location":"BDM/WEEK%202/Markets%20and%20Competiton/#factors-affecting-demand-curve","title":"Factors affecting Demand Curve","text":"<ul> <li> <p>Income (Other factors are constant)</p> <ul> <li> <p>Normal Good: An increase in income leads increase in demand.</p> <p>Example</p> <p>If the income increases a person can now buy more of a certain goods.</p> <p>Buying trendy clothes becomes normal.</p> </li> <li> <p>Inferior Good: An increase in income leads to decrease in demand</p> <p>Example</p> <p>If the income increases a person will look for better options for slightly  higher price</p> <p>Buying expensive shoes from brands like nike and puma.</p> </li> </ul> </li> <li> <p>Prices of related goods</p> <ul> <li> <p>Substitute (two goods): An increase in the price of one leads to an increase in demand of the other</p> <p>Example</p> <p>If the price of Tata Tea increases , consumer will move to a different brand, which will lead to increase in demand of the latter.</p> </li> <li> <p>Complements (two goods): An increase in the price of one leads to an decrease in demand of the other</p> <p>Example</p> <p>If the price of fuel increases , all the goods become costly due to transportation expenses , this will lead to decrease in demand of certain goods because of high price.</p> </li> </ul> </li> <li> <p>Tastes: Changes in tastes over time changes the demand.</p> <p>Example</p> <p>A person when of young age does not like coffee but as he grows older coffee/tea gives the person utility/satisfaction.</p> </li> <li> <p>Expectations : Expectation about the future</p> <ul> <li> <p>Expecting an increase in income might lead to increase in current demand of a certain good.</p> <p>Example</p> <p>Buying goods on loan/EMI</p> </li> <li> <p>Expecting higher prices might also lead to increase in current demand.</p> <p>Example</p> <p>Buying grains in large quantity when the news of bad harvest breaks out.</p> </li> </ul> </li> <li> <p>Number of buyers</p> </li> </ul>"},{"location":"BDM/WEEK%202/Markets%20and%20Competiton/#supply-and-demand-together","title":"Supply and Demand Together","text":"<p>Equilibrium is a situation when,</p> <ul> <li>Supply and demand forces are in balance.</li> <li>A sitation in which market price has reached a level where \\(\\text{Quantity Supplied} = \\text{Quantity Demanded}\\)</li> <li>Supply and demand curves intersect.</li> </ul> <p>Equilibrium Price: Balances quantity supplied and quantity demanded , also known as market-clearing price.</p> <p>Equilibrium Quantity: Quantity supplied and quantity demanded at the equilibrium price.</p> <p>Equilibrium of Supply and Demand</p> <p></p>"},{"location":"BDM/WEEK%202/Production%20Cost/","title":"The Cost of Production","text":"2 Broad Agents of Market <ul> <li>Consumer : Who demands via consumption. Objective of a consumer is to maximize his/her utility.</li> <li>Producer : Who supplies via production. Objective of a producer is to maximize his/her profits.</li> </ul> <p>The important factor that affect 'Supply' is 'Cost of Production</p> <p>Based on the cost of production, several supply decisions can be arrived at like what goods to produce ,  how much goods to produce  , to which segment to pitch the product to, etc.</p>"},{"location":"BDM/WEEK%202/Production%20Cost/#types-of-costs","title":"Types of Costs","text":""},{"location":"BDM/WEEK%202/Production%20Cost/#historical-cost-and-replacement-cost","title":"Historical Cost and Replacement Cost","text":"<ul> <li> <p>Historical Cost : It is the actual cost when purchasing an asset.</p> <p>Example</p> <ul> <li>Cost of Machinery while setting up a plant.</li> <li>Purchasing land for setting up a factory.</li> </ul> </li> <li> <p>Replacement Cost : The price that is needed to replace a certain asset based on the current market price, let's say Rs. 1 Cr</p> <p>Example</p> <p>The cost of machinery today replacing the outdated one(which was purchased and put at time of setting up of the plant) at current market price let's say 2 Cr</p> What is a Depreciation Reserve? <p>A firm bought machinery for a cost of 5 Cr, after 15 years the exact machinery needs to be replaced by a new one. But the cost of the same machinery today 15 years later is 15 Cr. To compensate this a firm starts a depreciation reserve, which accommodates a certain specific amount into this reserve, let's say 1 Cr per year and after 15 years, new machinery is bought from this reserve without any additional burden on the firm</p> </li> </ul>"},{"location":"BDM/WEEK%202/Production%20Cost/#fixed-cost-and-variable-cost","title":"Fixed Cost and Variable Cost","text":"<ul> <li> <p>Fixed Cost : All costs incurred that are unaffected by the company's production output or sales.</p> <p>Example</p> <ul> <li>Interest to be paid to bank is independent of firm's sales being up or down</li> <li>Rent to be paid is independent on firm's sales</li> </ul> </li> <li> <p>Variable Cost: All the costs that are associated with the firm that increase or decrease with respect to the production volume/output. Those costs which increase with increase in production volume and decrease with decrease in production volume.</p> <p>Example</p> <p>Cost of trolley autos increases with increase in production volume</p> </li> </ul>"},{"location":"BDM/WEEK%202/Production%20Cost/#real-cost-and-prime-cost","title":"Real Cost and Prime Cost","text":"<ul> <li> <p>Real Cost : It accounts for physical quantities of various non-monetary factors that are in materialistic terms. </p> <p>Example</p> <p>Cost of number of nails, cost of cubic per feet and etc</p> </li> <li> <p>Prime Cost: It is the direct cost incurred in terms of material and labour involved in the production excluding fixed cost. Prime costs help determine the selling cost of a commodity to earn profit.</p> </li> </ul>"},{"location":"BDM/WEEK%202/Production%20Decisions/","title":"Production Decisions","text":"Extra Information 2 factors concerning production decisions <p>Production decisions are intertwined with price and quantity. Pricing is a function of cost and quantity produced.</p> General Inputs <p>CLEM: Capital, Labour Energy and Material</p>"},{"location":"BDM/WEEK%202/Production%20Decisions/#production-function","title":"Production Function","text":"<ul> <li>It gives you the maximum level of output to be produced based on the various inputs.</li> <li>The production function gives relationship between inputs used in the production and the maximum output production with given period of time and with given period of technology</li> <li>\\(Q = f(x_1, x_2, \u2026.x_n)\\) where \\(x_1, x_2, \u2026..x_n\\) are inputs used in the production. \\(Q\\) is the maximum level of output.</li> </ul>"},{"location":"BDM/WEEK%202/Production%20Decisions/#types-of-production-function","title":"Types of Production Function","text":""},{"location":"BDM/WEEK%202/Production%20Decisions/#short-run-production-function","title":"Short Run Production Function","text":"<ul> <li> <p>Consider a simple production function with 2 inputs: capital and labour \\(Q = f(X,Y); Q: \\text{Output}, X: \\text{Labour}, Y: \\text{capital}\\)</p> </li> <li> <p>A function which provides the maximum output produced for given inputs such that at least one of the production inputs remains unchanged</p> </li> <li>Usually for a short-term production function, capital remains unchanged</li> <li>Short-term production function is useful in understanding short-term production goal for the firm</li> </ul>"},{"location":"BDM/WEEK%202/Production%20Decisions/#long-run-production-function","title":"Long Run Production Function","text":"<ul> <li> <p>Consider a simple production function with 2 inputs: capital and labour \\(Q = f(X,Y); Q: \\text{Output}, X: \\text{Labour}, Y: \\text{capital}\\)</p> </li> <li> <p>A function which provides the maximum output produced for given inputs such that at firm is free to vary ALL the production inputs</p> </li> </ul> <p>Terms Relating to Short-run analysis</p> <ul> <li>Marginal Product, Average Product and Total Product are the three terms important to short-run analysis</li> <li>Marginal Product (MP) \\(= \\frac{\\Delta Q}{\\Delta X}\\)</li> <li>Average Product (\\(AP_x\\)) \\(= \\frac{Q}{X}\\)</li> </ul>"},{"location":"BDM/WEEK%202/Production%20Decisions/#marginal-product-and-average-product","title":"Marginal Product and Average Product","text":"<ul> <li>MP gives you the estimate of change of production output resulting from unit change in a variable output</li> <li>For example, let\u2019s say a organic farming company wants to hire a manager, MP gives you how much additional production is achieved from this additional hire</li> <li>MP helps in production decision making as stated in above example, should I hire an additional person or not</li> <li>AP, for example gives you on and average what is total quantity of cement produced by 1 person applicable to a cement manufacturing firm</li> </ul> How does a firm decide how much to produce and when/where to stop hiring? <p>For a firm it is utmost important to locate the level of its production, this can be done with the help of production data (MP, TP, AP)</p>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/","title":"Financial Analysis","text":"<ul> <li>Financial analysis of the firm helps in finding its own strengths and weaknesses</li> <li>Financial analysis helps in monitoring the key indicators of the firm</li> <li>Financial analysis helps in comparison between different firms (competitive analysis)</li> <li>Financial Analysis helps in understanding a firm\u2019s past, present and future financial conditions</li> </ul> What are Financial Statements? <ul> <li>Financial statements are written records that convey the business activities and the financial performance of a company.</li> <li>Balance sheet (annual financial record) (provides performance of company) , income statement (sources of income) (sales, interests, etc), cash flow statement (provides for liquidity position), statement on retained earnings</li> </ul>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#ratio-analysis","title":"Ratio Analysis","text":"<ul> <li>Ratio analysis helps firms to evaluate performance, do structural analysis, provide useful insights and relationship between various business activities and performance</li> <li>Objectives of ratio analysis are to study efficiency of operations, study risk of operations, compare performance with the past performance, compare performance with other firms, evaluate current performance and etc</li> </ul> <p>Limitations of Ratio Analysis</p> <ul> <li>Accounting practices may differ from one firm to another</li> <li>Seasonality affects ratio analysis, eg: one quarter saw huge increase in performance (via. ratios) because of more festivals in that quarter which is not the right indicative. In such cases along with that quarter you could compare it with Annual performance to make sense of it.</li> </ul> 5 Major Ratios <ul> <li>Liquitdity: the ability of a firm to pay its way </li> <li>Investment/Shareholders : Information to enable decisions to be made on the extent of the risk  and earning potential of a business investment.</li> <li>Gearing : Information on the relationship between the exposure of the business to loans  as opposed to share capital.</li> <li>Profitability : How effective the firm is at generating profits given sales  and or its capital assets.</li> <li>Financial : The rate at which the company sells its stock and the efficiency  with which it uses its assets.</li> </ul>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#types-of-ratio-analysis","title":"Types of Ratio Analysis","text":""},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#acid-test-quick-ratio","title":"Acid Test (Quick Ratio)","text":"<ul> <li>Quick ratio = (current assets - stock inventory) / liabilities</li> <li>1:1 is an ideal ratio to have</li> <li>3:1 is a healthy ratio, and would mean that there exists lot current assets compared to liabilities</li> <li>0.5:1 is an unhealthy ratio, this would put lot of pressure on the firm</li> </ul>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#current-ratio","title":"Current Ratio","text":"<ul> <li>Current ratio = current assets / current liabilities</li> <li>Too high or too low current ratio could be problematic</li> <li>Too high would mean that there are too many current assets and mostly tied up with unproductive assets</li> <li>Too low would mean the risk of not able to pay your way</li> <li>Ideal ratio is 1.5:1</li> <li>5:1 ratio would mean Rs 5/- in assets is available to cover every Rs1/- of liabilities</li> <li>0.75:1 ratio would mean 75p in assets is available to cover every Rs1/- of liabilities</li> </ul>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#ratios-used-by-investors","title":"Ratios Used by Investors","text":"<ul> <li>Earnings Per Share : Profit after tax / number of shares</li> <li>Price Earnings Ratio : Market Price / Earning per share - The higher the better  generally for company. Comparison with other firms helps to identify value placed  on the market of business.</li> <li>EV / EBITDA Ratio : The higher the better for the company. It measures operational performance of the firm.</li> <li>Dividend Yield : Ordinary share dividend / market price * 100 - the higher the better. Related the return on the investment to share price.</li> </ul>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#gearing-ratio","title":"Gearing Ratio","text":"<ul> <li>Gearing ratio =( long term loans/capital employed) * 100</li> <li>This ratio provides for an idea on how much capital is employed from the long term loans taken</li> </ul>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#profitability","title":"Profitability","text":"<p>Profitability measures look at how much profit the firm generates from sales  or its capital assests.</p>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#different-measures-of-profit","title":"Different Measures of Profit","text":"<ul> <li> <p>Gross Profit : Effectively total revenue (turnover) - cost of goods sold</p> <p>Gross Profit Margin</p> <p>Gross Profit Margin = Gross Profit / Turnover * 100</p> <ul> <li>The higher the better </li> <li>Enables the firm to assess the impact of its sales and how much it cost to generate  those sales.</li> <li>A gross profit margin of 45% means that for every 1$ the firm makes 0.45$ in gross profit.</li> </ul> </li> <li> <p>Net Profit : Effectively total revenue (turnover) - Variable costs and fixed costs (overheads)</p> <p>Net Profit Margin</p> <p>Net Profit Margin = Net Profit / Turnover * 100</p> <ul> <li>Net profit takes  into account the fixed costs involved in production - the overheads.</li> <li>Keeping control over fixed costs is important - could be easy to overlook for example  the amount of waste - paper , stationery , lighting , heating , water ,etc.</li> </ul> </li> <li> <p>ROCE : Return on Captial Employment = Profit / Capital Employed * 100</p> <ul> <li>The higher the better</li> <li>Shows how effective the firm is in using its captial to generate profit</li> <li>Partly a measure of efficiency and use of capital in an organisation.</li> <li>A ROCE of 25% means that it uses 1$ of capital to generate 25p in profit.</li> </ul> </li> </ul>"},{"location":"BDM/WEEK%203/Analysis%20of%20Firm%20Performance/#stock-turnover-ratio","title":"Stock Turnover Ratio","text":"<ul> <li>Stock piling up is a big problem in stock intensive industries such as textile, cement etc</li> <li>Stock turnover ratio = cost of goods sold / stocks expressed as times per year</li> <li>Low stock turnover ratio would mean poor customer satisfaction of the goods and people may not be interested in the goods</li> <li>This ratio indicates the rate at which company stocks are turned over</li> </ul> What is debtor days? <ul> <li>Debtor days = (debtor/sales turnover)*365</li> <li>How long it takes for the business to recover its debts</li> <li>Shorter the debtor days, better for the firm\"</li> </ul> <p>Summary of Financial Ratios</p> <ul> <li>Ratios help to:<ul> <li>Evaluate Performance </li> <li>Structure Analysis </li> <li>Show the connection between activities and performance.</li> </ul> </li> <li>Ratios adjust for differenct sizes.</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/","title":"Pricing Strategies","text":"<ul> <li>Pricing of a product depends on the market (monopoly, competitive, etc)</li> <li>In general \u2018price\u2019 cannot be changed much in an competitive markets like FMCG, etc</li> <li>Pricing also depends on its product category</li> <li>Pricing depends on the long run vision of the firm on that product eg: to maximize sales or to maximize profits, or to capture market share etc.</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#pricing-strategies-objectives","title":"Pricing Strategies Objectives","text":"<p>In general products have a life cycle of their own, for example: A newly launched product might have a slow start to enter the market and then it gets diffused and faces the competition, then comes the maturity stage for the product when it hits the max volumes and after that comes the declining phase of the product life cycle.</p> <p>At each stage/phase of product life cycle, different pricing strategies are needed.</p> <ul> <li>Long Run Profits</li> <li>Short Run Profits </li> <li>Increase Sales Volume </li> <li>Company Growth </li> <li>Match Competitors Price </li> <li>Create Interest &amp; Excitement about the Product</li> <li>Discourage Competitors from cutting price.</li> <li>Social , Ethical and Ideological Objectives </li> <li>Discourage New Entrants </li> <li>Survival</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#decisions-in-pricing-strategy","title":"Decisions In Pricing Strategy","text":"<ul> <li>Fixed &amp; Variable Cost </li> <li>Competition </li> <li>Company Objectives </li> <li>Proposed Positioning Strategies </li> <li>Target Group &amp; Willingness to Pay</li> <li>External Market Demand </li> <li>Internal Factors : Product Cost &amp; Objectives of Company</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#factors-affecting-pricing","title":"Factors Affecting Pricing","text":"<ul> <li>Consumer\u2019s primary goals with respect to the product affects pricing of a product</li> <li>Having or not having a Unique Selling Point (USP) for the product vs. competition</li> <li>Bundling low-value and high-value products or services (eg: sedan features in a hatchback car)</li> <li>Geographical segmentation of market (city -district - income groups) also plays an important factor in pricing. Different regions in the same country may have varied prices sometimes</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#types-of-pricing-strategies","title":"Types of Pricing Strategies","text":""},{"location":"BDM/WEEK%203/Pricing%20Strategies/#market-skimming-prices","title":"Market Skimming Prices","text":"<ul> <li>This type of pricing strategy depends, if one has complete information on customer demand (willingness and ability to buy)</li> <li>High Price low volume products.</li> <li>Skim Profit from the Market </li> <li>Suitable for the products that have short life cycle or which will face some  comptetion at some point in the future.</li> </ul> <p>Example</p> <p>PlayStation , Digital Technology , Fast Fashion , etc.</p>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#value-pricing","title":"Value Pricing","text":"<ul> <li>Based on consumer perception.</li> <li>Price charged according to Customers Perception.</li> <li>Price set by the company as per the Percived value.</li> <li>Value pricing for a firm largely depends on the insights about via consumer</li> </ul> <p>Example</p> <p>Status Products (apple iphone) / Exclusive Products </p>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#loss-leader-pricing","title":"Loss Leader Pricing","text":"<ul> <li>Goods / services deliberately sold below cost to encourage  large volume of sales for a certain period of time.</li> <li>Purchases of other items more than covers 'loss' on item sold.</li> </ul> <p>Example</p> <p>Festival Sales , Supermarket special sales , etc.</p>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#psychological-pricing","title":"Psychological Pricing","text":"<ul> <li>Setting a price according to what consumers think the price to be .</li> <li>Its used to play on consumer perception , high value goods are priced  according to what customers THINK should be the price of that premium good.</li> </ul> <p>Example</p> <p>Rs. 9.99 instead of Rs 10.99</p>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#going-rate-pricing","title":"Going Rate Pricing","text":"<ul> <li>Constantly monitor rival\u2019s pricing</li> <li>Match the price or cut the price below the competitors price</li> <li>Increase the price when needed based on competitor\u2019s price</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#tender-pricing","title":"Tender Pricing","text":"<ul> <li>This is Low cost but high value delivery model</li> <li>Typically government tenders</li> <li>Many contracts are given via tenders</li> <li>Reputation (past track record) is important</li> <li>Entry barriers are high (tender placing requirements such as annual turnover of minimum 10cr and etc)</li> <li>Chances of collusion are there as tenders are kept somewhat secret.</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#price-discrimination","title":"Price Discrimination","text":"<ul> <li>Same product or service are sold to different people at different prices is called price discrimination</li> </ul> <p>Example</p> <p>Airline Tickets , Perishable Goods , etc.</p> <ul> <li>This strategy is possible where there is no resale of the product is possible.</li> </ul> <p>Subcategories of Price Discrimination</p> <ul> <li>Peak load pricing is a variant of price discrimination (metro prices at peak hours vs. non-peak hours)</li> <li>Cross-price subsidization: For example, there are 2 customers customer#1 does not have the ability to pay more for a service - you subsidize the price and customer#2 has ability to pay more - you charge more to recover from subsidizing the price for customer#1, electricity is another example, classes in train travel , etc.</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#penetration-pricing","title":"Penetration Pricing","text":"<ul> <li>Pricing set to penetrate the market</li> </ul> <p>Example</p> <p>Jio gave free data to new consumers in order to penetrate the market and expand its userbase.</p> <ul> <li>Initially price is very very low and focus on high volume sales</li> <li>Suitable for newly launched product</li> <li>Commonly a long term strategy</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#cost-plus-pricing","title":"Cost Plus Pricing","text":"<ul> <li>Cost-plus pricing is a pricing model used to maximize the rates of return for the companies</li> <li>Cost price(CP) + Mark-Up(MU) = Selling Price</li> <li>Cost price = FC + VC (FC: fixed costs. VC: variable cost)</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#target-pricing","title":"Target Pricing","text":"<ul> <li>I want this much of profits</li> <li>To reach those profits, vary the mark-ups</li> <li>Markup = profit /cost X 100</li> <li>When demand is low, you reduce the mark-up</li> <li>When the demand is high, you increase the mark-up</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#marginal-cost-pricing","title":"Marginal Cost Pricing","text":"<ul> <li>Marginal cost is the cost of producing one extra unit or one fewer unit.</li> <li>Margincal Cost allows flexibility as it allows variable pricing structure.</li> <li>Particularly relevant in transport where fixed costs may be relatively high.</li> <li>Marginal cost pricing MC = \u0394 Total Cost / \u0394 Output = $80 / 2 = $40</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#full-cost-pricing","title":"Full Cost Pricing","text":"<ul> <li>Full cost pricing is an attempt at pricing the commodity to cover both fixed and the variable costs</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#absorption-cost-pricing","title":"Absorption Cost Pricing","text":"<ul> <li>Absorption cost pricing is an attempt to price the commodity to cover variable costs and some of the fixed costs</li> <li>In certain markets where the sunk cost is high, one uses absorption cost pricing.</li> </ul>"},{"location":"BDM/WEEK%203/Pricing%20Strategies/#destroyer-pricing","title":"Destroyer Pricing","text":"<ul> <li>To destroy the post entry of new entrant</li> <li>Undercut the pricing to destroy the competition and force to exit</li> </ul> <p>Summary</p> <ul> <li>The firm should have an idea about the demand of the product and the perception  of that product by the consumer.</li> <li>The firm should have full information about the costs which go into manufacturing  the product.</li> <li>The firm should also have information about the rivals pricing strategy.</li> </ul> <p>With all this information a firm arrives at an appropriate pricing strategy.</p>"},{"location":"BDM/WEEK%204/Industry%20Definition/","title":"Industry Definition","text":"<ul> <li>Industry is collection of firms which are based on related business activities</li> <li>Eg: Cement Industry: Ultra Tech, ACC, Maha, etc</li> <li>Industry wise analysis provides for broad economic insights and projections that enable for future investment decisions</li> </ul> <p>Classification of Industries</p> <p></p> What is MNC? <p>Any company with &gt;10% equity and with operations in more than 1 country is called an MNC</p>"},{"location":"BDM/WEEK%204/Industry%20Definition/#types-of-industries","title":"Types of Industries","text":""},{"location":"BDM/WEEK%204/Industry%20Definition/#large-scale-industry","title":"Large Scale Industry","text":"<p>Industries which employ a large number of labourers in each unit are called large-scale industries.</p> <p>Example</p> <p>Cotton or jute textile industries are large scale industries.</p>"},{"location":"BDM/WEEK%204/Industry%20Definition/#medium-scale-industry","title":"Medium Scale Industry","text":"<p>The industries which employ neither very large nor very small number of labourers are put in the category of medium scale industries. </p> <p>Example</p> <p>Cycle Industry , radio and television industries are medium scale industries.</p> What is Missing Middle Phenomenon <ul> <li>This phenomenon \u2018missing middle\u2019 is unique to India, usually found in the manufacturing industry.</li> <li>Compared to small sector and large sector industries, medium sector industries are very very less, eg: manufacturing industry</li> <li>We call this missing medium sector industries phenomenon as \u2018missing middle</li> </ul>"},{"location":"BDM/WEEK%204/Industry%20Definition/#small-scale-industry","title":"Small Scale Industry","text":"<p>Industries which are owned and run by individuals and which employ a small number of labourers are called small scale industries.</p>"},{"location":"BDM/WEEK%204/Industry%20Definition/#heavy-industry","title":"Heavy Industry","text":"<p>Industries which use heavy and bulky raw-materials and produce products of the same category are called heavy industries.</p> <p>Example</p> <p>Iron and steel industry</p>"},{"location":"BDM/WEEK%204/Industry%20Definition/#light-industry","title":"Light Industry","text":"<p>The light industries use light raw-materials and produce light finished products.</p> <p>Example</p> <p>Electric Fans , Sewing Machines , etc.</p>"},{"location":"BDM/WEEK%204/Industry%20Definition/#private-sector-industry","title":"Private Sector Industry","text":"<p>Industries owned by individuals or firms such as Bajaj Auto or TISCO are called private sector industries.</p>"},{"location":"BDM/WEEK%204/Industry%20Definition/#joint-sector-industry","title":"Joint Sector Industry","text":"<p>Industries owned jointly by private firms and the state or its agencies.</p> <p>Example</p> <p>Gujarat Alkalies Ltd , Oil India Ltd.</p>"},{"location":"BDM/WEEK%204/Industry%20Definition/#co-operative-sector-industries","title":"Co-operative Sector Industries","text":"<p>Industries owned and run co-operatively by a group of people who are generally  producers of raw materials of the given industry such as sugar mill owned and run by  farmers are called co-operative sector industries.</p>"},{"location":"MATHS2/1.01%20-%20Vectors/","title":"Vectors","text":""},{"location":"MATHS2/1.01%20-%20Vectors/#a-vector-can-be-thought-of-as-a-list","title":"A vector can be thought of as a list.","text":"<ul> <li>Vectors can be used to perform arithmatic operations on lists such as table rows or columns.</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/","title":"Matrix","text":""},{"location":"MATHS2/1.02%20-%20Matricies/#video-link","title":"Video Link","text":"<p>Matrix is a rectangular array of number arranged in rows and columns. (Pural: Matrices)</p> <p>Example</p> <ul> <li>\\(\\begin{bmatrix}   1 &amp; 2 &amp; 3 \\\\   4 &amp; 5 &amp; 6 \\\\   \\end{bmatrix}\\)</li> <li>This is a 2x3 matrix.</li> <li>A matrix has \\(m\\) x \\(n\\) dimensions.</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#square-matrix","title":"Square Matrix","text":"<p>A square matrix is a matrix in which the number of rows is the same as the number of columns.</p> <p>Example</p> <ul> <li>\\(\\begin{bmatrix}   1 &amp; 2 &amp; 3 \\\\   4 &amp; 5 &amp; 6 \\\\   7 &amp; 8 &amp; 9 \\\\   \\end{bmatrix}\\)</li> <li>This is a 3x3 matrix.</li> <li>The (2,3) element is 6.</li> <li>The \\(i\\)-th diagonal element is \\(a_{ii}\\).</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#diagonal-matrix","title":"Diagonal Matrix","text":"<p>A diagonal matrix is a square matrix in which all the elements outside the main diagonal are zero.</p> <p>Example</p> <ul> <li>\\(\\begin{bmatrix}     1 &amp; 0 &amp; 0 \\\\     0 &amp; 2 &amp; 0 \\\\     0 &amp; 0 &amp; 3 \\\\     \\end{bmatrix}\\)</li> <li>This is a 3x3 diagonal matrix.</li> <li>The (2,3) element is 0.</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#scalar-matrix","title":"Scalar Matrix","text":"<p>A scalar matrix is a square matrix in which all the diagonal elements are the same.</p> <p>Example</p> <ul> <li>\\(\\begin{bmatrix} 2 &amp; 0 &amp; 0 \\\\ 0 &amp; 2 &amp; 0 \\\\ 0 &amp; 0 &amp; 2 \\\\ \\end{bmatrix}\\)</li> <li>This is a 3x3 scalar matrix.</li> <li>The (2,3) element is 0.</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#identity-matrix","title":"Identity Matrix","text":"<p>The identity matrix is a diagonal matrix in which all the diagonal elements are 1.</p> <p>Example</p> <ul> <li>\\(\\begin{bmatrix}       1 &amp; 0 &amp; 0 \\\\       0 &amp; 1 &amp; 0 \\\\       0 &amp; 0 &amp; 1 \\\\       \\end{bmatrix}\\)</li> <li>This is a 3x3 identity matrix.</li> <li>The (2,3) element is 0.</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#linear-equations-and-matrices","title":"Linear Equations and Matrices","text":"<p>A linear equation is an equation that can be written in the form \\(Ax = b\\) where \\(A\\) is a matrix, \\(x\\) is a vector and \\(b\\) is a vector.</p> <p>Example</p> <ul> <li>\\(3x + 2y = 5\\)</li> <li>\\(4x + 6y = 7\\)</li> <li>\\(A = \\begin{bmatrix}       3 &amp; 2 | &amp; 5 \\\\       4 &amp; 6 | &amp; 7\\\\       \\end{bmatrix}\\)</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#matrix-arithmetic","title":"Matrix Arithmetic","text":"<ul> <li>Lets take two matricies and perform arithmetic operations on them</li> <li>\\(A = \\begin{bmatrix}         1 &amp; 2 &amp; 3 \\\\         4 &amp; 5 &amp; 6 \\\\         \\end{bmatrix}\\)</li> <li>\\(B = \\begin{bmatrix}         4 &amp; 5 &amp; 6 \\\\         7 &amp; 8 &amp; 9 \\\\         \\end{bmatrix}\\)</li> </ul> <p>Note</p> <p>In addition and subtration the matricies must have the same dimensions.</p> <p>Properties of Matrix Arithmetic</p> <ul> <li>\\(A + B = B + A\\)</li> <li>\\((AB)C = A(BC)\\)</li> <li>\\(AB \\neq BA\\)</li> <li>\\(\\lambda(A + B) = \\lambda A + \\lambda B\\)</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#addition","title":"Addition","text":"<p>The sum of two matricies is the matrix obtained by adding corresponding elements of the two matricies.</p> <p>Example</p> <ul> <li>\\(A + B = \\begin{bmatrix}           1 + 4 &amp; 2 + 5 &amp; 3 + 6 \\\\           4 + 7 &amp; 5 + 8 &amp; 6 + 9 \\\\           \\end{bmatrix}\\)</li> <li>\\(A + B = \\begin{bmatrix}           5 &amp; 7 &amp; 9 \\\\           11 &amp; 13 &amp; 15 \\\\           \\end{bmatrix}\\)</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#subtraction","title":"Subtraction","text":"<p>Subtration is the same as addition but with subtraction.</p> <p>Example</p> <ul> <li>\\(A - B = \\begin{bmatrix}           1 - 4 &amp; 2 - 5 &amp; 3 - 6 \\\\           4 - 7 &amp; 5 - 8 &amp; 6 - 9 \\\\           \\end{bmatrix}\\)</li> <li>\\(A - B = \\begin{bmatrix}           -3 &amp; -3 &amp; -3 \\\\           -3 &amp; -3 &amp; -3 \\\\           \\end{bmatrix}\\)</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#scalar-multiplication","title":"Scalar Multiplication","text":"<p>The product of a matrix \\(A\\) with a number \\(c\\) is denoted by \\(cA\\) and the (i,j)-th entry of \\(cA\\) is product of (i,j)-th entry of \\(A\\) with the number \\(c\\).</p> <p>Example</p> <p>\\(2A = \\begin{bmatrix}         2 &amp; 4 &amp; 6 \\\\         8 &amp; 10 &amp; 12 \\\\         \\end{bmatrix}\\)</p>"},{"location":"MATHS2/1.02%20-%20Matricies/#matrix-multiplication","title":"Matrix Multiplication","text":"<p>The product of two matricies \\(A\\) and \\(B\\) is denoted by \\(AB\\) and is defined only if the number of columns of \\(A\\) is equal to the number of rows of \\(B\\).</p>"},{"location":"MATHS2/1.02%20-%20Matricies/#formula","title":"Formula:","text":"\\[(AB)_{ij} = \\sum_{k=1}^nA_{ij}\\cdot B_{kj}\\] <p>Example</p> <ul> <li>\\(A = \\begin{bmatrix}           1 &amp; 2 &amp; 3 \\\\           4 &amp; 5 &amp; 6 \\\\           \\end{bmatrix}\\)</li> <li>\\(B = \\begin{bmatrix}           4 &amp; 5 &amp; 6 \\\\           7 &amp; 8 &amp; 9 \\\\           \\end{bmatrix}\\)</li> <li>\\(AB = \\begin{bmatrix}             1 &amp; 2 &amp; 3 \\\\             4 &amp; 5 &amp; 6 \\\\             \\end{bmatrix} \\begin{bmatrix}             4 &amp; 5 &amp; 6 \\\\             7 &amp; 8 &amp; 9 \\\\             \\end{bmatrix}\\)</li> <li>\\(AB = \\begin{bmatrix}             1 \\times 4 + 2 \\times 7 &amp; 1 \\times 5 + 2 \\times 8 &amp; 1 \\times 6 + 2 \\times 9 \\\\             4 \\times 4 + 5 \\times 7 &amp; 4 \\times 5 + 5 \\times 8 &amp; 4 \\times 6 + 5 \\times 9 \\\\             \\end{bmatrix}\\)</li> <li>\\(AB = \\begin{bmatrix}             18 &amp; 21 &amp; 24 \\\\             45 &amp; 54 &amp; 63 \\\\             \\end{bmatrix}\\)</li> </ul>"},{"location":"MATHS2/1.02%20-%20Matricies/#about-matrix-multiplication","title":"About Matrix Multiplication:","text":"<ul> <li>In matrix multiplication the number of columns of the first matrix must be equal to the number of rows of the second matrix.</li> <li>The dimensions of the product matrix are the number of rows of the first matrix by the number of columns of the second matrix.</li> <li>\\(\\text{Scalar Multiplication by } c = \\text{Multiplication by scalar matrix } cI\\)</li> </ul>"},{"location":"MATHS2/1.03%20-%20Determinants/","title":"Determinants","text":""},{"location":"MATHS2/1.03%20-%20Determinants/#video-link","title":"Video Link","text":""},{"location":"MATHS2/1.03%20-%20Determinants/#definition","title":"Definition","text":"<ul> <li>Every square matrix A has an associated number, called its determinant and denoted by \\(\\det(A)\\) or \\(|A|\\).  It is used in : <ul> <li>Solving systems of linear equations</li> <li>Finding the inverse of a matrix</li> <li>Calculus and More</li> </ul> </li> </ul>"},{"location":"MATHS2/1.03%20-%20Determinants/#calculating-determinants","title":"Calculating Determinants","text":"<ul> <li> <p>Determinant of a 1 x 1 matrix : \\(\\det(A) = a_{11}\\)</p> </li> <li> <p>Determinant of a 2 x 2 matrix :</p> <ul> <li>\\(A = \\begin{bmatrix}         a &amp; b \\\\         c &amp; d \\\\         \\end{bmatrix}\\)</li> <li>\\(det(A) = ad - bc\\)</li> </ul> </li> <li> <p>Determinant of a 3 x 3 matrix :</p> <ul> <li>\\(A = \\begin{bmatrix}         a_{11} &amp; a_{12} &amp; a_{13} \\\\         a_{21} &amp; a_{22} &amp; a_{23} \\\\         a_{31} &amp; a_{32} &amp; a_{33} \\\\         \\end{bmatrix}\\)</li> <li>We will the get the determinant by using the first row.</li> <li>\\(det(A) = a_{11} \\begin{vmatrix}         a_{22} &amp; a_{23} \\\\         a_{32} &amp; a_{33} \\\\         \\end{vmatrix} - a_{12} \\begin{vmatrix}         a_{21} &amp; a_{23} \\\\         a_{31} &amp; a_{33} \\\\         \\end{vmatrix} + a_{13} \\begin{vmatrix}         a_{21} &amp; a_{22} \\\\         a_{31} &amp; a_{32} \\\\         \\end{vmatrix}\\)</li> <li>\\(det(A) = a_{11} (a_{22}a_{33} - a_{23}a_{32}) - a_{12} (a_{21}a_{33} - a_{23}a_{31}) + a_{13} (a_{21}a_{32} - a_{22}a_{31})\\)</li> </ul> </li> </ul> <p>Example</p> <p>\\(A = \\begin{bmatrix}         2 &amp; 4 &amp; 1 \\\\         3 &amp; 8 &amp; 7 \\\\         5 &amp; 6 &amp; 9 \\\\         \\end{bmatrix}\\)</p> <p>\\(\\begin{align}         \\det(A) &amp;= 2 \\begin{vmatrix}         8 &amp; 7 \\\\         6 &amp; 9 \\\\         \\end{vmatrix} - 4 \\begin{vmatrix}         3 &amp; 7 \\\\         5 &amp; 9 \\\\         \\end{vmatrix} + 1 \\begin{vmatrix}         3 &amp; 8 \\\\         5 &amp; 6 \\\\         \\end{vmatrix} \\\\         &amp;= 2 (8 \\times 9 - 7 \\times 6) - 4 (3 \\times 9 - 7 \\times 5) + 1 (3 \\times 6 - 8 \\times 5) \\\\         &amp;= 2 (72 - 42) - 4 (27 - 35) + 1 (18 - 40) \\\\         &amp;= 2 (30) - 4 (-8) + 1 (-22) \\\\         &amp;= 60 - (-32) + 22 \\\\         &amp;= 94 \\end{align}\\)</p>"},{"location":"MATHS2/1.03%20-%20Determinants/#determinant-of-identity-matrix","title":"Determinant of Identity Matrix","text":"<ul> <li>Determinant of a 1 x 1 identity matrix : \\(\\det(I) = 1\\)</li> <li>Determinant of a 2 x 2 identity matrix : \\(\\det(I) = (1 \\times 1) - (0 \\times 0) = 1\\)</li> <li>Determinant of a 3 x 3 identity matrix : \\(\\det(I) = 1 \\times 1 \\times 1 - 0 \\times 0 \\times 0 = 1\\)</li> </ul> <p>Properties of Determinant</p> <ul> <li>Determinant of Product of Matrices :  \\(\\det(AB) = \\det(A) \\times \\det(B)\\)</li> <li>Determinant of Inverse of Matrix : \\(\\det(A^{-1}) = \\frac{1}{\\det(A)}\\)</li> <li>Switching Rows : \\(\\det(A') = -\\det(A)\\) ( \\(A'\\) is the new matrix with switched rows.)</li> <li>Switching Columns : \\(\\det(A') = -det(A)\\) (\\(A'\\) is the new matrix with switched columns.)</li> <li> <p>Adding multiples of rows: (Same proof for multiple of columns)</p> <ul> <li>\\(A = \\begin{bmatrix}       a &amp; b \\\\       c &amp; d \\\\       \\end{bmatrix}\\)</li> <li> <p>\\(A' = \\begin{bmatrix}       a + tc &amp; b + td \\\\       c  &amp; d  \\\\       \\end{bmatrix}\\)</p> <p>\\(\\begin{align}  \\det(A') &amp;= (a + tc)(d) - (b + td)(c) \\\\ &amp;= ad + tcd - bc - tcd \\\\ &amp;= ad - bc \\\\ &amp;= \\det(A) \\\\ \\end{align}\\)</p> </li> </ul> </li> <li> <p>Scalar multiplication of a row/column of matrix \\(A\\) with a constant \\(t\\) : \\(det(A') = t \\cdot det(A)\\)</p> </li> </ul>"},{"location":"MATHS2/1.03%20-%20Determinants/#minors","title":"Minors","text":"<ul> <li>Minor of a matrix is the determinant of a submatrix obtained by deleting a row and a column from the matrix.</li> <li>Minors are denoted by \\(M_{ij}\\).</li> </ul> <p>Example</p> <p>\\(A = \\begin{bmatrix}         a_{11} &amp; a_{12} &amp; a_{13} \\\\         a_{21} &amp; a_{22} &amp; a_{23} \\\\         a_{31} &amp; a_{32} &amp; a_{33} \\\\         \\end{bmatrix}\\)</p> <p>\\(M_{11} = \\begin{vmatrix}         a_{22} &amp; a_{23} \\\\         a_{32} &amp; a_{33} \\\\         \\end{vmatrix}\\)</p> <p>\\(M_{11} = a_{22}a_{33} - a_{23}a_{32}\\)</p>"},{"location":"MATHS2/1.03%20-%20Determinants/#cofactors","title":"Cofactors","text":"<ul> <li>Cofactor of a matrix is the determinant of a submatrix obtained by deleting a row and a column from the matrix.</li> <li> <p>Cofactors are used to calculate the inverse of a matrix.</p> </li> <li> <p>We can use Minors and Cofactors to calculate the determinant of a matrix.</p> </li> </ul>"},{"location":"MATHS2/1.03%20-%20Determinants/#formula","title":"Formula","text":"\\[\\sum_{j=1}^n (-1)^{1+i} \\cdot a_{1i} \\cdot M_{1j} = \\sum_{j=1}^n (-1)^{1+i} \\cdot a_{1i} \\cdot C_{1j}\\]"},{"location":"MATHS2/1.03%20-%20Determinants/#expansion-along-any-row-or-column","title":"Expansion along any row or column","text":"\\[det(A) = \\sum_{j=1}^n (-1)^{1+i} \\cdot a_{ii} \\cdot C_{ij} \\text{ (i is fixed)}\\] \\[\\text{OR}\\] \\[det(A) = \\sum_{j=1}^n (-1)^{1+i} \\cdot a_{ii} \\cdot C_{ij} \\text{ (j is fixed)}\\] <p>More Properties of Determinants</p> <ul> <li>\\(\\det(A^n) = \\det(A)^n\\)</li> <li>\\(\\det(A^{-1}) = \\frac{1}{\\det(A)}\\)</li> <li>\\(\\det(P^{-1}AP) = \\det(A)\\)</li> <li>\\(\\det(AB) = \\det(BA)\\)</li> <li>\\(\\det(A^T) = \\det(A)\\)</li> <li>\\(\\det(tA_{n\\times n}) = t^n \\cdot \\det(A)\\)</li> </ul> <p>Tips for Calculating Determinant</p> <ul> <li>The determinant of a matrix with a row or column of zeros is \\(0\\).</li> <li>The determinant of a matrix in which one row (or column) is a linear combination of other rows (resp. columns) is \\(0\\).</li> <li>Scalar multiplication of a row by a constant t multiplies the     determinant by \\(t\\).</li> <li>While computing the determinant, you can choose to compute it using expansion along a suitable row or column.</li> </ul>"},{"location":"MATHS2/10.01%20-%20Directional%20ascent%20%26%20descent/","title":"Direction of Ascent and Descent","text":"<ul> <li>Let \\(f(x_1,x_2, \\dots, x_n)\\) be a function defined on a domain in \\(D\\) in \\(\\mathbb{R}^n\\) containing some open ball around the point \\(a\\).</li> <li>Suppose \\(\\nabla f\\) exists and is continuous on some open ball around the point \\(a\\).</li> <li>\\(f_u = \\nabla f \\cdot u\\) is the directional derivative of \\(f\\) in the direction of \\(u\\).</li> <li>\\(f_u(a) = ||\\nabla f(a)|| ||u||\\cos \\theta\\)</li> <li>It is minimized when \\(\\theta = \\pi\\) and maximized when \\(\\theta = 0\\).</li> <li>It is maximised when \\(u\\) is in the same direction as \\(\\nabla f(a)\\) or \\(u = \\frac{\\nabla f(a)}{||\\nabla f(a)||}\\).</li> <li>It is minimized when \\(u\\) is in the opposite direction as \\(\\nabla f(a)\\) or \\(u = -\\frac{\\nabla f(a)}{||\\nabla f(a)||}\\).</li> <li>It remains unchanged when \\(f_u = 0\\) or \\(\\theta = \\frac{\\pi}{2}\\). It is orthogonal or perpendicular to \\(\\nabla f(a)\\).</li> </ul>"},{"location":"MATHS2/10.01%20-%20Directional%20ascent%20%26%20descent/#example","title":"Example","text":"<ul> <li> <p>\\(f(x,y) = \\sin(xy)\\)</p> </li> <li> <p>\\(\\nabla f(a) = (y\\cos(xy),x\\cos(xy))\\)</p> </li> <li>At \\((\\pi,1)\\)</li> <li>\\(\\nabla f(\\pi,1) = (1 \\cos(\\pi), \\pi \\cos(\\pi)) = (-1,\\pi)\\)</li> <li> <p>\\(u = \\frac{\\nabla f(\\pi,1)}{||\\nabla f(\\pi,1)||} = \\frac{-1,\\pi}{\\sqrt{1^2 + \\pi^2}} = \\frac{1}{\\sqrt{\\pi^2 + 1}} \\cdot (1,\\pi)\\)</p> </li> <li> <p>\\(f(x,y,z) = x^2 + y^2 +z^2\\)</p> </li> <li>\\(\\nabla f(a) = (2x,2y,2z)\\)</li> <li>At $(1,1,1) what is the direction in which the function increases fastest?</li> <li>\\(\\nabla f(1,1,1) = (2,2,2)\\)</li> <li>\\(u = \\frac{(2,2,2)}{\\sqrt{2^2 + 2^2 + 2^2}} = \\frac{1}{\\sqrt{12}}(2,2,2)\\)</li> </ul>"},{"location":"MATHS2/10.02%20-%20Tangets%20of%20scalared-valued%20multivariable%20functions/","title":"Tangents for \\(f(x,y)\\)","text":"<ul> <li>Let \\(f(x,y)\\) be a function defined on a domain in \\(D\\) in \\(\\mathbb{R}^2\\) containing some open ball around the point \\(a\\).</li> <li>Consider a line \\(L\\) in \\(D\\) passing through \\(a\\) and restrict \\(f\\) to \\(L\\).</li> <li>Sicne it now a function of one variable, we can consider the tanget to \\(f\\) at \\(a\\) over \\(L\\).</li> <li>If the line \\(L\\) is in the direction of the unit vector \\(u\\), then the tangent (if it exists) is given by \\(f_u(a)\\) passing through the point \\((a,f(a))\\).</li> </ul>"},{"location":"MATHS2/10.02%20-%20Tangets%20of%20scalared-valued%20multivariable%20functions/#equations-of-the-tangent-line","title":"Equations of the tangent line","text":"<ul> <li>\\(u = (u_1,u_2)\\) is a unit vector in the direction of the tangent line.</li> <li>\\(a = (a,b)\\) is the point on the tangent line.</li> <li>\\(f_u(a)\\) is the directional derivative at \\(a\\) in the direction of \\(u\\).</li> <li>\\(L : z = 0, u_1(y-b) = u_2(x-a)\\)</li> <li>\\(P : u_1(y-b) = u_2(x-a)\\)</li> <li>\\(x(t) = a + tu_1\\)</li> <li>\\(y(t) = b + tu_2\\)</li> <li>\\(z(t) = 0\\)</li> <li>\\((x(t),y(t),z(t)) = (a + tu_1, b + tu_2, 0)\\)</li> <li>Parametric equation of the tangent line is \\(P(t) = (a + tu_1, b + tu_2, f(a,b) + tf_u(a,b))\\)</li> </ul>"},{"location":"MATHS2/10.02%20-%20Tangets%20of%20scalared-valued%20multivariable%20functions/#example","title":"Example","text":"<ul> <li>\\(f(x,y) = x + y;\\) tangent at \\((1,1)\\) in the direction of \\((1,0)\\)</li> <li>\\(f_u(a) = \\nabla f \\cdot u = 1\\)</li> <li>\\((x(t),y(t),z(t)) = (1 + t, 1, 1 + tf_u(1,1)) = (1 + t, 1, 2 + t)\\)</li> <li>\\(f(x,y) = xy;\\) tangent at \\((1,1)\\) in the direction of \\((3,4)\\)</li> <li>\\(u = (\\frac{3}{5},\\frac{4}{5})\\)</li> <li>\\(f_u(1,1) = 1 \\cdot \\frac{3}{5} + 1 \\cdot \\frac{4}{5} = \\frac{7}{5}\\)</li> <li>\\((x(t),y(t),z(t)) = (1 + \\frac{3}{5}t, 1 + \\frac{4}{5}t, 1 + \\frac{7}{5}t)\\)</li> </ul>"},{"location":"MATHS2/10.02%20-%20Tangets%20of%20scalared-valued%20multivariable%20functions/#tangents-for-scalared-valued-multivariable-functions","title":"Tangents for scalared-valued multivariable functions","text":"<ul> <li>Let \\(f(x_1,x_2, \\dots, x_n)\\) be a function defined on a domain in \\(D\\) in \\(\\mathbb{R}^n\\) containing some open ball around the point \\(a\\).</li> <li>Consider a line \\(L\\) in \\(D\\) passing through \\(a\\) and restrict \\(f\\) to \\(L\\).</li> <li>Computing this is same as computing it for \\(R^2\\).</li> </ul>"},{"location":"MATHS2/10.03%20-%20Finding%20the%20tangent%20Hyper%28plane%29/","title":"Collection of all the tangents","text":"<ul> <li>Let \\(f(x,y)\\) be a fucntion defined on a domain \\(D\\) in \\(\\mathbb{R}^2\\) containing some open ball around the point \\((a,b)\\).</li> <li>Suppose \\(\\nabla f\\) exists and is continuous on some open ball around the point \\((a,b)\\).</li> <li>Then all the tangent line at the point \\((a,b)\\) exists and we can rewrite the equation of a tangent line the direction of the unit vector \\(u\\) as:   \\(\\(\\begin{align} f_u(a,b) &amp;= \\nabla f \\cdot u \\\\ &amp;= u_1 \\frac{\\partial f}{\\partial x} + u_2 \\frac{\\partial f}{\\partial y} \\end{align}\\)\\)</li> </ul>"},{"location":"MATHS2/10.03%20-%20Finding%20the%20tangent%20Hyper%28plane%29/#tangents-in-terms-of-linear-algebra-for-fxy","title":"Tangents in terms of linear algebra for \\(f(x,y)\\)","text":"<ul> <li>\\((x(t),y(t),z(t)) = (a + tu_1, b + tu_2, f(a,b) + tf_u(a,b))\\)</li> <li>Tangent line to \\(f\\) at \\((a,b)\\) in the direction of \\(u\\) is given by \\((a,b,f(a,b)) + W\\) \\(\\(z = f(a,b) + \\frac{\\partial f}{\\partial x}(a,b)(x-a) + \\frac{\\partial f}{\\partial y}(a,b)(y-b)\\)\\)</li> </ul>"},{"location":"MATHS2/10.03%20-%20Finding%20the%20tangent%20Hyper%28plane%29/#the-tangent-hyperplane","title":"The tangent hyperplane","text":"<ul> <li>Let \\(f(x_1,x_2, \\dots, x_n)\\) be a function defined on a domain \\(D\\) in \\(\\mathbb{R}^n\\) containing some open ball around the point \\(a\\).</li> <li>Suppose \\(\\nabla f\\) exists and is continuous on some open ball around the point \\(a\\).</li> </ul>"},{"location":"MATHS2/10.03%20-%20Finding%20the%20tangent%20Hyper%28plane%29/#linear-approximation","title":"Linear Approximation","text":"<ul> <li>Let \\(f(x_1,x_2, \\dots, x_n)\\) be a function defined on a domain \\(D\\) in \\(\\mathbb{R}^n\\) containing some open ball around the point \\(a\\).</li> <li>Suppose \\(\\nabla f\\) exists and is continuous on some open ball around the point \\(a\\).</li> <li>Then the function:   \\(\\(L_f(x) = f(a) + \\nabla f \\cdot (x-a)\\)\\)</li> </ul>"},{"location":"MATHS2/10.04%20-%20Points%20of%20local%20extrema%20for%20multivariable%20functions/","title":"Points of local extrema for multivariable functions","text":"<ul> <li>Let \\(f(x)\\) be a function defined on a domain \\(D\\) in \\(\\mathbb{R}^n\\) containing some open ball around the point \\(a\\).</li> <li>The point \\(a\\) is the local maximum (or point of local maximum) of \\(f\\) if for some some open ball \\(B\\) containing \\(a\\), \\(f(x) \\leq f(a)\\) whenever \\(x \\in B \\cap D\\).</li> <li>The point \\(a\\) is the local minimum (or point of local minimum) of \\(f\\) if for some some open ball \\(B\\) containing \\(a\\), \\(f(x) \\geq f(a)\\) whenever \\(x \\in B \\cap D\\).</li> <li>A local extremum (or point of local extremum) of \\(f\\) is a point \\(a\\) such that \\(f\\) is either a local maximum or a local minimum at \\(a\\).</li> </ul>"},{"location":"MATHS2/10.04%20-%20Points%20of%20local%20extrema%20for%20multivariable%20functions/#the-gradient-vector-at-points-of-local-extrema","title":"The gradient vector at points of local extrema","text":"<ul> <li>Let \\(f(x)\\) be a function defined on a domain \\(D\\) in \\(\\mathbb{R}^n\\) containing some open ball around the point \\(a\\) of local extremum.</li> <li>Restrict \\(f\\) to a a line \\(L\\) passing throught \\(a\\) and view it as a fucntion of one variable on \\(L\\).</li> <li>Then \\(a\\) is a local extremum for the restricted function on \\(L\\) and hence the directional derivative of \\(f\\) in the direction of the \\(L\\)(if it exists) at \\(a\\) is zero.</li> <li>In particular, those partial derivatives which exist at \\(a\\) are zero.</li> </ul>"},{"location":"MATHS2/10.04%20-%20Points%20of%20local%20extrema%20for%20multivariable%20functions/#critical-points","title":"Critical points","text":"<ul> <li>A point \\(a\\) is called a critical point of a function \\(f(x)\\) if either \\(\\nabla f(a)\\) does not exist or \\(\\nabla f(a) = 0\\).</li> </ul>"},{"location":"MATHS2/10.04%20-%20Points%20of%20local%20extrema%20for%20multivariable%20functions/#example","title":"Example","text":"<ul> <li>Critical Points of \\(f(x,y) = x^2 + 6xy + 4y^2 + 2x - 4y\\)</li> <li>\\(\\frac{\\partial f}{\\partial x} = 2x + 6y + 2 = 0\\)</li> <li>\\(\\frac{\\partial f}{\\partial y} = 6x + 8y - 4 = 0\\)</li> <li>\\(\\nabla f(a) = (0,0)\\)</li> <li>\\(\\nabla f(x,y) = (2x + 6y + 2, 6x + 8y - 4) = (0,0)\\)</li> <li>Using Gaussian elimination, we get \\(x = 2\\) and \\(y = -1\\).</li> <li>Therefore, \\((2,-1)\\) is a critical point of \\(f(x,y)\\).</li> </ul>"},{"location":"MATHS2/11.01%20-%20Higher%20order%20partial%20derivatives%20and%20Hessian%20matrix/","title":"Second order partial derivatives for \\(f(x,y)\\)","text":"<ul> <li>Let \\(f(x,y)\\) be a function of two variables.</li> <li>Then the second order partial derivatives for \\(f\\) are the partial derivatives of the first order partial derivatives.</li> <li> \\[   \\begin{align} f_{xx} &amp;=(fx)x &amp;= \\frac{\\partial^2 f}{\\partial x^2}   \\\\ f_{xy} &amp;=(fx)y &amp;= \\frac{\\partial^2 f}{\\partial y \\partial x}   \\\\ f_{yx} &amp;=(fy)x &amp;= \\frac{\\partial^2 f}{\\partial x \\partial y}   \\\\ f_{yy} &amp;=(fy)y &amp;= \\frac{\\partial^2 f}{\\partial y^2} \\end{align}   \\] </li> </ul>"},{"location":"MATHS2/11.01%20-%20Higher%20order%20partial%20derivatives%20and%20Hessian%20matrix/#example","title":"Example","text":"<ul> <li>\\(f(x,y) = x+y\\)</li> <li>\\(\\frac{\\partial f}{\\partial x} = 1\\)</li> <li>\\(\\frac{\\partial f}{\\partial y} = 1\\)</li> <li>\\(f_{xx} = \\frac{\\partial^2 f}{\\partial x^2} = 0\\)</li> <li>\\(f_{xy} = \\frac{\\partial^2 f}{\\partial y \\partial x} = 0\\)</li> <li>\\(f(x,y) = sin(xy)\\)</li> <li>\\(\\frac{\\partial f}{\\partial x} = y\\cos(xy)\\)</li> <li>\\(\\frac{\\partial f}{\\partial y} = x\\cos(xy)\\)</li> <li>\\(f_{xx} = \\frac{\\partial^2 f}{\\partial x^2} = -y^2\\sin(xy)\\)</li> <li>\\(f_{xy} = \\frac{\\partial^2 f}{\\partial y \\partial x} = -xy\\sin(xy)\\)</li> <li>\\(f_{yx} = \\frac{\\partial^2 f}{\\partial x \\partial y} = -yx\\sin(xy)\\)</li> <li>\\(f_{yy} = \\frac{\\partial^2 f}{\\partial y^2} = -x^2\\sin(xy)\\)</li> </ul>"},{"location":"MATHS2/11.01%20-%20Higher%20order%20partial%20derivatives%20and%20Hessian%20matrix/#clairauts-theorem","title":"Clairaut's Theorem","text":"<ul> <li>Let \\(f(x,y)\\) be a function defined on a domain in \\(D\\) in \\(\\mathbb{R}^2\\) containing some open ball around the point \\(a\\).</li> <li>If the second order partial derivatives \\(f_{xy}\\) or \\(f_{yx}\\) are continuous on some open ball around the point \\(a\\) then \\(f_{xy} = f_{yx}\\).</li> </ul>"},{"location":"MATHS2/11.01%20-%20Higher%20order%20partial%20derivatives%20and%20Hessian%20matrix/#higher-order-partial-derivatives","title":"Higher order partial derivatives","text":"<ul> <li>Let \\(f(x_1,x_2, \\dots, x_n)\\) be a function defined on a domain D in \\(\\mathbb{R}^n\\). Then the higher order partial derivatives of \\(f\\) are defined by taking successive partial derivatives of \\(f\\).   $$ f_{x_1x_2 \\dots x_n} = \\frac{\\partial^4 f}{\\partial x_1 \\partial x_2 \\dots \\partial x_n} $$</li> <li>An appropriately modified statement of Clairaut's theorem holds.</li> </ul>"},{"location":"MATHS2/11.01%20-%20Higher%20order%20partial%20derivatives%20and%20Hessian%20matrix/#hessian-matrix","title":"Hessian matrix","text":"<ul> <li>Let \\(f(x_1,x_2, \\dots, x_n)\\) be a function defined on a domain D in \\(\\mathbb{R}^n\\).</li> <li>Then the Hessian matrix of \\(f\\) is defined has   \\(\\(\\begin{bmatrix} f_{xx} &amp; f_{xy} &amp; \\dots &amp; f_{x_n} \\\\ f_{yx} &amp; f_{yy} &amp; \\dots &amp; f_{y_n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ f_{n_1x} &amp; f_{n_1y} &amp; \\dots &amp; f_{n_1n} \\end{bmatrix}\\)\\)</li> </ul>"},{"location":"MATHS2/11.01%20-%20Higher%20order%20partial%20derivatives%20and%20Hessian%20matrix/#example_1","title":"Example","text":"<ul> <li>\\(f (x,y,z) = xy + yz + xz\\)</li> <li>\\(\\begin{bmatrix} f_{xx} &amp; f_{xy} &amp; f_{xz} \\\\ f_{yx} &amp; f_{yy} &amp; f_{yz} \\\\ f_{zx} &amp; f_{zy} &amp; f_{zz} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\end{bmatrix}\\)</li> </ul>"},{"location":"MATHS2/11.02%20-%20Hessian%20matrix%20and%20local%20extrema/","title":"Hessian Test : Classifying Critical Points for \\(f(x,y)\\)","text":"<ul> <li>Let \\(f(x,y)\\) be a function defined on a domain \\(D\\) in \\(\\mathbb{R}^2\\).</li> <li>Let \\(a\\) be a critical point of \\(f\\) such that the first and second order partial derivatives are continuous in an open ball around \\(a\\).</li> <li> <p>Then the Hessian test can be applied to check the nature of the critical point \\(a\\).</p> </li> <li> <p>If \\(det(Hf(a)) &gt; 0\\) and \\(f_{xx}(a) &gt; 0\\) then \\(a\\) is a local minimum.</p> </li> <li>If \\(det(Hf(a)) &gt; 0\\) and \\(f_{xx}(a) &lt; 0\\) then \\(a\\) is a local maximum.</li> <li>If \\(det(Hf(a)) &lt; 0\\) then \\(a\\) is a saddle point.</li> <li>If \\(det(Hf(a)) = 0\\) then \\(a\\) then the test is inconclusive.</li> </ul>"},{"location":"MATHS2/11.02%20-%20Hessian%20matrix%20and%20local%20extrema/#hessian-test-classifying-critical-points-for-fxyz","title":"Hessian Test : Classifying Critical Points for \\(f(x,y,z)\\)","text":"<ul> <li>Let \\(f(x,y,z)\\) be a function defined on a domain \\(D\\) in \\(\\mathbb{R}^3\\).</li> <li>Let \\(a\\) be a critical point of \\(f\\) such that the first and second order partial derivatives are continuous in an open ball around \\(a\\).</li> <li>Then the Hessian test can be applied to check the nature of the critical point \\(a\\).</li> <li>If \\(f_{xx}(a) &gt; 0, (f_{xx}f_{yy}-f_{xy}^2)(a) &gt; 0\\) and \\(det(Hf(a)) &gt; 0\\) then \\(a\\) is a local minimum.</li> <li>If \\(f_{xx}(a) &lt; 0, (f_{xx}f_{yy}-f_{xy}^2)(a) &gt; 0\\) and \\(det(Hf(a)) &lt; 0\\) then \\(a\\) is a local maximum.</li> <li>For all other cases where the determinant of the Hessian \\(\\neq 0\\) then it is a saddle point.</li> <li>If \\(det(Hf(a)) = 0\\) then \\(a\\) then the test is inconclusive.</li> </ul>"},{"location":"MATHS2/11.04%20-%20Differentiablity%20for%20Multvariable%20Functions/","title":"Differenability for Scalar-Value Multivariable Functions","text":"<ul> <li>Let \\(f\\) be a scalar-valued multivariable function defined on a domain \\(D\\) in \\(\\mathbb{R}^n\\) containing some open ball around the point \\(a\\).</li> <li>Then \\(f\\) is differentiable at \\(a\\) if:   \\(\\(\\lim_{h \\to 0} \\frac{f(a+h) - f(a)-h\\cdot\\nabla f(a)}{||h||}=0   \\tag{1}\\)\\)</li> <li>If \\(f\\) is differentiable at \\(a\\), then</li> <li>Tangent Hyperplane to \\(f\\) at \\(a\\) exists</li> <li>Best linear approximation of \\(f\\) at \\(a\\) is given by the tangent hyperplane</li> <li>It is continuous at \\(a\\)</li> </ul>"},{"location":"MATHS2/2.01%20-%20Cramer%27s%20Rule/","title":"Cramer's Rule","text":"<p>Cramer's rule is a formula for solving systems of linear equations using determinants. It expresses the solution for a particular variable in terms of the determinants of matrices derived from the coefficients of the equations and their corresponding constants.</p>"},{"location":"MATHS2/2.01%20-%20Cramer%27s%20Rule/#forumla","title":"Forumla","text":""},{"location":"MATHS2/2.01%20-%20Cramer%27s%20Rule/#cramers-rule-for-2x2-systems","title":"Cramer's Rule for 2x2 Systems","text":"<ul> <li>\\(\\begin{align}    A &amp;= \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\end{bmatrix}  &amp; B &amp;= \\begin{bmatrix} e  \\\\ f  \\end{bmatrix} \\end{align}\\)</li> <li> <p>\\(\\begin{align}    A_{x1} &amp;= \\begin{bmatrix} e &amp; b \\\\ f &amp; d \\end{bmatrix} &amp; A_{x2} &amp;= \\begin{bmatrix} a &amp; e \\\\ c &amp; f \\end{bmatrix} \\end{align}\\)</p> </li> <li> <p>\\(\\begin{align}      x_1 &amp;= \\frac{\\det(A_{x1})}{\\det(A)} &amp; x_2 &amp;= \\frac{\\det(A_{x2})}{\\det(A)}   \\end{align}\\)</p> </li> </ul> <p>This is how we find the solution to a system of linear equations using Cramer's rule.</p>"},{"location":"MATHS2/2.01%20-%20Cramer%27s%20Rule/#cramers-rule-for-3x3-systems","title":"Cramer's Rule for 3x3 Systems","text":"<ul> <li>\\(\\begin{align}   A &amp;= \\begin{bmatrix} a &amp; b &amp; c \\\\ d &amp; e &amp; f \\\\ g &amp; h &amp; i \\end{bmatrix} &amp; B &amp;= \\begin{bmatrix} j  \\\\ k  \\\\ l \\end{bmatrix} \\end{align}\\)</li> <li>\\(\\begin{align}   A_{x1} &amp;= \\begin{bmatrix} j &amp; b &amp; c \\\\ k &amp; e &amp; f \\\\ l &amp; h &amp; i \\end{bmatrix} &amp; A_{x2} &amp;= \\begin{bmatrix} a &amp; j &amp; c \\\\ d &amp; k &amp; f \\\\ g &amp; l &amp; i \\end{bmatrix} &amp; A_{x3} &amp;= \\begin{bmatrix} a &amp; b &amp; j \\\\ d &amp; e &amp; k \\\\ g &amp; h &amp; l \\end{bmatrix}   \\end{align}\\)</li> <li>\\(\\begin{align}     x_1 &amp;= \\frac{\\det(A_{x1})}{\\det(A)} &amp; x_2 &amp;= \\frac{\\det(A_{x2})}{\\det(A)} &amp; x_3 &amp;= \\frac{\\det(A_{x3})}{\\det(A)}   \\end{align}\\)</li> </ul> <p>Note</p> <ul> <li>A 3x3 matrix is invertible if the determinant is not equal to 0.</li> <li>If the determinant is not equal to 0, then the inverse of the matrix is equal to the adjoint divided by the determinant.</li> </ul>"},{"location":"MATHS2/2.02%20-%20Solutions%20to%20a%20system%20of%20linear%20equations%20with%20invertible%20coefficient/","title":"Invertible Coefficient Matrix","text":"<p>Let \\(A\\) be a \\(n \\times n\\) matrix with \\(det(A) \\neq 0\\). The Inverse of \\(A\\) is \\(B\\) such that \\(AB = BA = I\\).</p> <p>Example</p> <ul> <li>\\(\\begin{align} A &amp;= \\begin{bmatrix} 4 &amp; 7 \\\\ 2 &amp; 6 \\end{bmatrix} &amp; B &amp;= \\begin{bmatrix} 0.6 &amp; -0.7 \\\\ -0.2 &amp; 4 \\end{bmatrix} \\end{align}\\)</li> <li>\\(A \\times B = \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} = B \\times A\\)</li> </ul>"},{"location":"MATHS2/2.02%20-%20Solutions%20to%20a%20system%20of%20linear%20equations%20with%20invertible%20coefficient/#the-adjugate-of-a-matrix","title":"The Adjugate of a matrix","text":"<p>The adjugate of a matrix is the transpose of the cofactor matrix.</p>"},{"location":"MATHS2/2.02%20-%20Solutions%20to%20a%20system%20of%20linear%20equations%20with%20invertible%20coefficient/#adjugate-of-a-2-times-2-matrix","title":"Adjugate of a \\(2 \\times 2\\) matrix","text":"<ul> <li>\\(A = \\begin{bmatrix} 1 &amp; 2 \\\\ 3 &amp; 4 \\end{bmatrix}\\)</li> <li>Calculate the cofactor matrix of \\(A\\).</li> <li>\\(C = \\begin{bmatrix} 4 &amp; -3 \\\\ -2 &amp; 1 \\end{bmatrix}\\)</li> <li>Now, calculate the transpose of \\(C\\).</li> <li>\\(C^T = \\begin{bmatrix} 4 &amp; -2 \\\\ -3 &amp; 1 \\end{bmatrix}\\)</li> <li>The final step is to divide the transpose of the cofactor matrix by the determinant of the original matrix.</li> </ul> <p>\\(\\begin{align}   A^* &amp;= \\frac{1}{det(A)} \\times C^T \\times A \\\\   &amp;= \\frac{1}{-2} \\times \\begin{bmatrix} 4 &amp; -2 \\\\ -3 &amp; 1 \\end{bmatrix} \\times \\begin{bmatrix} 1 &amp; 2 \\\\ 3 &amp; 4 \\end{bmatrix} \\\\   &amp;= \\frac{1}{-2} \\times \\begin{bmatrix} 4 &amp; -2 \\\\ -3 &amp; 1 \\end{bmatrix} \\\\    &amp;= \\begin{bmatrix} -2 &amp; 1 \\\\ 1.5 &amp; -0.5 \\end{bmatrix}   \\end{align}\\)</p>"},{"location":"MATHS2/2.02%20-%20Solutions%20to%20a%20system%20of%20linear%20equations%20with%20invertible%20coefficient/#adjugate-of-a-3-times-3-matrix","title":"Adjugate of a \\(3 \\times 3\\) matrix","text":"<ul> <li>\\(A = \\begin{bmatrix} 1 &amp; 2 &amp; 3 \\\\ 0 &amp; 2 &amp; 8 \\\\ 5 &amp; 6 &amp; 0 \\end{bmatrix}\\)</li> <li>Calculate the cofactor matrix of \\(A\\).</li> <li>\\(C = \\begin{bmatrix} -48 &amp; 40 &amp; -10 \\\\ 18 &amp; -15 &amp; 4 \\\\ 10 &amp; -8 &amp; 2 \\end{bmatrix}\\)</li> <li>Now, calculate the transpose of \\(C\\).</li> <li>\\(C^T = \\begin{bmatrix} -48 &amp; 18 &amp; 10 \\\\ 40 &amp; -15 &amp; -8 \\\\ -10 &amp; 4 &amp; 2 \\end{bmatrix}\\)</li> <li>The final step is to divide the transpose of the cofactor matrix by the determinant of the original matrix.</li> <li>Formula for the adjugate of a matrix:</li> </ul> \\[A^* = \\frac{1}{det(A)} \\times C^T \\times A\\] <p>\\(\\begin{align}   A^* &amp;= \\frac{1}{2} \\times \\begin{bmatrix} -48 &amp; 18 &amp; 10 \\\\ 40 &amp; -15 &amp; -8 \\\\ -10 &amp; 4 &amp; 2 \\end{bmatrix} \\times \\begin{bmatrix} 1 &amp; 2 &amp; 3 \\\\ 0 &amp; 2 &amp; 8 \\\\ 5 &amp; 6 &amp; 0 \\end{bmatrix} \\\\    &amp;= \\begin{bmatrix} -24 &amp; 9 &amp; 5 \\\\ 20 &amp; -7.5 &amp; -4 \\\\ -5 &amp; 2 &amp; 1 \\end{bmatrix} \\times \\begin{bmatrix} 1 &amp; 2 &amp; 3 \\\\ 0 &amp; 2 &amp; 8 \\\\ 5 &amp; 6 &amp; 0 \\end{bmatrix} \\\\    &amp;= \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix}\\\\ \\end{align}\\)</p> <p>Properties of the Adjugate of a matrix</p> <ul> <li>\\(adj(AB) = adj(B) \\times adj(A)\\)</li> <li>\\(adj(AB) = adj(B) \\times adj(A)\\)</li> <li>\\(adj(A+B) = adj(A) + adj(B)\\)</li> <li>\\(adj(A^T) = adj(A)^T\\)</li> <li>\\(adj(A^{-1}) = adj(A)^{-1}\\)</li> </ul>"},{"location":"MATHS2/2.02%20-%20Solutions%20to%20a%20system%20of%20linear%20equations%20with%20invertible%20coefficient/#solution-of-a-system-of-linear-equations-with-invertible-coefficient-matrix","title":"Solution of a system of linear equations with invertible coefficient matrix","text":"<p>Consider the system of linear equations \\(Ax = b\\) where the coefficient matrix \\(A\\) is an invertible matrix.</p> <p>Multiplying both sides by we obtain \\(A^{-1}\\) we obtain:</p> \\[\\begin{align}   Ax &amp;= b \\\\   A^{-1}Ax &amp;= A^{-1}b \\\\   I_n x &amp;= A^{-1}b \\\\    x &amp;= A^{-1}b \\\\ \\end{align}\\] <p>Properties of systems of linear equations</p> <ul> <li>A system of linear equations \\(Ax = b\\) is called a non-homogeneous system of linear equations if \\(b \\neq 0.\\)</li> <li>If \\(v\\) is a solution of the system of linear equations \\(Ax = b\\), then \\(\\frac{1}{c}v\\) is a solutions of linear equation \\(cAx = b\\). where \\(c \\neq 0\\).</li> <li>Let \\(Ax = b\\) be a system of linear equations. If \\(A\\) is invertible, then \\(adj(A)x = b\\) also has a solution.</li> </ul>"},{"location":"MATHS2/2.02%20-%20Solutions%20to%20a%20system%20of%20linear%20equations%20with%20invertible%20coefficient/#the-inverse-of-a-matrix","title":"The Inverse of a matrix","text":"<ul> <li>The inverse of a matrix \\(A\\) is a matrix \\(B\\) such that \\(AB = BA = I\\).</li> <li>The inverse of a matrix \\(A\\) is denoted by \\(A^{-1}\\).</li> <li>We can find the inverse of a matrix by using the adjugate of the matrix.</li> </ul> \\[A^{-1} = \\frac{1}{det(A)} \\times adj(A)\\]"},{"location":"MATHS2/2.03%20-%20The%20Echelon%20form/","title":"Echelon Form","text":""},{"location":"MATHS2/2.03%20-%20The%20Echelon%20form/#definition","title":"Definition","text":"<p>A matrix is in echelon form if it is in row echelon form and has all leading entries in the first column, second column, and so on.</p>"},{"location":"MATHS2/2.03%20-%20The%20Echelon%20form/#row-echelon-form","title":"Row Echelon Form","text":"<ul> <li>The first non-zero element in each row, called the leading entry, is \\(1\\).</li> <li>Each leading entry is in a column to the right of the leading entry in the previous row.</li> <li>Rows with zero elements, if any, are below rows having a non-zero element.</li> <li>For a non-zero row, the leading entry in the row is the only non-zero entry in the column.</li> </ul> <p>Note</p> <p>Suppose for some \\(i\\), \\(i^{th}\\) row of \\(A\\) is a zero row but \\(b_i \\neq 0\\). Then the system of equations \\(Ax=b\\) has no solution.</p> <p>Reason being that if we write the corresponding system of linear equations, the \\(i^{th}\\) equation is</p> <p>\\(0x_1 + 0x_2 + \\cdots + 0x_n = b_i\\). This solution is not possible.</p> <p>Example</p> <ul> <li>\\(A_{ref} = \\begin{bmatrix}         1 &amp; 2 &amp; 3 &amp; 4 \\\\         0 &amp; 0 &amp; 1 &amp; 3 \\\\         0 &amp; 0 &amp; 0 &amp; 1 \\\\         \\end{bmatrix}\\)</li> <li>\\(A\\) is in row echelon form.</li> <li>Converting \\(A\\) to reduced row echelon form:</li> <li>\\(A_{rref} = \\begin{bmatrix}         1 &amp; 2 &amp; 0 &amp; 0 \\\\         0 &amp; 0 &amp; 1 &amp; 0 \\\\         0 &amp; 0 &amp; 0 &amp; 1 \\\\         \\end{bmatrix}\\)</li> <li>\\(A\\) is in reduced row echelon form.</li> </ul>"},{"location":"MATHS2/2.03%20-%20The%20Echelon%20form/#dependency","title":"Dependency","text":"<p>Let \\(Ax=b\\) where \\(A\\) is in the form of \\(A_{rref}\\). Assume that for every zero row of \\(A\\), \\(b_i = 0\\).</p> <ul> <li>If the \\(i^{th}\\) column has the leading entry of some row, we call \\(x_i\\) a dependent variable.</li> <li>If the \\(i^{th}\\) column has no leading entry, we call \\(x_i\\) an independent variable.</li> </ul> <p>Example</p> <ul> <li>\\(A = \\begin{bmatrix}         1 &amp; 2 &amp; 3 &amp; 4 \\\\         0 &amp; 0 &amp; 1 &amp; 3 \\\\         0 &amp; 0 &amp; 0 &amp; 1 \\\\         \\end{bmatrix}\\)</li> <li>\\(A\\) is in reduced row echelon form.</li> <li>In this case, \\(\\mathbf{x_1}\\), \\(\\mathbf{x_3}\\) and \\(\\mathbf{x_4}\\) are dependent variables and \\(\\mathbf{x_2}\\) is an independent variable.</li> </ul>"},{"location":"MATHS2/2.04%20-%20Row%20Reduction/","title":"Elementry Row Operations","text":""},{"location":"MATHS2/2.04%20-%20Row%20Reduction/#operations","title":"Operations","text":"TYPE ACTION EXAMPLE AND NOTATION Description 1 Interchange two rows \\(R_1 \\leftrightarrow R_2\\) Interchanging \\(R_1\\) and \\(R_2\\) 2 Scalar multiplication of a row by constant \\(t\\) \\(kR_1 \\rightarrow R_1\\) Multiplying Row 1 with constant \\(k\\) 3 Add a multiple of one row to another row \\(R_1 (+/-) kR_2\\) Adding or subtracting \\(k \\times R_2\\) from \\(R_1\\)"},{"location":"MATHS2/2.04%20-%20Row%20Reduction/#what-are-these-operations-used-for","title":"What are these operations used for?","text":""},{"location":"MATHS2/2.04%20-%20Row%20Reduction/#row-reduction-row-echelon-form","title":"Row Reduction: Row Echelon Form","text":"<ul> <li>Row reduction is a sequence of elementry row operations that transforms a matrix into row echelon form.</li> <li>\\(A = \\begin{bmatrix}       3 &amp; 2 &amp; 1 &amp; 1 \\\\       1 &amp; 1 &amp; 0 &amp; 0 \\\\       0 &amp; 7 &amp; 1 &amp; 1 \\\\       \\end{bmatrix}\\)</li> <li>To get the \\(rref\\) of the matrix \\(A\\) we need to reduce the first element to \\(1\\). This can be done by multiplying the first row by \\(1/3\\).</li> <li>So the first operation is \\(R_1/3\\).</li> <li>\\(A = \\begin{bmatrix}       1 &amp; 2/3 &amp; 1/3 &amp; 1/3 \\\\       1 &amp; 1 &amp; 0 &amp; 0 \\\\       0 &amp; 7 &amp; 1 &amp; 1 \\\\       \\end{bmatrix}\\)</li> <li>Now we need to make the second element of the second row \\(0\\). This can be done by subtracting \\(1\\) times the first row from the second row.</li> <li>So the second operation is \\(R_2 - R_1\\).</li> <li>\\(A = \\begin{bmatrix}       1 &amp; 2/3 &amp; 1/3 &amp; 1/3 \\\\       0 &amp; 1/3 &amp; -1/3 &amp; -1/3 \\\\       0 &amp; 7 &amp; 1 &amp; 1 \\\\       \\end{bmatrix}\\)</li> <li>Now we want to normalize the second row. This can be done by multiplying the second row by \\(3\\).</li> <li>So the third operation is \\(3R_2\\).</li> <li>\\(A = \\begin{bmatrix}       1 &amp; 2/3 &amp; 1/3 &amp; 1/3 \\\\       0 &amp; 1 &amp; -1 &amp; -1 \\\\       0 &amp; 7 &amp; 1 &amp; 1 \\\\       \\end{bmatrix}\\)</li> <li>Now we want to make the third element of the third row \\(0\\). This can be done by subtracting \\(7\\) times the second row from the third row.</li> <li>So the fourth operation is \\(R_3 - 7R_2\\).</li> <li>\\(A = \\begin{bmatrix}       1 &amp; 2/3 &amp; 1/3 &amp; 1/3 \\\\       0 &amp; 1 &amp; -1 &amp; -1 \\\\       0 &amp; 0 &amp; 8 &amp; 8 \\\\       \\end{bmatrix}\\)</li> <li>Now we want to normalize the third row. This can be done by multiplying the third row by \\(1/8\\).</li> <li>So the fifth operation is \\(R_3/8\\).</li> <li>\\(A = \\begin{bmatrix}       1 &amp; 2/3 &amp; 1/3 &amp; 1/3 \\\\       0 &amp; 1 &amp; -1 &amp; -1 \\\\       0 &amp; 0 &amp; 1 &amp; 1 \\\\       \\end{bmatrix}\\)</li> <li>Now we want to set all the values above the leading one to \\(0\\). This can be done by subtracting \\(1\\) times the third row from the first row.</li> <li>So the sixth operation is \\(R_2 - R_3 \\text{ and } R_1 - \\frac{1}{3}R_3\\).</li> <li>\\(A = \\begin{bmatrix}       1 &amp; 2/3 &amp; 0 &amp; 0 \\\\       0 &amp; 1 &amp; 0 &amp; 0 \\\\       0 &amp; 0 &amp; 1 &amp; 1 \\\\       \\end{bmatrix}\\)</li> <li>Final Step is remove the leading zeros. This can be done by subtracting \\(2/3\\) times the second row from the first row.</li> <li>So the seventh operation is \\(R_1 - \\frac{2}{3}R_2\\).</li> <li>\\(A = \\begin{bmatrix}       1 &amp; 0 &amp; 0 &amp; 0 \\\\       0 &amp; 1 &amp; 0 &amp; 0 \\\\       0 &amp; 0 &amp; 1 &amp; 1 \\\\       \\end{bmatrix}\\)</li> <li>So we used the Row Operations to get the \\(rref\\) of the matrix \\(A\\).</li> </ul> <p>Note</p> <p>After all the row and column operations the determinant of the matrix always remains the same.</p>"},{"location":"MATHS2/2.05%20-%20Gaussian%20elemination/","title":"Gaussian Elimination","text":""},{"location":"MATHS2/2.05%20-%20Gaussian%20elemination/#augmented-matrix","title":"Augmented Matrix","text":"<ul> <li>Let \\(Ax = b\\) be a system of linear equations where \\(A\\) is an \\(m \\times n\\) matrix and \\(b\\) is an \\(m \\times 1\\) matrix.</li> <li>The augmented matrix of \\(A\\) and \\(b\\) is the \\(m \\times (n+1)\\) matrix \\([A|b]\\).</li> </ul> <p>Example</p> <p>Lets say for a system of linear equations:</p> <p>\\(\\begin{alignedat}{4}         3x_1 &amp; {}+{} &amp; 2x_2 &amp; {}+{} &amp; x_3 &amp; {}+{} &amp; x_4 &amp;= 6 \\\\         x_1 &amp; {}+{} &amp; x_2 &amp;         &amp;     &amp;       &amp;     &amp;= 2 \\\\         &amp;       &amp;  7x_2 &amp; {}+{} &amp; x_3 &amp; {}+{} &amp; x_4  &amp;= 8   \\end{alignedat}\\)</p> <ul> <li> <p>Matrix \\(A = \\begin{bmatrix}       3 &amp; 2 &amp; 1 &amp; 1 \\\\       1 &amp; 1 &amp; 0 &amp; 0 \\\\       0 &amp; 7 &amp; 1 &amp; 1 \\\\       \\end{bmatrix}\\)</p> </li> <li> <p>Matrix \\(b = \\begin{bmatrix}     6 \\\\     2 \\\\     8 \\\\     \\end{bmatrix}\\)</p> </li> <li>Augmented matrix \\(= [A|b] = \\left[ \\begin{array}{cccc|c}     3 &amp; 2 &amp; 1 &amp; 1 &amp; 6 \\\\     1 &amp; 1 &amp; 0 &amp; 0 &amp; 2 \\\\     0 &amp; 7 &amp; 1 &amp; 1&amp; 8 \\\\     \\end{array} \\right]\\)</li> </ul>"},{"location":"MATHS2/2.05%20-%20Gaussian%20elemination/#gaussian-elimination","title":"Gaussian Elimination","text":"<p>Gaussian elimination is a method for solving a system of linear equations.</p>"},{"location":"MATHS2/2.05%20-%20Gaussian%20elemination/#algorithm","title":"Algorithm","text":"<ul> <li>Form the augmented matrix \\([A|b]\\).</li> <li>Perform the following steps until the augmented matrix is in reduced row echelon form.</li> <li>Apply elementary row operations on both sides of the augmented matrix.</li> <li>It is ok if the \\(b\\) column is not in reduced row echelon form.</li> <li>Let \\(R\\) be the submatrix of the obtained matrix of the frist \\(n\\) columns and \\(c\\) be the submatrix of the obtained matrix consisting of the last column.</li> <li>We write the obtained matrix as \\([R|c]\\).</li> <li>The solutions of \\(Ax=b\\) are precisely the values of solutions of \\(Rx=c\\).</li> </ul> <p>Note</p> <p>If there are zero rows in the augmented matrix, then the system has no solutions.</p> <p>Example</p> <ul> <li>\\(A = \\left[\\begin{array}{cccc|c}         3 &amp; 2 &amp; 1 &amp; 1 &amp; 6 \\\\         1 &amp; 1 &amp; 0 &amp; 0 &amp; 2 \\\\         0 &amp; 7 &amp; 1 &amp; 1&amp; 8 \\\\         \\end{array} \\right]\\)</li> <li>\\(A\\) is not in reduced row echelon form.</li> <li>\\(R_1/3\\):<ul> <li>\\(A = \\left[ \\begin{array}{cccc|c}       1 &amp; \\frac{2}{3} &amp; \\frac{1}{3} &amp; \\frac{1}{3} &amp; 2 \\\\       1 &amp; 1 &amp; 0 &amp; 0 &amp; 2 \\\\       0 &amp; 7 &amp; 1 &amp; 1 &amp; 8 \\\\       \\end{array} \\right]\\)</li> </ul> </li> <li> <p>\\(R_2 - R_1\\):</p> <ul> <li>\\(A = \\left[\\begin{array}{cccc|c}   1 &amp; \\frac{2}{3} &amp; \\frac{1}{3} &amp; \\frac{1}{3} &amp; 2 \\\\       0 &amp; \\frac{1}{3} &amp; -\\frac{1}{3} &amp; -\\frac{1}{3} &amp; 0 \\\\       0 &amp; 7 &amp; 1 &amp; 1&amp; 8 \\\\       \\end{array}\\right]\\)</li> </ul> </li> <li> <p>\\(3R_2\\):</p> <ul> <li>\\(A = \\left[\\begin{array}{cccc|c}       1 &amp; \\frac{2}{3} &amp; \\frac{1}{3} &amp; \\frac{1}{3} &amp; 2 \\\\       0 &amp; 1 &amp; -1 &amp; -1 &amp; 0 \\\\       0 &amp; 7 &amp; 1 &amp; 1&amp; 8 \\\\       \\end{array} \\right]\\)</li> </ul> </li> <li>\\(R_3 - 7R_2\\):<ul> <li>\\(A = \\left[\\begin{array}{cccc|c}       1 &amp; \\frac{2}{3} &amp; \\frac{1}{3} &amp; \\frac{1}{3} &amp; 2 \\\\       0 &amp; 1 &amp; -1 &amp; -1 &amp; 0 \\\\       0 &amp; 0 &amp; 8 &amp; 8 &amp; 8 \\\\       \\end{array} \\right]\\)</li> </ul> </li> <li>\\(R_3/8\\):<ul> <li>\\(A = \\left[\\begin{array}{cccc|c}       1 &amp; \\frac{2}{3} &amp; \\frac{1}{3} &amp; \\frac{1}{3} &amp; 2 \\\\       0 &amp; 1 &amp; -1 &amp; -1 &amp; 0 \\\\       0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\\\       \\end{array}\\right]\\)</li> </ul> </li> <li>\\(R_2 + R_3, R_1 - R_3/3\\)<ul> <li>\\(A = \\left[\\begin{array}{cccc|c}       1 &amp; \\frac{2}{3} &amp; 0 &amp; 0 &amp; \\frac{5}{3} \\\\       0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\\\       0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\\\       \\end{array}\\right]\\)</li> </ul> </li> <li>\\(R_1 - 2/3R_2:\\)<ul> <li>\\(A = \\left[\\begin{array}{cccc|c}       1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\       0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\\\       0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\\\       \\end{array} \\right]\\)</li> </ul> </li> </ul>"},{"location":"MATHS2/2.05%20-%20Gaussian%20elemination/#homogeneous-system-of-linear-equations","title":"Homogeneous System of linear equations","text":"<ul> <li>0 is always a solution of a homogenous system of linear equations.</li> <li>\\(Ax = 0\\) is called a trivial solution.</li> <li>For a homogenous system, there are always \\(2\\) types of possible outcomes:</li> <li>0 is the unqiue solution.</li> <li>There are infinitely many solutions other than 0.</li> <li>In a homogenous system, if there are more variables than equations, then it is guaranteed to have non-trivial solutions.</li> </ul>"},{"location":"MATHS2/3.01%20-%20Vector%20Spaces/","title":"Vectors","text":"<p>Consider two vectors \\((x_1, x_2, \\cdots , x_n)\\) and \\((y_1, y_2, \\cdots , y_n)\\) in \\(\\mathbb{R}^n\\) and \\(c \\in \\mathbb{R}\\).</p> <p>Properties of Vectors</p> <p>Let \\(v, w\\) and \\(v'\\) be vectors in \\(\\mathbb{R}^n\\).</p> <ul> <li>\\(v + w = w + v\\)</li> <li>\\((v + w) + v' = v + (w + v')\\)</li> <li>The \\(0\\) vector satisfies that \\(v + 0 = 0 + v = v\\).</li> <li>The vector \\(-v\\) satisfies that \\(v + (-v) = (-v) + v = 0\\).</li> <li>\\(1 \\cdot v = v\\).</li> <li>\\((ab)v = a(bv)\\).</li> <li>\\(a(v + w) = av + aw\\).</li> <li>\\((a + b)v = av + bv\\).</li> </ul>"},{"location":"MATHS2/3.01%20-%20Vector%20Spaces/#vector-spaces","title":"Vector Spaces","text":"<ul> <li>A vector space is a set with two operations (called addition and scalar multiplication with the first and last properties mentioned above).</li> <li>A vector space \\(V\\) over \\(\\mathbb{R}\\) is a set along with two functions</li> </ul> \\[+ : V \\times V \\rightarrow V \\text{ and } \\cdot : \\mathbb{R} \\times V \\rightarrow V\\] <ul> <li>It is standard to suppress the \\(\\cdot\\)</li> <li>Addition and scalar multiplication on restricts to the solution set. Hence it is a vector space.</li> </ul> <p>Definition of a Vector Space</p> <ul> <li>\\(v_1+ v_2\\) for all \\(v_1, v_2 \\in V\\).</li> <li>\\((v_1 + v_2) + v_3 = v_1 + (v_2 + v_3)\\) for all \\(v_1, v_2, v_3 \\in V\\).</li> <li>There exists a vector \\(0 \\in V\\) such that \\(v + 0 = 0 + v = v\\) for all \\(v \\in V\\).</li> <li>For each element \\(v \\in V\\) there exists an element in \\(v' \\in V\\) such that \\(v + v' = v' + v = 0\\).</li> <li>For each ement in \\(v \\in V\\) , \\(1 \\cdot v = v\\).</li> <li>For each pair of elements \\(a, b \\in \\mathbb{R}\\) and \\(v \\in V\\), \\((ab)v = a(bv)\\).</li> <li>For each element \\(a \\in \\mathbb{R}\\) and each pair of ements \\(v_1\\) and \\(v_2\\) a(\\(v_1 + v_2) = av_1 + av_2\\).</li> <li>For each pair of elements \\(a,b \\in \\mathbb{R}\\) and each element \\(v \\in V\\), \\((a + b)v = av + bv\\).</li> </ul> <p>Example</p> <p>Matricies</p> <ul> <li>Let \\(M_{m \\times n}(\\mathbb{R})\\) be the set of all \\(m \\times n\\) matrices with entries in \\(\\mathbb{R}\\).</li> <li>Addition and scalar multiplication are defined as usual:</li> <li>\\((A + B)_{ij} = A_{ij} + B_{ij}\\)</li> <li>\\((cA)_{ij} = cA_{ij}\\)</li> </ul> <p>Solutions of homogeneous linear equations</p> <ul> <li>Consider the set of solutions \\(V\\) of a homogenous linear equation \\(Ax = 0\\) where \\(A \\in M_{m \\times n}(\\mathbb{R})\\)</li> <li> <p>Nothat that if \\(v, w \\in V\\) then , \\(A(v+w) = Av + Aw = 0 + 0 = 0\\)</p> </li> <li> <p>If \\(c \\in \\mathbb{R}\\) then , \\(A(c \\cdot v) = c(A \\cdot v) = c(0) = 0\\)</p> </li> </ul> <p>Non - Examples</p> <ul> <li>\\((x_1, x_2) + (y_1, y_2) = (x_1 + y_1, x_2 + y_2)\\) is not a vector space. It is not closed under scalar multiplication.</li> <li>\\(c(x_1, x_2) = (cx_1, 0)\\) is not a vector space. It is not closed under addition. it fails under the \\(3^{rd}\\), \\(4^{th}\\) and \\(5^{th}\\) properties.</li> </ul> <p>Cancelation Law of Addition</p> <p>If \\(v_1, v_2, v_3 \\in V\\) and \\(v_1 + v_3 = v_2 + v_3\\) then \\(v_1 = v_2\\). This is called the cancelation law of addition.</p>"},{"location":"MATHS2/3.01%20-%20Vector%20Spaces/#linear-dependence","title":"Linear Dependence","text":"<p>A set of vectors VI, v2, , Vn from a vector space \\(V\\) linearly dependent if there exists scalars \\(a_1, a_2, \\dots , a_n,\\) such that is said to be not all zero.</p> \\[a_1v_1 + a_2v_2 + \\cdots + a_nv_n = 0\\]"},{"location":"MATHS2/3.01%20-%20Vector%20Spaces/#the-0-vector","title":"The 0 Vector","text":"<ul> <li>Let \\(v_1, v_2, \\dots , v_n\\) be a set of vectors containing the zero vector \\(0\\).</li> <li>Suppose \\(v_i = 0\\). Then we can choose \\(a_i = 1\\) and \\(a_j = 0\\) for \\(j \\neq i\\).</li> <li>Then the linear combination \\(a_1v_1 + a_2v_2 + \\cdots + a_nv_n = 0\\) is satisfied.</li> <li>Hence, a set of vectors \\(v_1, v_2, \\dots , v_n\\) containing the \\(0\\) vector is always linearly dependent.</li> </ul>"},{"location":"MATHS2/3.01%20-%20Vector%20Spaces/#linear-independence","title":"Linear Independence","text":"<p>A set of vectors \\(v_1, v_2, \\dots , v_n\\) from a vector space \\(V\\) is said to be linearly independent if no scalar \\(a_1, a_2, \\dots , a_n\\) can be found such that all are zero.</p> \\[a_1v_1 + a_2v_2 + \\cdots + a_nv_n = 0\\] <p>When are two non-zero vectors linearly independent?</p> <ul> <li>Let \\(v_1, v_2\\) be two non-zero vectors in \\(\\mathbb{R}^n\\).</li> <li>Suppose \\(v_1\\) and \\(v_2\\) are linear dependent.</li> <li>Then \\(a_1v_1 + a_2v_2 = 0\\) for some \\(a_1, a_2 \\in \\mathbb{R}\\). and atleast one of \\(a_1, a_2\\) is not zero.</li> <li>Dividing by \\(a_1\\) and putting \\(c = -\\frac{a_2}{a_1}\\) we get \\(v_1 - cv_2 = 0\\)</li> <li>we get \\(v_1 = cv_2\\).</li> <li>Hence \\(v_1\\) is a scalar multiple of \\(v_2\\).</li> <li> <p>We can reverse the implications above and conclude that if \\(v_1\\) and \\(v_2\\) are multiples of each other then they are linearly dependent.</p> </li> <li> <p>If \\(v_1\\) and \\(v_2\\) are linearly independent when \\(v_1\\) and \\(v_2\\) are not multiples of each other.</p> </li> </ul> <p>Example</p> <ul> <li>Consider the two vectors \\((-1,3)\\) and (2,0) in \\(\\mathbb{R}^2\\).</li> <li>Consider the following equation:</li> <li>\\(a(-1,3) + b(2,0) = 0\\)</li> <li>Hence the following linear equation is satisfied:</li> <li>\\(a(-1) + b(2) = 0\\)</li> <li>\\(a(3) + b(0) = 0\\)</li> <li>Hence \\(a = 0\\) and \\(b = 0\\) is the only answer.</li> </ul> <p>When are three vectors Linearly Independent</p> <ul> <li>Let \\(v_1, v_2, v_3\\) be a set of vectors in \\(\\mathbb{R}^n\\).</li> <li>Then \\(a_1v_1 + a_2v_2 + a_3v_3 = 0\\) for some \\(a_1, a_2, a_3 \\in \\mathbb{R}\\) and atleast one of \\(a_1, a_2, a_3\\) is not zero.</li> <li>If \\(a_1 = 0\\) then \\(v_1 = b_2v_2 + b_3v_3\\), where. \\(b_2 = -\\frac{a_2}{a_1}\\) and \\(b_3 = -\\frac{a_3}{a_1}\\). Hence \\(v_1\\) is a linear combination of \\(v_2\\) and \\(v_3\\).</li> <li>Similarly if \\(a_2 \\neq 0\\)</li> <li>Since the implication is true in both directions, we conclude that if \\(v_1, v_2, v_3\\) are linearly independent then \\(v_1\\) is not a linear combination of \\(v_2\\) and \\(v_3\\).</li> <li>Concusion: If \\(v_1, v_2, v_3\\) are linearly independent then non of these vectors is a linear combination of the other two.</li> </ul> <p>Example</p> <ul> <li>Let us consider the vectors \\(v_1 = (1,1,2)\\), \\(v_2 = (1,2,0)\\) and \\(v_3 = (0,2,1)\\) in \\(\\mathbb{R}^3\\).</li> </ul> \\[a(1,1,2) + b(1,2,0) + c(0,2,1) = 0\\] <ul> <li> <p>We get the following equations:</p> </li> <li> <p>\\(a + b = 0\\)</p> </li> <li>\\(a + 2b + 2c= 0\\)</li> <li> <p>\\(2a + c = 0\\)</p> </li> <li> <p>We get \\(a = 0\\), \\(b = 0\\) and \\(c = 0\\).</p> </li> <li>Hence \\(v_1, v_2, v_3\\) are linearly dependent.</li> </ul>"},{"location":"MATHS2/3.01%20-%20Vector%20Spaces/#linear-independence-of-n-vectors","title":"Linear Independence of n Vectors","text":"<ul> <li>Let \\(v_1, v_2, \\dots , v_n\\) be a set of vectors in \\(\\mathbb{R}^m\\).</li> <li>In terms of coordinates, let \\(v_j = (v_{j1}, v_{j2}, \\dots , v_{jm})\\).</li> <li> <p>Let us write the linear combination of these vectors with arbitary coefficients \\(a_1, a_2, \\dots , a_n\\) as: \\(a_1v_1 + a_2v_2 + \\cdots + a_nv_n = 0\\)</p> </li> <li> <p>We get the following equations:</p> <ul> <li>\\(a_1v_{11} + a_2v_{12} + \\cdots + a_nv_{1n} = 0\\)</li> <li>\\(a_1v_{21} + a_2v_{22} + \\cdots + a_nv_{2n} = 0\\)</li> <li>\\(\\vdots\\)</li> <li>\\(a_1v_{n1} + a_2v_{n2} + \\cdots + a_nv_{nm} = 0\\)</li> </ul> </li> <li>For linear independence, we need to find a set of coefficients \\(a_1, a_2, \\dots , a_n\\) such that all the equations are satisfied.</li> <li>We need to check if the only choice of \\(a_i\\)'s satisfying the above identities is \\(a_i = 0\\) for all \\(i\\).</li> <li>Concusion: If \\(v_1, v_2, \\dots , v_n \\in \\mathbb{R}^m\\) are linearly independent, we have to check that the homogeneous system of linear eqautions \\(V_x=0\\) has only trivial solution, where \\(j^{th}\\) column of \\(V\\) is \\(v_j\\).</li> </ul> <p>Example</p> <p>2x2 Matrix</p> <ul> <li>Consider the two vectors \\((5,2) \\text{ and } (1,3)\\) in \\(\\mathbb{R}^2\\). Write the linear combination of these vectors with arbitary coefficients \\(a_1\\) and \\(a_2\\) as:</li> </ul> \\[a_1(5,2) + a_2(1,3) = 0\\] <ul> <li>We get the following equations:</li> <li>\\(5x + y = 0\\)</li> <li>\\(2x + 3y = 0\\)</li> <li>Since the corresponding matrix is:   \\(\\begin{bmatrix} 5 &amp; 1 \\\\ 2 &amp; 3 \\end{bmatrix}\\) is invertible, the system of linear equations has only trivial solution.</li> </ul> <p>3x2 Matrix</p> <ul> <li>Consider the two vectors \\((1,2,0) \\text{ and } (3,3,5)\\) in \\(\\mathbb{R}^3\\). Write the linear combination of these vectors with arbitary coefficients \\(a_1\\) and \\(a_2\\) as:</li> </ul> \\[a_1(1,2,0) + a_2(3,3,5) = 0\\] <ul> <li>We get the following equations:</li> <li>\\(x + 3y = 0\\)</li> <li>\\(2x + 3y = 0\\)</li> <li>\\(5y = 0\\)</li> </ul> <p>2x3 Matrix</p> <ul> <li>Consider the three vectors \\((1,2), (1,3) \\text{ and } (3,4)\\). Equate the linear combination of these vectors with arbitary coefficients \\(a_1, a_2, a_3\\) as:</li> </ul> \\[a_1(1,2) + a_2(1,3) + a_3(3,4) = 0\\] <ul> <li>We get the following equations:</li> <li>\\(1x + 1y + 3z = 0\\)</li> <li>2x + 3y + 4z = 0$</li> <li>We can find the values using gaussian elimination.</li> <li>\\(\\begin{bmatrix} 1 &amp; 1 &amp; 3 \\\\ 2 &amp; 3 &amp; 4 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\)</li> <li>\\(\\begin{bmatrix} 1 &amp; 1 &amp; 3 \\\\ 0 &amp; 1 &amp; -2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\)</li> <li>\\(\\begin{bmatrix} 1 &amp; 1 &amp; 3 \\\\ 0 &amp; 1 &amp; -2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\)</li> <li>We get infinite solutions. Hence the vectors are linearly dependent.</li> </ul> <p>3x3 Matrix</p> <ul> <li>Consider the three vectors \\((1,2,0), (0,2,4) \\text{ and } (3,0,0)\\). Equate the linear combination of these vectors with arbitary coefficients \\(x, y, z\\) as:</li> </ul> \\[x(1,2,0) + y(0,2,4) + z(3,0,0) = 0\\] <ul> <li>We get the following equations:</li> <li>\\(x + 2y = 0\\)</li> <li>\\(2y + 4z = 0\\)</li> <li>\\(3x = 0\\)</li> <li>Since the matrix is \\(\\begin{bmatrix} 1 &amp; 0 &amp; 3 \\\\ 2 &amp; 2 &amp; 0 \\\\ 0 &amp; 4 &amp; 0 \\end{bmatrix}\\) is invertible, the system of linear equations has only trivial solution.</li> </ul>"},{"location":"MATHS2/3.01%20-%20Vector%20Spaces/#more-than-2-vectors-in-mathbbr2","title":"More than 2 vectors in \\(\\mathbb{R}^2\\)","text":"<ul> <li>Suppose we have \\(n\\) vectors in \\(\\mathbb{R}^2\\), where \\(n \\geq 3\\). To check linear independece, we have to check wheater the corresponding homogeneous linear system \\(V_x = 0\\) has only trivial solution.</li> <li>Since \\(n \\geq 3 &gt; 2\\)</li> <li>We also know that gaussian elimination can yeild infinite solutions.</li> <li>Hence, any set of \\(n\\) vectors in \\(\\mathbb{R}^2\\) with \\(n \\geq 3\\) are linearly dependent.</li> </ul>"},{"location":"MATHS2/3.01%20-%20Vector%20Spaces/#relation-between-linear-independence-and-determinant","title":"Relation between Linear Independence and Determinant","text":"<ul> <li>To Check wheater a set of \\(n\\) vectors in \\(\\mathbb{R}^n\\) are linearly independent, we can check wheater the corresponding homogeneous linear system \\(V_x = 0\\) has only trivial solution. Where \\(V\\) is an \\(n \\times n\\) matrix obtained by arranging the vectors as columns.</li> <li>Since \\(V\\) is a square matrix, it has unique solution \\(x=0\\) if and only if \\(V\\) is invertible and it has its \\(det(V) \\neq 0\\).</li> <li>If \\(A\\) is invertible then there exists \\(A^{-1}\\) such that \\(A^{-1}A = I\\). Hence \\(det(A^{-1}A) = det(I) \\neq 0\\).</li> </ul> <p>Example</p> <ul> <li>Let us consider the following matrix \\((1,4,2), (0,4,3) \\text{ and } (1,1,0)\\) in \\(\\mathbb{R}^3\\).</li> <li>Let the matrix be: \\(V = \\begin{bmatrix} 1 &amp; 0 &amp; 1 \\\\ 4 &amp; 4 &amp; 1 \\\\ 2 &amp; 3 &amp; 0 \\end{bmatrix}\\)</li> <li>Since the \\(det(V) = 1\\) and \\(\\neq 0\\), the system of linear equations has only trivial solution. Hence the vectors are linearly independent.</li> </ul>"},{"location":"MATHS2/4.01%20-%20Vector%20Basis/","title":"Vector Basis","text":""},{"location":"MATHS2/4.01%20-%20Vector%20Basis/#_1","title":"Vector Basis","text":""},{"location":"MATHS2/4.01%20-%20Vector%20Basis/#span-of-a-set-of-vectors","title":"Span of a set of vectors","text":"<p>The span of a set \\(S\\) (of vectors) is defined as the set of all finite linear combinations of elements(vectors) of \\(S\\), and denoted by \\(Span(S)\\).</p> \\[Span(S) = \\{ \\sum_{i=1}^n a_i v_i  \\in V|a_1, a_2, \\cdots, a_n \\in \\mathbb{R}\\}\\] <p>Example</p> <ul> <li> <p>Let \\(S = \\{(1,0)\\} \\in \\mathbb{R}^2\\)</p> <ul> <li>\\(Span(S) = \\{a(1,0) | a \\in \\mathbb{R}\\} = \\{(a,0) | a \\in \\mathbb{R}\\}\\)</li> </ul> </li> <li> <p>Let \\(S = \\{(1,1)\\} \\in \\mathbb{R}^2\\)</p> <ul> <li>\\(Span(S) = \\{a(1,1) | a \\in \\mathbb{R}\\} = \\{(a,a) | a \\in \\mathbb{R}\\}\\)</li> </ul> </li> <li> <p>Let \\(S = \\{(1,0,0), (0,1,0)\\} \\in \\mathbb{R}^3\\)</p> <ul> <li>\\(Span(S) = \\{a(1,0,0) + b(0,1,0) | a,b \\in \\mathbb{R}\\} = \\{(a, b, 0) | a,b \\in \\mathbb{R}\\}\\)</li> </ul> </li> </ul>"},{"location":"MATHS2/4.01%20-%20Vector%20Basis/#spaning-set-for-a-vector-space","title":"Spaning set for a vector space","text":"<p>Let \\(V\\) be a vector space. A set \\(S\\) of vectors in \\(V\\) is called a spanning set for \\(V\\) if \\(V = Span(S)\\).</p> <p>Example</p> <ul> <li>If \\(S = \\{(1,0), (0,1)\\}\\), then \\(Span(S) = \\mathbb{R}^2\\).</li> <li>If \\(S = \\{(1,1), (0,1)\\}\\), then \\(Span(S) = \\mathbb{R}^2\\).</li> <li>If \\(S = \\{(1,0,0), (0,1,0), (0,0,1)\\}\\), then \\(Span(S) = \\mathbb{R}^3\\).</li> </ul> <p>Adding vectors to obtain a spanning set for \\(\\mathbb{R}^3\\)</p> <ul> <li>Start with \\(S_0\\) to be the empty set \\(\\emptyset\\).</li> <li>Thus \\(Span(S_0) = \\{(0,0,0)\\}\\).</li> <li>We will add the vector \\((3,0,0)\\) to \\(S_0\\) to obtain \\(S_1\\).</li> <li>Now \\(Span(S_1) = \\{(3,0,0)\\}\\).</li> <li>Now we will add the vector \\((2,2,1)\\) to \\(S_1\\) to obtain \\(S_2\\).</li> <li>This does not cover the entire vector space \\(\\mathbb{R}^3\\).</li> <li>So we add the vector \\((1,3,3)\\) to \\(S_2\\) to obtain \\(S_3\\).</li> <li>So \\(Span(S_3) = \\mathbb{R}^3\\).</li> <li>\\((x,y,z) = \\frac{3x-5y+4z}{9}(3,0,0) + (y-z)(2,2,1) + \\frac{2z-y}{3}(1,3,3)\\)</li> </ul>"},{"location":"MATHS2/4.01%20-%20Vector%20Basis/#basis-of-a-vector-space","title":"Basis of a vector space","text":"<p>A basis \\(B\\) of a vector space \\(V\\) is linearly independent subset of \\(B\\) that spans \\(V\\).</p> <p>Conditions for a set to be a basis</p> <ul> <li>The set \\(B\\) is linearly independent. \\(Span(B) = V\\).</li> <li>\\(B\\) is a maximal linearly independent set.</li> <li>\\(B\\) is a minimal spanning set.</li> </ul>"},{"location":"MATHS2/4.01%20-%20Vector%20Basis/#finding-a-basis-for-a-vector-space","title":"Finding a basis for a vector space","text":""},{"location":"MATHS2/4.01%20-%20Vector%20Basis/#method-1","title":"Method 1","text":"<p>Start with the \\(\u00d8\\) and keep appending vectors which are not in the span of the set thus far obtained, until we obtain a spanning set.</p> <p>Example</p> <ul> <li>Let \\(V = \\mathbb{R}^2\\).</li> <li>Let us start with the empty set \\(\\emptyset\\) and append a non-zero vector \\((1,2)\\) to it.</li> <li>Now choose another vector which is not in the span of the of the earlier vector like \\((2,3)\\).</li> </ul>"},{"location":"MATHS2/4.01%20-%20Vector%20Basis/#method-2","title":"Method 2","text":"<p>Take a spanning set and keep deleting vectors which are linear combinations of the other vectors, until the remaining vectors satisfy that they are not a linear combination of the other remaining ones.</p> <p>Example</p> <ul> <li>Let \\(V = \\mathbb{R}^3\\).</li> <li>Let us start with the spanning set \\(\\{(1,0,0), (1,2,0), (1,0,3), (0,2,3), (0,4,3)\\}\\).</li> </ul> Span of an Empty Set <p>The span of an empty set is the zero vector space \\(\\{0\\}\\).</p>"},{"location":"MATHS2/4.01%20-%20Vector%20Basis/#dimension-rank-of-a-vector-space","title":"Dimension / Rank of a vector space","text":"<ul> <li>The dimension of a vector space \\(V\\) is the cardinality of a basis for \\(V\\).</li> <li>If \\(B\\) is a basis for \\(V\\), then rank of \\(V\\) is the cardinality of \\(B\\).</li> <li>For every vector space there exists a basis,and all bases of a vector space have the same number of elements (or cardinality); hence, the dimension (or rank) of a vector space (say \\(V\\)) is uniquely defined and denoted by \\(dim(V)\\) / \\(rank(V)\\) respectively.</li> </ul>"},{"location":"MATHS2/5.01%20-%20null%20space%20and%20nullity/","title":"Null Space of a Matrix","text":"<ul> <li>Let \\(A\\) be a \\(m \\times n\\) matrix</li> <li>The subspace \\(W = \\{x \\in \\mathbb{R}^n | Ax = 0\\}\\) of \\(\\mathbb{R}^n\\) is called the Solution Space of the homogenous system \\(Ax = 0\\) or the Null Space of \\(A\\).</li> <li>Note that the null space is the subspace of \\(\\mathbb{R}^n\\). The dimension of the null space is the nullity of \\(A\\).</li> </ul> \\[x,y \\in W \\implies Ax = Ay = 0 \\implies A(x-y) = 0 \\implies Ax + Ay = 0 + 0 = 0\\] \\[ \\lambda \\in \\mathbb{R} \\implies A(\\lambda x) = \\lambda (Ax) = 0 \\implies \\lambda 0 = 0 \\] \\[\\therefore \\ \\lambda \\in W\\]"},{"location":"MATHS2/5.01%20-%20null%20space%20and%20nullity/#finding-the-nullity-and-a-basis-for-the-null-space","title":"Finding the nullity and a basis for the null space","text":"<ul> <li>We have seen how to find the dimension and a basis for the row space of A using row reduction.</li> <li>We will use row reduction to also find the nullity and a basis for the null space of A.</li> <li> <p>First how to find the solution space for a system Ax b i.e. Gaussian elimination.</p> <ul> <li>Form the augmented matrix \\([A |b]\\)</li> <li>Applying the elementary row operations to the augmented matrix we reduce the matrix \\(A\\) to its reduced row echelon form and obtain \\([R | c]\\) where \\(R\\) is the reduced row echelon form of \\(A\\) and \\(c\\) is the reduced row echelon form of \\(b\\).</li> <li>If the \\(i^{th}\\) column has the leading entry of some row, we call \\(x_i\\) a dependent variable.</li> <li>If the \\(i^{th}\\) column has no leading entry, we call \\(x_i\\) an independent variable.</li> </ul> \\[ nullity(A) = \\text{number of independent variables}\\] </li> <li> <p>Assign arbitrary values \\(t_i\\) to the \\(i^{th}\\) independent variable.</p> </li> <li>Compute the value of each dependent variable in terms of \\(t_is\\) from the unique row it occurs in.</li> <li>Every solution is obtained by letting \\(t_is\\) be any real number.</li> </ul> <p>Example</p> <ul> <li>Consider the homogeneous system \\(Ax = 0\\) where \\(A = \\begin{bmatrix} 1 &amp; 1 &amp; 1 \\\\ 2 &amp; 2 &amp; 2 \\\\ 3 &amp; 3 &amp; 3 \\end{bmatrix}\\)</li> <li>The augmented matrix is \\([A | 0] = \\begin{bmatrix} 1 &amp; 1 &amp; 1 |&amp; 0 \\\\ 2 &amp; 2 &amp; 2 |&amp; 0 \\\\ 3 &amp; 3 &amp; 3 |&amp; 0 \\end{bmatrix}\\)</li> <li>Row reduce the augmented matrix to obtain \\([R | c] = \\begin{bmatrix} 1 &amp; 1 &amp; 1 |&amp; 0 \\\\ 0 &amp; 0 &amp; 0 |&amp; 0 \\\\ 0 &amp; 0 &amp; 0 |&amp; 0 \\end{bmatrix}\\)</li> <li>Here \\(x_1\\) is a dependent variable and \\(x_2 , x_3\\) are independent variables.<ul> <li>The first column has the leading entry of the first row hence \\(x_1\\) is a dependent variable.</li> <li>The second and the third column dont have the leading entry of any row , hence \\(x_2 , x_3\\) are independent variables.</li> </ul> </li> <li> <p>Hence the nullity of \\(A\\) is 2 because there are 2 independent variables.</p> </li> <li> <p>Put \\(x_2 = t_1\\) and \\(x_3 = t_2\\) that yeilds \\(x_1 = -t_1 - t_2\\).</p> <ul> <li>The null space of \\(A\\) is \\(\\{ (-t_1-t_2, t_1,t_2)\\}\\)</li> <li>Now put \\(t_1 = 0 , t_2 = 1\\) and you will get \\((-1 , 0 ,1)\\).</li> <li>Now put \\(t_1 = 1 , t_2 = 0\\) and you will get \\((-1 , 1 , 0)\\).</li> <li>Hence the basis vector is \\(\\{(-1,0,1), (-1,1,0)\\}\\)</li> </ul> </li> <li> <p>Consider the matrix \\(A = \\begin{bmatrix} 1 &amp; 2 &amp; 0 &amp; 3 \\\\ 2 &amp; 3 &amp; 0 &amp; 3 \\\\ 1 &amp; 1 &amp; 1 &amp; 2 \\end{bmatrix}\\)</p> <ul> <li>Applying row reductions on the matrix \\(A\\) we obtain \\([R | c] = \\begin{bmatrix} 1 &amp; 2 &amp; 0 &amp; 3 |&amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 3 |&amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 2 |&amp; 0 \\end{bmatrix}\\)</li> <li>\\(x_1,x_2 \\text{ and } x_3\\) are dependent variables and \\(x_4\\) are independent variables.</li> <li>Hence the nullity of \\(A\\) is 1. The null space of \\(A\\) is \\(\\{ (3t,-3t,-2t,t)\\}\\)</li> </ul> </li> </ul>"},{"location":"MATHS2/5.01%20-%20null%20space%20and%20nullity/#the-rank-nullity-theorem","title":"The Rank-Nullity Theorem","text":"<ul> <li>Let \\(A\\) be a \\(m \\times n\\) matrix.</li> <li>The rank is number of linearly dependent variables in \\(A\\).</li> <li>The nullity is the number of linearly independent variables in \\(A\\).</li> </ul> \\[rank(A) + nullity(A) = n , \\text{where n is the number of columns in A}\\]"},{"location":"MATHS2/5.04%20-%20Linear%20Mapping/","title":"Linear Mapping","text":""},{"location":"MATHS2/5.04%20-%20Linear%20Mapping/#defination","title":"Defination","text":"<ul> <li>A linear mapping \\(f\\) from \\(\\mathbb{R}^n\\) to \\(\\mathbb{R}^m\\) is a function that satisfies the following two conditions:   \\(\\(f(x_1,x_2, \\dots ,x_n) = (\\sum^n_{j=1}a_{1j}x_j, \\sum^n_{j=1}a_{2j}x_j, \\dots , \\sum^n_{j=1}a_{mj}x_j)\\)\\)</li> <li>Here the coefficients \\(a_{ij}\\) are real numbers (scalars). A linear mapping can be thought of as a collection of linear combinations.</li> </ul>"},{"location":"MATHS2/5.04%20-%20Linear%20Mapping/#linearity-of-a-linear-mapping","title":"Linearity of a Linear Mapping","text":"<ul> <li>It follows that a linear mapping satisfies linearity, i.e. for any \\(c \\in \\mathbb{R}\\) (scalar)   \\(\\(f(x_1 + cy_1 , x_2 + cy_2, \\dots , x_n + cy_n) = f(x_1,x_2, \\dots ,x_n) + cf(y_1,y_2, \\dots ,y_n)\\)\\) \\(\\(\\text{or}\\)\\) \\(\\(f(x_1 + cy_1 , x_2 + cy_2, \\dots , x_n + cy_n) = A \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} + c \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\)\\)</li> </ul>"},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/","title":"Linear Mappings","text":""},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#definition","title":"Definition","text":"<ul> <li>A linear mapping \\(f: V \\rightarrow W\\) between two vector spaces \\(V\\) and \\(W\\) is said to be a linear transformations if for nay two vectors \\(v_1\\) and \\(v_2\\) in the vector space \\(V\\) and for any \\(c \\in \\mathbb{R}\\), the following two conditions are satisfied:</li> <li>\\(f(v_1 + cv_2) = f(v_1) + cf(v_2)\\)</li> <li>\\(f(v_1) + f(cv_2) = f(v_1) + cf(v_2)\\)</li> </ul>"},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#types-of-linear-mappings","title":"Types of Linear Mappings","text":""},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#1-1-function","title":"\\(1-1\\) function","text":"<ul> <li>Function \\(f: V \\rightarrow W\\) is said to be a \\(1-1\\) function if for any two vectors \\(v_1\\) and \\(v_2\\) in the vector space \\(V\\), if \\(f(v_1) = f(v_2)\\) then \\(v_1 = v_2\\).</li> <li>For linear transformation, being a \\(1-1\\) is equivalent to \\(f(v) = 0\\) implies \\(v = 0\\).</li> </ul>"},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#onto-function","title":"Onto function","text":"<ul> <li>Function \\(f: V \\rightarrow W\\) is said to be an onto function if for any vector \\(w\\) in the vector space \\(W\\), there exists a vector \\(v\\) in the vector space \\(V\\) such that \\(f(v) = w\\).</li> </ul>"},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#isomorphism","title":"Isomorphism","text":"<ul> <li>A linear transformation \\(f: V \\rightarrow W\\) is said to be an isomorphism if it is both a \\(1-1\\) function and an onto function or \\(f\\) is a bijective function.</li> <li>Note that being a bijection is equivalent to: for any \\(v \\in W\\), there exists a \\(v \\in V\\) such that \\(f(v) = w\\).</li> </ul>"},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#definition_1","title":"Definition","text":"<ul> <li>A linear transformation \\(f: V \\rightarrow W\\) between two vector spaces \\(V\\) and \\(W\\) is said to be an isomorphism if it is a bijection.</li> </ul>"},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#example","title":"Example","text":"<ul> <li>\\(f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2\\) defined by \\(f(x,y) = (2x,0)\\)</li> <li> <p>There is no pre-image for the vector \\((u,v)\\), where v is non-zero eg. \\((0,1)\\) has no pre-image. So \\(f\\) is not surjective. Also \\(f(x,y) = (0,0)\\) implies \\(x = 0\\). But there is no restriction on \\(y\\), eg. \\(f(0,1) = (0,0)\\). Hence \\(f\\) is not \\(1-1\\).</p> </li> <li> <p>\\(f : \\mathbb{R} \\rightarrow \\mathbb{R}^3 \\ ; \\ f(t) = (t,3t,\\frac{23}{89}t)\\) is \\(1-1\\) but not onto.</p> </li> <li>\\(f : \\mathbb{R}^2 \\rightarrow \\mathbb{R} \\ ; \\ f(x,y) = x\\) is onto but not \\(1-1\\).</li> </ul>"},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#bases-determine-linear-transformations","title":"Bases determine linear transformations","text":"<ul> <li>Let \\(V\\) be a vector space with basis \\(\\lbrace v_1, v_2, \\dots,v_n\\rbrace\\).</li> <li>Let \\(f : V \\rightarrow W\\) be a linear transformation. Then the ordered vectors \\(f(v_1), f(v_2), \\dots, f(v_n)\\) form a basis for \\(W\\).   \\(\\(f(v) = f(\\sum^n_{i=1}c_iv_i) = \\sum^n_{i=1}c_if(v_i)\\)\\) \\(\\(\\text{ The values are determined by } c_1,\\dots,c_n \\ \\&amp; \\ f(v_1), \\dots f(v_n).\\)\\)</li> </ul>"},{"location":"MATHS2/5.05%20-%20Linear%20Transformation/#example_1","title":"Example","text":"<ul> <li>Let the standard basis for \\(\\mathbb{R}^2\\) be \\(\\lbrace (1,0), (0,1) \\rbrace\\). What linear transformation \\(f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2\\) do we obtain by extending:   $$ f((1,0)) = (2,0) = 2(1,0)$$   $$ f((0,1)) = (0,1) = 1(0,1)$$</li> <li>\\((x,y) = x(1,0) + y(0,1)\\)</li> <li>\\(f(x,y) = 2x(1,0) + y(0,1) = (2x,y)\\)</li> </ul>"},{"location":"MATHS2/6.01%20-%20Linear%20Tranformation%2C%20ordered%20bases%20and%20matricies/","title":"An important property of finite dimensional vector spaces","text":"<ul> <li>Let \\(V\\) be a vector space with dimension \\(n\\). Choose a basis \\(\\lbrace v_1, v_2, \\dots, v_n \\rbrace\\) for \\(V\\).</li> <li>Define \\(f : V \\rightarrow \\mathbb{R}^n\\) by extending the function sending the basis vector \\(v_i\\) to the standard basis vector \\(e_i \\in \\mathbb{R}^n\\) for each in \\(i\\).</li> <li>Then \\(f\\) is an isomorphism.</li> <li>\\(v = \\sum c_iv_i\\)</li> <li>\\(f(v) = \\sum c_ie_i \\rightarrow f(v_i) = e_i\\)</li> <li>Onto : \\((x_1,\\dots,x_n) \\in \\mathbb{R}^n . \\text{ Let } V = \\sum x_iv_i\\)<ul> <li>Then \\(f(V) = (x_1,\\dots,x_n) \\text{ or } \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix}\\)</li> </ul> </li> <li>\\(1-1\\) : \\(f(v) = 0 \\rightarrow \\sum c_ie_i = (0,\\dots,0)\\)<ul> <li>\\((c_1,\\dots,c_n) = (0,\\dots, 0)\\)</li> </ul> </li> </ul>"},{"location":"MATHS2/6.01%20-%20Linear%20Tranformation%2C%20ordered%20bases%20and%20matricies/#examples","title":"Examples","text":"<ul> <li>We computed the that the basis for the subspace.</li> <li>\\(W = \\lbrace (x,y,z)| x + y + z = 0\\rbrace \\text{ is } (-1,1,0), (-1, 0, 1)\\)</li> <li>Then the homomorphism \\(f\\) obtained by extending \\(f(-1,1,0) = (1,0) \\text{ and } f(-1,0,1) = (0,1)\\) is an isomorphism.</li> <li>Note that \\((x,y,z)\\) can be uniquely expressed as<ul> <li>\\((x,y,z) = y(-1,1,0) + z(-1,0,1)\\)</li> </ul> </li> <li>Hence, \\(f : W \\rightarrow \\mathbb{R}^2 is f(x,y,z) = y(1,0) + z(0,1) = (y,z)\\)</li> <li>\\(Onto : (y,z)^ \\in \\mathbb{R}^2 \\text{ is } x = -y - z\\) and consider \\((x,y,z) \\in W\\)<ul> <li>Then \\(f(W) = (y,z) = (x,-x)\\)</li> </ul> </li> <li>\\(1-1\\) : \\(f(x,y,z) = (0,0) \\rightarrow x = -y - z = 0\\)<ul> <li>Then \\((x,y,z) = (0,0,0)\\)</li> </ul> </li> </ul>"},{"location":"MATHS2/6.01%20-%20Linear%20Tranformation%2C%20ordered%20bases%20and%20matricies/#example-linear-transformation-in-matrix-form","title":"Example : Linear transformation in Matrix form","text":"<ul> <li>Consider the linear tranformation \\(f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2 ; f(x,y) = (2x,y)\\)</li> <li>We can represent this matrix form as \\(f(x,y) = \\begin{bmatrix}  2 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}\\)</li> <li>If we represent the matrix using the standard basis we can write it as</li> <li>\\(f(1,0) = (2,0) = 2(1,0) + 0(0,1)\\)</li> <li>\\(f(0,1) = (0,1) = 0(1,0) + 1(0,1)\\)</li> </ul>"},{"location":"MATHS2/6.01%20-%20Linear%20Tranformation%2C%20ordered%20bases%20and%20matricies/#matrix-corresponding-to-a-linear-transformation-with-respect-to-ordered-basis","title":"Matrix corresponding to a linear transformation with respect to ordered basis","text":"<ul> <li>Let \\(f : V \\rightarrow W\\) be a linear transformation</li> <li>Let \\(\\beta = v_1,v_2, \\dots, v_n\\) be an ordered basis of \\(V\\) and \\(\\gamma = w_1,w_2, \\dots, w_n\\) be an ordered basis of \\(W\\)</li> <li>Each \\(f(v_1)\\) can be uniquely written as a linear combination of \\(w_js\\), where \\(i  = 1,2, \\dots, n\\) and \\(j = 1,2, \\dots, m\\)   $$f(v_1) = a_{11}w_1 + a_{21}w_2 + \\dots + a_{m1}w_m $$   $$f(v2) = aw1 + aw2 + \\dots + awm $$   (\\(\\vdots\\)\\)   $$f(v_n) = aw1 + aw2 + \\dots + aw_m $$</li> <li>The matrix corresponding to the linear transformation \\(f\\) with respect to the ordered bases \\(\\beta \\text{ and } \\gamma\\) are given by the matrix   \\(\\(A = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; \\dots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; \\dots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; a_{m2} &amp; \\dots &amp; a_{mn} \\end{bmatrix}\\)\\)</li> <li>The matrix \\(A\\) is called the matrix corresponding to the linear transformation \\(f\\) with respect to the ordered bases \\(\\beta\\) and \\(\\gamma\\)</li> <li>Example:<ul> <li>Let \\(V = W = \\mathbb{R}^2, \\beta = \\gamma = (1,0), (1,1) anf f(x,y) = (2x,y)\\)</li> <li>\\(f(1,0) = (2,0) = 2(1,0) + 0(1,1)\\)</li> <li>\\(f(1,1) = (2,1) = 1(1,0) + 1(1,1)\\)</li> <li>Then the matrix corresponding to the linear transformation \\(f\\) with respect to the ordered bases \\(\\beta\\) and \\(\\gamma\\) are given by the matrix   \\(\\(A = \\begin{bmatrix} 2 &amp; 1 \\\\ 0 &amp; 1 \\end{bmatrix}\\)\\)</li> </ul> </li> </ul>"},{"location":"MATHS2/6.01%20-%20Linear%20Tranformation%2C%20ordered%20bases%20and%20matricies/#recovering-the-linear-transformation-from-the-matrix","title":"Recovering the linear transformation from the matrix","text":"<ul> <li>Let \\(\\beta = v_1, v_2, \\dots, v_n\\) and \\(\\gamma = w_1, w_2, \\dots, w_m\\) be ordered bases for \\(V\\) and \\(W\\) respectively. Suppose \\(A\\) is an \\(m \\times n\\) matrix. What is the linear transformation?</li> <li>Let \\(v \\in V\\). Express \\(v = \\sum_{j=1}^n c_jv_j\\) \\(\\(f(v) = \\sum_{j=1}^n c_j\\sum_{i=1}^ma_{ij}w_i\\)\\)</li> <li>Checking that \\(f\\) is a linear transformation!</li> <li>Letting \\(c_k = 1\\) and \\(c_j = 0\\) for all \\(j \\neq k\\) we get     \\(\\(f(v_k) = A_{1k}w_1 + \\dots + A_{mk}w_m\\)\\)</li> </ul>"},{"location":"MATHS2/6.01%20-%20Linear%20Tranformation%2C%20ordered%20bases%20and%20matricies/#fixed-ordered-bases-linear-transformations-lrarr-matrices","title":"Fixed ordered bases : Linear transformations \\(\\lrarr\\) matrices","text":"<ul> <li>Let \\(\\beta\\) and \\(\\gamma\\) be ordered bases for vector spaces \\(V\\) and \\(W\\) respectively where \\(n = dim(V)\\) and \\(m = dim(W)\\)</li> <li>There is a bijection:</li> <li>\\(\\lbrace \\text{Linear transformations from } V \\text{ to } W \\rbrace \\leftrightarrow \\lbrace m \\times n \\text{ matrices } \\rbrace\\)</li> </ul>"},{"location":"MATHS2/6.01%20-%20Linear%20Tranformation%2C%20ordered%20bases%20and%20matricies/#example","title":"Example","text":"<ul> <li>Let \\(W  = \\lbrace (x,y,z)| x + y + z = 0\\rbrace\\) and \\(V = \\mathbb{R}^2\\)</li> <li>Let \\(\\beta = (-1,1,0), (-1,0,1)\\) and \\(\\gamma = (1,0), (0,1)\\)</li> <li>The isomorphism \\(f\\) is obtained by extending \\(f (\u20141, 1, 0) (1, 0)\\) and \\(f (\u20141, 0, 1) = (0,1)\\) \\(\\(A = \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix}\\)\\)</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/","title":"Kernal and Image","text":""},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#definations","title":"Definations","text":""},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#kernal","title":"Kernal","text":"<ul> <li>Let \\(f : V \\rightarrow W\\) be a linear transformation.</li> <li>The kernal of \\(f\\) or \\(ker(f):\\) \\(\\(ker(f) = \\{v \\in V | f(v) = 0\\}\\)\\)</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#image","title":"Image","text":"<ul> <li>The image of \\(f\\) or \\(im(f) / Im(f):\\) \\(\\(im(f) = \\{w \\in W | \\exists v \\in V, f(v) = w\\}\\)\\)</li> <li>\\(Im(f)\\) is the other name for the \"range of the function \\(f\\)\" which we have studied in Math-1.</li> <li>The image of \\(f\\) is also the subspace for \\(W\\).</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#examples","title":"Examples","text":"<ul> <li>Consider \\(f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2\\) defined by \\(f(x, y) = (2x, y)\\).</li> <li>Then the \\(ker(f) = \\lbrace (0,0) \\rbrace\\)</li> <li>\\(Im(f) = \\mathbb{R}^2\\)</li> <li>Consider \\(f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2\\) defined by \\(f(x, y) = (2x, 0)\\).</li> <li>Then the \\(ker(f) = \\lbrace (0,y) | y \\in \\mathbb{R} \\rbrace\\)</li> <li>\\(Im(f) = \\lbrace (x,0) | x \\in \\mathbb{R} \\rbrace\\)</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#the-kernal-and-injectivity-of-a-linear-transformation","title":"The kernal and injectivity of a linear transformation","text":"<ul> <li>Function \\(f : V \\rightarrow W\\) is injective if \\(f(v_1) = f(v_2)\\) implies \\(v_1 = v_2\\).</li> <li>Linear transformation \\(f\\) being \\(1-1\\) (or injective) is equivalent to \\(f(v) = 0\\) implies \\(v = 0\\).</li> <li>Rewriting the last part in terms of \\(ker(f)\\), we see that linear transformation is \\(1-1\\) is equivalent to \\(ker(f) = \\lbrace 0 \\rbrace\\).   \\(\\(\\text{ A linear transformation } f \\text{ is injective if and only if } ker(f) = \\lbrace 0 \\rbrace\\)\\)</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#the-image-and-surjectivity-of-a-linear-transformation","title":"The image and surjectivity of a linear transformation","text":"<ul> <li>Function \\(f : V \\rightarrow W\\) is surjective if for each \\(w \\in W\\), there exists some \\(v \\in V\\) such that \\(f(v) = w\\).</li> <li>It follows the defination of the function \\(f : V \\rightarrow V\\) being onto (or surjective) is equivalent to \\(Range(f) = W\\).</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#kernels-and-null-spaces","title":"Kernels and null spaces","text":"<ul> <li>Let \\(f : V \\rightarrow W\\) be a linear transformation. Let \\(\\beta = v_1, v_2, \\dots, v_n\\) and \\(\\gamma = w_1, w_2, \\dots, w_m\\) be ordered bases for \\(V\\) and \\(W\\) respectively.</li> <li>Let \\(A\\) be the corresponding to \\(f\\) with respect to \\(\\beta\\) and \\(\\gamma\\).   \\(\\(v = \\sum_{j=1}^n c_j v_j \\in V, f(v)=\\sum_{j=1}^nc_j\\sum_{i=1}^m A_{ij}w_i\\)\\)</li> <li>If \\(f(v) = 0\\) for all \\(v \\in V\\), then \\(f\\) is called a zero transformation.</li> <li>All the coefficients \\(c_j\\) are zero, so \\(v = 0\\).</li> <li>Thus \\(v = ker(f)\\).</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#bases-for-the-kernal-and-image-of-linear-transformation","title":"Bases for the kernal and image of linear transformation","text":"<ul> <li>Let \\(A\\) be the matrix corresponding to \\(f\\) with respect to \\(\\beta\\) and \\(\\gamma\\).</li> <li>The relation between kernals and null spaces derived earlier actually yields an isomorphism between the null space of \\(A\\) and the kernal of \\(f\\).</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#finding-the-basis-for-the-kernal-and-range","title":"Finding the basis for the kernal and range","text":"<ul> <li>If we have the matrix of the linear transformation we can find the basis for the kernal and range:</li> <li>We can convert that matrix into a RREF and then multiply it by the variables from the vector space:<ul> <li>Example 1:</li> <li>Suppose the matrix \\(A =\\begin{bmatrix} 1 &amp; 2 \\\\ 3 &amp; 4 \\end{bmatrix}\\)</li> <li>The RREF of the matrix is \\(\\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix}\\)</li> <li>Multiply the matrix by the variables \\(x\\) and \\(y\\) we get</li> <li>\\(\\begin{bmatrix}1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y\\end{bmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}\\)</li> <li>The basis for range of the matrix \\(A\\) is the columns with pivot points. So the basis is \\(\\text{Basis for } R =\\lbrace (1,3) , (2,4) \\rbrace\\)</li> <li>In this case both \\(x\\) and \\(y\\) are equating to \\(0\\) so the \\(ker(A) =\\lbrace 0 \\rbrace\\)</li> <li>Example 2:</li> <li>Linear Transformation from \\(\\mathbb{R}^2 \\rightarrow \\mathbb{R}^3\\) with respect to standard ordered basis.</li> <li>Basis for Domain \\(\\lbrace (1,0), (0,1) \\rbrace\\)</li> <li>Basis for Range \\(\\lbrace (1,0,0), (0,1,0), (0,0,1) \\rbrace\\)</li> <li>Matrix \\(A = \\begin{bmatrix} 1 &amp; 2 \\\\ 2 &amp; 4 \\\\ 4 &amp; 8 \\end{bmatrix}\\)</li> <li>\\(A_{rref} = \\begin{bmatrix} 1 &amp; 2 \\\\ 0 &amp; 0 \\\\ 0 &amp; 0 \\end{bmatrix}\\)</li> <li>The basis for range of the matrix \\(A\\) is the columns with pivot points. So the basis is \\(\\text{Basis for } R =\\lbrace (1,3,4) \\rbrace\\)</li> <li>\\(ker(T) = \\text{ Nullspace of } \\begin{pmatrix} 1 &amp; 2 \\\\ 0 &amp; 0 \\\\ 0 &amp; 0\\end{pmatrix} = \\begin{pmatrix} 1 &amp; 2 \\\\ 0 &amp; 0 \\\\ 0 &amp; 0\\end{pmatrix} \\cdot \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\Rightarrow x + 2y = 0 \\Rightarrow x= -2y\\)</li> <li>The kernal is \\(\\lbrace (-2y, y) | y \\in \\mathbb{R} \\rbrace\\) and the basis of the kernal is \\(\\lbrace (-2, 1) \\rbrace\\).</li> <li>Example 3:</li> <li>Linear Transformation from \\(\\mathbb{R}^2 \\rightarrow \\mathbb{R}^2\\) with respect to \\(\\lbrace (1,1), (1,0) \\rbrace\\).</li> <li>The matix \\(A = \\begin{bmatrix} 1 &amp; 2 \\\\ 3 &amp; 6 \\end{bmatrix}\\)</li> <li>\\(A_{rref} = \\begin{bmatrix} 1 &amp; 2 \\\\ 0 &amp; 0 \\end{bmatrix}\\)</li> <li>The basis for range of the matrix \\(A\\) is the columns with pivot points. So the basis is \\(\\text{Basis for } R =\\lbrace 1(1,1) + 3(1,0) \\rbrace = \\lbrace (4,1)\\rbrace\\)</li> <li>Nullspace of \\(A\\) is \\(\\begin{pmatrix} 1 &amp; 2 \\\\ 0 &amp; 0 \\end{pmatrix} \\cdot \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\Rightarrow x +2y = 0 \\Rightarrow x = -2y\\)</li> <li>\\(ker(T) = \\lbrace (-2y, y) | y \\in \\mathbb{R} \\rbrace\\).</li> <li>Basis for kernal is \\(\\lbrace -2(1,1) + 1(1,0) \\rbrace \\Rightarrow \\{  (-1,-2)\\}\\)</li> <li>Example 4:</li> <li>Linear Transformation from \\(\\mathbb{R}^3 \\rightarrow \\mathbb{R}^3\\) with respect to \\(\\{ (1, 0, 0) , (0, 1, 0), (0, 0, 1)\\}\\) for the domain and \\(\\{ (1, 1, 1) , (1, 1, 0), (1, 0, 0)\\}\\) for the codomain</li> <li>The Matrix \\(A = \\begin{bmatrix} 1 &amp; 4 &amp; 1 \\\\ 0 &amp; 2 &amp; 2 \\\\ 1 &amp; 6 &amp; 3 \\end{bmatrix}\\)</li> <li>\\(A_{rref} = \\begin{bmatrix} 1 &amp; 0 &amp; -3 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix}\\)</li> <li>Basis for range is \\(\\{ 1(1,1,1) + 0 (1,1,0) + 1(1,0,0), 4(1,1,1) + 2 (1,1,0) + 6(1,0,0) \\} \\Rightarrow \\{ (2,1,1),(12,6,4)\\}\\)</li> <li>B</li> </ul> </li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#points","title":"Points","text":""},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#properties-of-linear-spaces","title":"Properties of linear spaces","text":"<ul> <li>If the linear transformation is from \\(\\mathbb{R}^m \\rightarrow \\mathbb{R}^n\\), where are \\(m &gt; n\\).</li> <li>Then the transformation can never be \\(1-1\\).</li> <li>This is because we there has to be some overlap while mapping a higher dimension to a lower dimension.</li> <li>If the linear transformation is from \\(\\mathbb{R}^m \\rightarrow \\mathbb{R}^n\\), where are \\(m &lt; n\\).</li> <li>Then the transformation can never be \\(\\text{onto}\\).</li> <li>This is because a smaller dimension cannot fully map to a higher dimension.</li> <li>If the linear transformation is from \\(\\mathbb{R}^m \\rightarrow \\mathbb{R}^n\\), where are \\(m = n\\).</li> <li>Then this transformation can be \\(1-1\\) and \\(\\text{onto}\\).</li> <li>If the \\(\\ker(f) = 0\\) then it can be \\(1-1\\). If the \\(\\ker(f) = 0\\) then the \\(nullity(A) = 0\\).</li> <li>According to the Rank Nullity Theorm \\(rk(A) + nullity(A) = n\\).<ul> <li>\\(rk(A) + 0 = n\\)</li> </ul> </li> <li>Since the rank of the matrix is \\(n\\) then it is onto.</li> <li>TLDR: A linear transformation can be \\(1-1\\) and \\(\\text{onto}\\) if the transformtion is happening in the same dimension and nullity of the transformation is 0 or the rank of the matrix is \\(n\\).</li> <li>We can use these properties to find the properties of the transformation.</li> </ul>"},{"location":"MATHS2/6.02%20-%20Image%20and%20Kernal%20of%20linear%20transformations/#finding-the-linear-transformation","title":"Finding the linear transformation","text":"<ul> <li>We can find the linear transformation if we have the basis of the domain and codomain.</li> <li>We can backtrack from codomain to domain. We can find the matrix of the transformation and then find the transformation.</li> </ul>"},{"location":"MATHS2/7.01%20-%20Equivalence%20and%20similarity%20of%20matricies/","title":"Equivalence of Matricies","text":"<ul> <li>Let \\(A\\) and \\(B\\) be two matrices of order \\(m \\times n\\). We say \\(A\\) is equivalent to \\(B\\) if \\(B = QAP\\) for some invertible \\(n \\times n\\) matrix \\(P\\) and some invertible \\(m \\times m\\) matrix \\(Q\\).</li> </ul>"},{"location":"MATHS2/7.01%20-%20Equivalence%20and%20similarity%20of%20matricies/#properties-of-equivalence","title":"Properties of equivalence","text":"<ul> <li>\\(A\\) can be transformed into \\(B\\) by a sequence of elementary row operations.</li> <li>\\(rank(A) = rank(B)\\)</li> <li>If the rank of \\(A\\) and \\(B\\) are the same then they are equivalent.</li> </ul>"},{"location":"MATHS2/7.01%20-%20Equivalence%20and%20similarity%20of%20matricies/#equivalence-matrices-is-an-equivalence-relation","title":"Equivalence matrices is an equivalence relation","text":"<ul> <li>\\(A\\) is equivalent to itself.</li> <li>\\(A\\) is equivalent to \\(B\\) if and only if \\(B\\) is equivalent to \\(A\\).</li> <li>\\(A\\) is equivalent to \\(B\\) and \\(B\\) is equivalent to \\(C\\) if and only if \\(A\\) is equivalent to \\(C\\).</li> </ul>"},{"location":"MATHS2/7.01%20-%20Equivalence%20and%20similarity%20of%20matricies/#example","title":"Example","text":"<ul> <li>Consider the linear transformation \\(f : \\mathbb{R}^3 \\rightarrow \\mathbb{R}^2,\\) defined as :</li> <li>\\(f(x,y,z) = (x + y, x - z)\\)</li> <li>Consider two ordered bases for \\(\\mathbb{R}^3\\):</li> <li>\\(\\beta_1 = (1,0,0), (0,1,0),(0,0,1)\\) and \\(\\beta_1 = (1,1,0), (0,1,1),(0,0,1)\\)</li> <li>Consider two ordered basis for \\(\\mathbb{R}^2\\):</li> <li>\\(\\gamma_1 = (1,0), (0,1)\\) and \\(\\gamma_2 = (1,0), (1,1)\\)</li> <li>\\(f(1,0,0) = (1,0)\\)</li> <li>\\(f(0,1,0) = (1,1) = 1(1,0) + 1(0,1)\\)</li> <li>\\(f(0,0,1) = (0,1)\\)</li> <li>The matrix of \\(\\beta_1\\) with respect to \\(\\gamma_1\\) is:</li> <li>\\(A = \\begin{bmatrix} 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 \\end{bmatrix}\\)</li> <li>\\(f(1,1,0) = (2,1) = 1(1,0) + 1(1,1)\\)</li> <li>\\(f(0,1,1) = (1,2) = -1(1,0) + 2(1,1)\\)</li> <li>\\(f(0,0,1) = (0,1) = -1(1,0) + 1(1,1)\\)</li> <li>The matrix of \\(\\beta_2\\) with respect to \\(\\gamma_2\\) is:</li> <li>\\(B = \\begin{bmatrix} 1 &amp; -1 &amp; -1 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix}\\)</li> <li>Choose \\(P = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 1\\end{bmatrix}\\) and \\(Q = \\begin{bmatrix} 1 &amp; -1 \\\\ 0 &amp; 1 \\end{bmatrix}\\)</li> <li>\\(QAP = \\begin{bmatrix} 1 &amp; -1 &amp; -1 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 1\\end{bmatrix}  = \\begin{bmatrix} 1 &amp; -1 &amp; -1 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix} = B\\)</li> <li>Hence \\(A\\) and \\(B\\) are equivalent.</li> </ul>"},{"location":"MATHS2/7.01%20-%20Equivalence%20and%20similarity%20of%20matricies/#note","title":"Note","text":"<ul> <li>We can get the matrix of \\(P\\) by expressing the ordered basis \\(\\beta_2\\) in terms of the ordered basis \\(\\beta_1\\)</li> <li>We can get the matrix of \\(Q\\) by expressing the ordered basis \\(\\gamma_2\\) in terms of the ordered basis \\(\\gamma_1\\)</li> </ul>"},{"location":"MATHS2/7.01%20-%20Equivalence%20and%20similarity%20of%20matricies/#similarity","title":"Similarity","text":"<ul> <li>An \\(n \\times n\\) matrix \\(A\\) is said to be similar to a matrix \\(B\\) if there exists an invertible \\(n \\times n\\) matrix \\(P\\) such that \\(B = P^{-1}AP \\text{ or } PB = AP\\).</li> <li>Similar matrix have the same trace.</li> <li> \\[\\text{Trace = } tr(A) = \\sum_{i=1}^nA_{ii}\\] </li> <li>\\(A\\) is similar to itself.</li> <li>\\(A\\) is similar to \\(B\\) if and only if \\(B\\) is similar to \\(A\\).</li> <li>\\(A\\) is similar to \\(B\\) and \\(B\\) is similar to \\(C\\) if and only if \\(A\\) is similar to \\(C\\).</li> </ul>"},{"location":"MATHS2/7.01%20-%20Equivalence%20and%20similarity%20of%20matricies/#properties-of-similarity","title":"Properties of similarity","text":"<ul> <li>Suppose \\(A\\) is similar to \\(B\\) matricies.</li> <li>\\(A\\) and \\(B\\) are equivalent.</li> <li>\\(rank(A) = rank(B)\\)</li> <li>\\(det(B) = det(A)\\)</li> <li>\\(det(B) = det(P^{-1}AP) \\Rightarrow det(P^{-1})det(A)det(P) \\Rightarrow  \\frac{1}{det(P)}det(A)det(P) = det(A)\\)</li> <li>Several other invariants of \\(A\\) and \\(B\\) are the same such as the characteristic polynomial, minimal polynomial and eigen values (with multiplicity).</li> </ul>"},{"location":"MATHS2/7.01%20-%20Equivalence%20and%20similarity%20of%20matricies/#example_1","title":"Example","text":"<ul> <li>Consider the linear transformation \\(f : \\mathbb{R}^3 \\rightarrow \\mathbb{R}^3 \\text{ where } f(x,y,z) = (-x+y+z,x-y+z,x+y-z)\\)</li> <li>The basis \\(\\beta = \\gamma\\) both are the standard ordered basis for</li> <li>\\(f(1,0,0) = (-1,1,1) = -1(1,0,0) + 1(0,1,0) + 1(0,0,1)\\)</li> <li>\\(f(0,1,0) = (1,-1,1) = 1(1,0,0) - 1(0,1,0) + 1(0,0,1)\\)</li> <li>\\(f(0,0,1) = (1,1,-1) = 1(1,0,0) + 1(0,1,0) - 1(0,0,1)\\)</li> <li>Hence the matrix of \\(f\\) is:<ul> <li>\\(A = \\begin{bmatrix} -1 &amp; 1 &amp; 1 \\\\ 1 &amp; -1 &amp; 1 \\\\ 1 &amp; 1 &amp; -1 \\end{bmatrix}\\)</li> </ul> </li> <li>We get \\(P\\) by expressing the ordered basis \\(\\beta\\) in terms of the ordered basis \\(\\gamma\\).<ul> <li>\\(P = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 \\end{bmatrix}\\)</li> </ul> </li> <li>Consider the linear transformation \\(f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2 \\text{ where } f(x,y) = (2x,y)\\)</li> <li>The basis \\((1,0), (1,1)\\) for \\(\\mathbb{R}^2\\). Then we have the following:</li> <li>\\(f(1,0) = (2,0) = 2(1,0) + 0(1,1)\\)</li> <li>\\(f(1,1)= (2,1) = 1(1,0) + 1(1,1)\\)</li> <li>The matrix of \\(f\\) is:<ul> <li>\\(B = \\begin{bmatrix} 2 &amp; 1 \\\\ 0 &amp; 1 \\end{bmatrix}\\)</li> </ul> </li> </ul>"},{"location":"MATHS2/7.02%20-%20Affine%20subspace/","title":"Affine Subspace","text":""},{"location":"MATHS2/7.02%20-%20Affine%20subspace/#defination","title":"Defination","text":"<ul> <li>Let \\(V\\) be a vector space. An affine subspace of \\(V\\) is a subset \\(L\\) such that there exists \\(v \\in V\\) and a vector subspace \\(U \\sube V\\) such that   \\(\\(L = v + U := \\{ v + u| u \\in U\\}\\)\\)</li> <li>An affine subspace \\(L\\) is n-dimensional if the corresponding subspace \\(U\\) is n-dimensional.</li> <li>The subspace \\(U\\) corresponding to an affine subspace is unique.</li> <li>However the vector \\(v\\) corresponding to an affine subspace is not unique.</li> <li>Affine subspaces are thus translation of vector subspace \\(V.\\)</li> </ul>"},{"location":"MATHS2/7.02%20-%20Affine%20subspace/#solution-set-of-a-system-of-linear-equations","title":"Solution set of a system of linear equations","text":"<ul> <li>Let \\(Ax = b\\) be a linear system of equations.</li> <li>\\(b = 0:\\) In this case, it is a homogeneous system and as seen     before, the solution set is a subspace of \\(\\mathbb{R}^n\\), namely the null     space \\(A\\).</li> <li>\\(b \\notin \\text{ column space of } A\\): In this case, \\(Ax = b\\) does not have a solution, so the solution set is the empty set.</li> <li>\\(b \\in \\text{ column space of } A\\): In this case, the solution set L is an affine subspace of \\(\\mathbb{R}^n\\). Specifically, it can be described as \\(L =  v + nullspace(A)\\) where v is any solution of the equation \\(Ax = b.\\)</li> </ul>"},{"location":"MATHS2/7.02%20-%20Affine%20subspace/#affine-mapping-of-affine-subspaces","title":"Affine mapping of affine subspaces","text":"<ul> <li>Let \\(L\\) and \\(L'\\) be affine subspace of \\(V\\) and \\(W\\) respectively. Let \\(f : L \\rightarrow L'\\) be a function. Cosider any vector \\(v \\in L\\) and the unique subspace \\(U \\sube V\\) such that \\(L = v + U\\).</li> <li>Note that \\(f(v) \\in L'\\) and hence \\(f(v) + U'\\) where \\(U'\\) is unique subspace of \\(W\\) corresponding to \\(L'\\). Then \\(f\\) is an affine mapping from \\(L\\) to \\(L'\\) if the function \\(g: U \\rightarrow U'\\) defined by \\(g(u) = f(u+v) - f(v)\\) is a linear transformation.</li> <li>For a linear transformation \\(T: U \\rightarrow U'\\), and fixed vectors \\(v \\in L\\) and \\(v' \\in L'\\), an affine mapping \\(f\\) can be obtained by defining \\(f(v+u) = v' + T(u)\\), and in fact every affine mapping is obtained in this way.</li> </ul>"},{"location":"MATHS2/7.02%20-%20Affine%20subspace/#example","title":"Example","text":"<ul> <li>Let \\(T = (2x+3y+2, 4x-5y+3)\\). Then this is an affine mapping from \\(\\mathbb{R}^3 \\rightarrow \\mathbb{R}^2\\)</li> <li>Let \\(T : V \\rightarrow W\\) be a linear transformation and \\(w \\in W\\), then mapping   \\(\\(T': V \\rightarrow W\\)\\) \\(\\(T'(v) = T(v) + w\\)\\)</li> <li>This is a affine mapping from \\(V\\) to \\(W\\).</li> <li>We can find the shift in the mapping by looking at the shift at the \\(0\\) vector</li> </ul>"},{"location":"MATHS2/7.03%20-%20Lengths%20and%20angle/","title":"Lengths of Vectors","text":"<ul> <li>Let us find the length of vector \\((3,4)\\) in \\(\\mathbb{R}^2\\)</li> <li>Using Pythagoras' theorm the length of the vector \\((3,4)\\) is:</li> <li>\\(\\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5\\text{ units}\\)</li> </ul>"},{"location":"MATHS2/7.03%20-%20Lengths%20and%20angle/#formula","title":"Formula","text":"<ul> <li>The Length of the vector is the Square root of it's Dot Product with itself.</li> <li>\\(u \\in \\mathbb{R}^n\\) \\(\\(||u|| = \\sqrt{u \\cdot u}\\)\\)</li> </ul>"},{"location":"MATHS2/7.03%20-%20Lengths%20and%20angle/#angle-between-between-two-vectors-in-mathbbr2","title":"Angle between between two vectors in \\(\\mathbb{R}^2\\)","text":""},{"location":"MATHS2/7.03%20-%20Lengths%20and%20angle/#formula_1","title":"Formula","text":"\\[cos(\\theta) = \\frac{u \\cdot v}{||u|| \\cdot ||v|| }$$ $$or$$ $$\\theta = \\cos^{-1}(\\frac{u\\cdot v}{\\sqrt{(v \\cdot v) \\times(u \\cdot u)}})\\] <ul> <li>Let us find the angle between the vectors \\((3,4)\\) and \\((1,5)\\) in \\(\\mathbb{R}^2\\)</li> <li>The angle is measured in degrees or radians \\(( 0 \\text{ and } 2\\pi)\\)</li> <li>It is clockwise from the positive \\(x\\)-axis</li> <li>The angle is often described by computing its trigonometrix function \\((e.g. \\sin, \\cos, \\tan)\\)</li> </ul>"},{"location":"MATHS2/7.03%20-%20Lengths%20and%20angle/#the-dot-product-and-the-angle-between-two-vectors-in-mathbbr2","title":"The dot product and the angle between two vectors in \\(\\mathbb{R}^2\\)","text":"<ul> <li>Let \\(u\\) and \\(v\\) be two vectors in \\(\\mathbb{R}^2\\). Then we can compute the angle \\(\\theta\\) between the vectors \\(u\\) and \\(v\\) using the dot products as:   $$   \\cos(\\theta) = \\frac{u\\cdot v}{\\sqrt{(v \\cdot v) \\times(u   \\cdot u)}}   $$   $$ \\text{or}$$   $$   \\theta = \\cos^{-1}(\\frac{u\\cdot v}{\\sqrt{(v \\cdot v) \\times(u \\cdot u)}})   $$</li> </ul>"},{"location":"MATHS2/7.03%20-%20Lengths%20and%20angle/#the-dot-product-of-two-vectors-in-mathbb3","title":"The dot product of two vectors in \\mathbb{3}$","text":"<ul> <li>Consider the two vectors \\((1, 2, 3)\\) and \\((2, 0, 1)\\) in \\(\\mathbb{R}^3\\). The dot product of these two vectors gives us a scalar as follows:   \\(\\((1,2,3) \\cdot (2,0,1) = 1 \\times 2 + 2 \\times 0 + 3 \\times 1 = 5\\)\\)</li> </ul>"},{"location":"MATHS2/7.03%20-%20Lengths%20and%20angle/#length-of-vector-in-mathbbr3","title":"Length of vector in \\(\\mathbb{R}^3\\)","text":"<ul> <li>Finding the length of the vector \\((4,3,3)\\) in \\(\\mathbb{R}^3\\)</li> <li>Using the formula we get:</li> <li>\\(\\sqrt{4^2 + 3^2 + 3^2} = \\sqrt{16 + 9 + 9} = \\sqrt{34} = 5.83\\text{ units}\\)</li> </ul>"},{"location":"MATHS2/7.03%20-%20Lengths%20and%20angle/#angle-between-two-vectors-in-mathbbr3","title":"Angle between two vectors in \\(\\mathbb{R}^3\\)","text":"<ul> <li>Finding the angle \\(\\theta\\) between \\((1,0,0) \\text{ and } (1,0,1).\\)</li> <li>Using the formula:</li> <li>\\((1,0,0). (1, 0, 1)= 1, (1, 0, 1). (1, 0, 1) = 2,(1, 0, 0) . (1, 0, 0) = 1\\)</li> <li>Hence, \\(\\theta = \\cos^{-1}(\\frac{1}{\\sqrt{2}}) = 45^{\\circ}\\)</li> </ul>"},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/","title":"Inner Product","text":""},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/#definition","title":"Definition","text":"<ul> <li>An inner product on a vector space \\(V\\) is a function:   \\(\\(&lt; .\\ ,\\ . &gt;: V \\times V \\rightarrow \\mathbb{R}\\)\\)</li> <li>It is an inner product when it satisfies all the conditions mentioned below.</li> </ul>"},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/#conditions","title":"Conditions","text":"<ul> <li>\\(&lt;v_1,v_2&gt; = &lt;v_2,v_1&gt;\\)</li> <li>\\(&lt;v_1+v_2,v_3&gt; = &lt;v_1,v_3&gt; + &lt;v_2,v_3&gt;\\)</li> <li>\\(&lt;cv_1,v_2&gt; = c&lt;v_1,v_2&gt; = &lt;v_1,cv_2&gt;\\)</li> <li>\\(&lt;v_1,v_1&gt; \\geq 0\\)</li> <li>\\(&lt;v_1,v_1&gt; = 0 \\iff v_1 = 0\\)</li> <li>A vector space \\(V\\) together with an inner product \\(&lt; .\\ ,\\ . &gt;\\) is called an inner product space.</li> </ul>"},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/#dot-product","title":"Dot Product","text":"<ul> <li>The dot product is a special case of an inner product.</li> <li>\\(u,v \\in \\mathbb{R}^2\\) \\(\\(u \\cdot v = &lt;u,v&gt; = u_1v_1 + u_2v_2 + \\dots + u_nv_n\\)\\)</li> </ul>"},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/#norm","title":"Norm","text":""},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/#defination","title":"Defination","text":"\\[|| \\ \\cdot \\ || : V \\rightarrow \\mathbb{R}$$ $$ x \\rightarrowtail ||x|| = \\sqrt{&lt;x,x&gt;}\\] <ul> <li>It is an inner product when it satisfies all the conditions mentioned below.</li> </ul>"},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/#conditions_1","title":"Conditions","text":"<ul> <li>\\(|| x + y || \\leq ||x|| + ||y||\\)</li> <li>\\(||cx|| = |c| ||x||\\)</li> <li>\\(||x|| \\geq 0\\) and \\(||x|| = 0 \\iff x = 0\\)</li> <li>All inner products satify the conditions of norms</li> </ul>"},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/#length","title":"Length","text":"<ul> <li>The length of the vector \\(x\\) is the norm of the vector \\(x\\).   \\(\\(||u|| = \\sqrt{(x_1^2+ x_2^2 + \\dots + x_n^2)}\\)\\)</li> <li>The length function \\(\\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is the norm of the vector space \\(\\mathbb{R}^n\\).</li> </ul>"},{"location":"MATHS2/7.04%20-%20Inner%20Product%20and%20Norm/#example","title":"Example","text":"<ul> <li>The following is an expample of a norm of \\(\\mathbb{R}^n\\)</li> <li>Defining \\(||u||_1 = |x_1| + |x_2| + \\dots + |x_n| \\text{ for all } u = (x_1,x_2,\\dots,x_n) \\in \\mathbb{R}^n\\)</li> <li>\\(||u||_1\\) satisfies the \\(0\\) condtion of the norm because it can only be \\(0\\) when all the values in \\(u\\) are \\(0\\).</li> <li>\\(||cu||_1 = |cx_1| + |cx_2| + \\dots + |cx_n| = |c|(|x_1| + |x_2| + \\dots + |x_n|) = |c| (|x_1| + |x_2| + \\dots + |x_n|)\\) This also statisfies the scalar multiplication condition of the norm.</li> <li>\\(||u+v||_1 \\leq |x_1 + y_1| + |x_2 + y_2| + \\dots + |x_n + y_n|\\). This also statisfies the triangle inequality condition of the norm.</li> <li>\\(\\therefore ||u||_1\\) is a norm of \\(\\mathbb{R}^n\\)</li> </ul>"},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/","title":"Orthogonality","text":""},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/#definition","title":"Definition","text":"<ul> <li>Two vectors \\(u,v \\in V\\) are orthogonal if \\(&lt;u,v&gt; = 0\\) or \\(u \\cdot v = 0\\).</li> <li>It depends on the inner product of the vector space.</li> <li>Different inner products can lead to different definitions of orthogonality.</li> </ul>"},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/#example","title":"Example","text":"<ul> <li>Consider the \\(\\mathbb{R}^2\\) with inner product</li> <li>\\(&lt;u,v&gt; = x_1y_1 - (x_2y_2 + x_2y_1) + 2x_2y_2\\)</li> <li>Then the vectors \\((1,1)\\) and \\((1,0)\\) are orthogonal.</li> <li>\\(&lt;u,v&gt; = 1 \\times 1 - (1 \\times 0 + 1 \\times 1) + 2 \\times 0 = 0\\)</li> </ul>"},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/#an-orthogonal-set-of-vectors","title":"An Orthogonal set of vectors","text":"<ul> <li>An orthogonal set of vectors of an inner product space \\(V\\) is a set of vectors whose elements are mutually orthogonal.</li> <li>Explicitly, if \\(S = \\{v_1,v_2,\\dots,v_n\\}\\) is an orthogonal set of vectors, then \\(&lt;v_i,v_j&gt; = 0\\) for all \\(i \\neq j\\).   \\(\\(&lt;v_i,v_j&gt; = 0 \\text{ for all } i,j \\in \\{1,2, \\dots, k\\} \\text{ and } i \\neq j\\)\\)</li> </ul>"},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/#example_1","title":"Example","text":"<ul> <li>Consider \\(\\mathbb{R}^3\\) with the usual inner product. Then the set \\(S = \\{(4,3, -2), (-3, 2, -3), (-5, 18, 17)\\}\\) is an orthogonal set of vectors.</li> </ul>"},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/#orthogonality-and-linear-independence","title":"Orthogonality and Linear Independence","text":"<ul> <li>Let \\(V\\) be an orthogonal set of vectors in the inner product space \\(V\\).</li> <li>Then \\(V\\) is linearly independent if and only if \\(V\\) is orthogonal.</li> </ul>"},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/#proof","title":"Proof","text":"<ul> <li>If \\(V\\) is orthogonal, then \\(&lt;v_i,v_j&gt; = 0\\) for all \\(i \\neq j\\).</li> <li>Thus, \\(v_i\\) is orthogonal to \\(v_j\\) for all \\(i \\neq j\\).</li> <li>Thus, \\(v_i\\) is linearly independent of \\(v_j\\) for all \\(i \\neq j\\).</li> <li>Thus, \\(V\\) is linearly independent.</li> </ul>"},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/#orthogonal-basis","title":"Orthogonal Basis","text":"<ul> <li>Let V be an inner product space. A basis consisting of mutually orthogonal vectors is called an orthogonal basis.   Since an orthogonal set of vectors is already linearly independent, an orthogonal set is a basis precisely when it is a maximal orthogonal set (i.e. there is no orthogonal set strictly containing this one).</li> <li>If \\(dim(V) = n\\), then   \\(\\(\\text{orthogonal basis = orthogonal set of n vectors.}\\)\\)</li> </ul>"},{"location":"MATHS2/8.01%20-%20Orthogonality%20and%20Linear%20Independence/#example_2","title":"Example","text":"<ul> <li>The standard basis</li> <li>\\(S = \\{(4,3, -2), (-3, 2, -3), (-5, 18, 17)\\}\\)</li> <li>Consider \\(\\mathbb{R}^2\\) with the inner product \\(&lt;(x_1,x_2),(y_1,y_2)&gt; = x_1y_1 - (x_2y_2 + x_2y_1) + 2x_2y_2\\)</li> <li>Then the basis \\(\\{(1,0), (0,1)\\}\\) is an orthogonal basis.</li> </ul>"},{"location":"MATHS2/8.02%20-%20Orthonormal%20Basis/","title":"What is an Orthonormal Set?","text":"<ul> <li>An orthonormal set of vectors of an inner product space \\(V\\) is an orthogonal set of vectors such that the norm of each vector of the set is \\(1\\).</li> <li>Suppose \\(S \\in V\\), then \\(S\\) is an orthonormal set if and only if   \\(\\(\\|v_i\\| = 1 \\text{ for all } i \\in \\{1,2, \\dots, k\\}\\)\\) \\(\\(&lt;v_i,v_j&gt; = 0 \\text{ for all } i,j \\in \\{1,2, \\dots, k\\} \\text{ and } i \\neq j\\)\\)</li> </ul>"},{"location":"MATHS2/8.02%20-%20Orthonormal%20Basis/#what-is-an-orthonormal-basis","title":"What is an Orthonormal Basis?","text":"<ul> <li>An orthonormal basis is an orthonormal set of vectors which forms a basis.</li> <li>Equivalently : An orthonormal basis is an orthogonal basis where the norm of each vector is 1.</li> <li>Equivalently : An orthonormal basis is a maximal orthonormal set.</li> <li>Example : The standard basis w.r.t. the usual inner product forms an orthonormal basis.</li> </ul>"},{"location":"MATHS2/8.02%20-%20Orthonormal%20Basis/#example","title":"Example","text":"<ul> <li>Consider \\(\\mathbb{R}^3\\) with the usual inner product. Then the set \\(S = \\{\\frac{1}{3}(,2, 2), \\frac{1}{3}(-2,-1, -2), \\frac{1}{3}(2, -2, 1)\\}\\) is an orthonormal basis in \\(\\mathbb{R}^3\\).</li> </ul>"},{"location":"MATHS2/8.02%20-%20Orthonormal%20Basis/#obtaining-an-orthonormal-sets-from-an-orthogonal-sets","title":"Obtaining an Orthonormal sets from an Orthogonal sets","text":"<ul> <li>Let V be an inner product space. If \\(S\\) is an orthogonal set of vectors, then we can obtain an orthonormal set of vectors \\(\\beta\\) from \\(S\\) by dividing each vector \\(v_i\\) by its norm.   \\(\\(\\beta = \\{\\frac{v_1}{\\|v_1\\|}, \\frac{v_2}{\\|v_2\\|}, \\dots, \\frac{v_n}{\\|v_n\\|}\\}\\)\\)</li> </ul>"},{"location":"MATHS2/8.02%20-%20Orthonormal%20Basis/#example_1","title":"Example","text":"<ul> <li>Consider \\(\\mathbb{R}^2\\) with the usual inner product. Then the set \\(S = \\{(4,3), (-3, 2), (-5, 18)\\}\\) is an orthogonal set of vectors.</li> <li>Then \\(\\beta = \\{\\frac{1}{\\sqrt{10}},(1,3), \\frac{1}{\\sqrt{10}(-3,1)}\\}\\) is an orthonormal set of vectors.</li> </ul>"},{"location":"MATHS2/8.02%20-%20Orthonormal%20Basis/#why-orthonormal-bases-are-important","title":"Why Orthonormal Bases are Important?","text":"<ul> <li>Suppose \\(S\\) is an orthonormal basis of an inner product space \\(V\\) and let \\(v \\in V\\)</li> <li>Then \\(v\\) can be written as a linear combination of the vectors in \\(S\\).   \\(\\(v = \\sum_{i=1}^n c_i v_i\\)\\)</li> <li>How do we find the coefficients \\(c_i\\)? For any basis, this means writing a system of linear equations and solving it.</li> <li>But since \\(\\gamma\\) is orthonormal, we can use the inner product and compute the coefficients \\(c_i\\) directly.   \\(\\(c_i = &lt;v, v_i&gt;\\)\\)</li> </ul>"},{"location":"MATHS2/8.02%20-%20Orthonormal%20Basis/#example_2","title":"Example","text":"<ul> <li>\\(\\{\\frac{1}{\\sqrt{10}},(1,3), \\frac{1}{\\sqrt{10}(-3,1)}\\) is an orthonormal basis of \\(\\mathbb{R}^2\\). Write \\((2,5)\\) as a linear combination in terms of these basis vectors.</li> <li>\\(c_1 = &lt;(2,5), \\frac{1}{\\sqrt{10}(1,3)}&gt;\\)</li> <li>\\(c_1 = \\frac{1}{\\sqrt{10}}(2\\cdot 1 + 5\\cdot 3) = \\frac{1}{\\sqrt{10}}(2 + 15) = \\frac{17}{\\sqrt{10}}\\)</li> <li>\\(c_2 = &lt;(2,5), \\frac{1}{\\sqrt{10}(-3,1)}&gt;\\)</li> <li>\\(c_2 = \\frac{1}{\\sqrt{10}}(2\\cdot (-3) + 5\\cdot 1) = \\frac{1}{\\sqrt{10}}(-6 + 5) = \\frac{-1}{\\sqrt{10}}\\)</li> </ul>"},{"location":"MATHS2/8.03%20-%20Projections%20using%20inner%20products/","title":"The projection of a vector a subspace","text":""},{"location":"MATHS2/8.03%20-%20Projections%20using%20inner%20products/#shortest-distance-in-mathbbr2","title":"Shortest Distance in \\(\\mathbb{R}^2\\)","text":"<ul> <li>\\(A\\) and \\(B\\) are points in the plane \\(\\mathbb{R}^2\\) and we want to find the nearest point from \\(B\\) on the line passing through \\(A\\) and the origin. Drop a perpendicular from \\(B\\) on to the line.   Let \\(a\\) and \\(b\\) be the vectors corresponding to the points A and B respectively.</li> </ul>"},{"location":"MATHS2/8.03%20-%20Projections%20using%20inner%20products/#defination","title":"Defination","text":"<ul> <li>Let \\(V\\) be an inner product space, \\(v \\in V\\) and \\(W \\subseteq V\\) be a subspace of \\(V\\). Then the projection of \\(v\\) onto \\(W\\) is in the vector in \\(proj_W(v),\\) computed as follows:   \\(\\(proj_W(v) = \\sum_{i=1}^n&lt;v,v_i&gt;v_i\\)\\)</li> <li>Fact : The definition is independent of the chosen orthonormal basis (i.e. the expression on the RHS does not change even if you choose a different orthonormal basis).</li> <li>The projection of \\(v\\) onto \\(W\\) is the vector in \\(W\\) closest to \\(v\\). Note that \"closest\" is in terms of the distance based on the norm   induced by the inner product.</li> </ul>"},{"location":"MATHS2/8.03%20-%20Projections%20using%20inner%20products/#example","title":"Example","text":"<ul> <li>\\(V = \\mathbb{R}^2, W = &lt;(3,1)&gt;,v = (1,3)\\)</li> <li>\\(\\frac{1}{\\sqrt{10}}(1,3)\\)</li> <li>\\(proj_W(v) = &lt;v,\\frac{1}{\\sqrt{10}}(1,3)&gt; \\times\\sqrt{10}(1,3) = &lt;(1,3),(3,1)&gt;\\frac{1}{10}(3,1) = \\frac{3+3}{10}(3,1) = \\frac{6}{10}(3,1)\\)</li> </ul>"},{"location":"MATHS2/8.03%20-%20Projections%20using%20inner%20products/#projection-on-a-vector-and-orthogonal-bases","title":"Projection on a vector and orthogonal bases","text":"<ul> <li>Let \\(V\\) be an inner product space and \\(v, w \\in V\\) is defined as follows:   \\(\\(proj_w(v) = proj_{&lt;w&gt;}(v)\\)\\)   $$ proj*w(v) =  \\frac{w}{||w||} = \\frac{}{||w||^2}w = \\frac{}{}w$$   \\(\\(proj_W(v) = \\sum_{i=1}^n\\frac{&lt;v,v_i&gt;}{&lt;v_i,v_i&gt;}v_i\\)\\)"},{"location":"MATHS2/8.03%20-%20Projections%20using%20inner%20products/#example_1","title":"Example","text":"<ul> <li>Let \\(W\\) be the 2-dimensional subpsace of \\(V = \\mathbb{R}^3\\) spanned by the orthogonal vectors \\(v_1 = (1,2,1)\\) and \\(v_2 = (1, \u20141, 1)\\). What is the projection of \\(v = (-2,2,2)\\) on \\(W\\).</li> <li>\\(proj_{v1}v = \\frac{&lt;v,v_1&gt;}{v_1,v_1}v_1 = \\frac{4}{6} (1,2,1) = \\frac{2}{3}(1,2,1)\\)</li> <li>\\(proj_{v2}v = \\frac{&lt;v,v_2&gt;}{v_2,v_2}v_2 = -\\frac{2}{3} (1,-1,1)\\)</li> <li>\\(proj_Wv = proj_{v1}v + proj_{v2}v = \\frac{2}{3}(1,2,1) - \\frac{2}{3} (1,-1,1) = (0,1,0)\\)</li> </ul>"},{"location":"MATHS2/8.03%20-%20Projections%20using%20inner%20products/#projection-as-a-linear-transformation","title":"Projection as a linear transformation","text":"<ul> <li>Let \\(V\\) be an inner product space and \\(W\\) be a subspace of \\(V\\). Then the projection of \\(v\\) onto \\(W\\) is the unique vector in \\(W\\) that is closest to \\(v\\) in the sense of the norm induced by the inner product.</li> <li>\\(P_w(v)\\) is the linear transformation that maps \\(v\\) to the projection of \\(v\\) onto \\(W\\).   \\(\\(P_w(v) = proj_W(v)\\)\\) \\(\\(P_W(v_1 + v_2) = P_W(v_1) + P_W(v_2) \\ \\And \\ P_W(cv) = cP(v)\\)\\)</li> <li>It follows all the properties of a linear transformation.</li> </ul>"},{"location":"MATHS2/8.03%20-%20Projections%20using%20inner%20products/#properties","title":"Properties","text":"<ul> <li>\\(P_W(v) =v, \\forall v \\in W\\)</li> <li>\\(Image(P_W) = W\\)</li> <li>\\(W^{\\perp} = \\{ v| v \\in V,\\) such that \\(&lt;v,w&gt; = 0 \\ \\forall w \\in W\\}\\) is the null space of \\(P_W\\)</li> <li>\\(P_W^2 = P_W\\)</li> <li>\\(||P_W(v)|| \\leq ||v||\\)</li> </ul>"},{"location":"MATHS2/8.04%20-%20Gram-Schmidt%20Process/","title":"Gram-Schmidt Process","text":""},{"location":"MATHS2/8.04%20-%20Gram-Schmidt%20Process/#definition","title":"Definition","text":"<ul> <li>The Gram-Schmidt process is a method for constructing an orthogonal basis from a given linearly independent set of vectors.</li> </ul>"},{"location":"MATHS2/8.04%20-%20Gram-Schmidt%20Process/#finding-an-orthogonal-basis-using-inner-products-and-projections","title":"Finding an Orthogonal Basis using inner products and projections","text":""},{"location":"MATHS2/8.04%20-%20Gram-Schmidt%20Process/#example-and-intuition","title":"Example and Intuition","text":"<ul> <li>Consider the basis \\(\\beta = \\{(1,2,2), (-1,0,2),(0,0,1)\\}\\) in \\(\\mathbb{R}^3\\).</li> <li>Let \\(v_1 = (1,2,2).\\) We want a vector which is orthogonal to $v_1 a vector in \\(&lt;v_1&gt;\\), so we can use the projection \\(P_{v_1}\\) to \\(v_1\\).</li> <li>Define \\(v_2 = (-1,0,2) - P_{v_1}((-1,0,2))\\)<ul> <li>\\(\\Rightarrow (-1,0,2) - \\frac{&lt;(-1,0,2), (1,2,2)&gt;}{&lt;(1,2,2), (1,2,2)&gt;} (1,2,2)\\)</li> <li>\\(\\Rightarrow (-\\frac{4}{3},-\\frac{2}{3}, \\frac{4}{3})\\)</li> </ul> </li> <li>\\(W^\\perp = \\{ v | &lt;v,w&gt; = 0 \\forall w \\in W\\} = \\text{ Nullspace of } P_W\\)</li> <li>\\(P_W(v) = 0 \\leftrightarrow v \\in W^\\perp\\)</li> <li>We want a vector which is orthogonal to both \\(v_1\\) and \\(v_2\\), a vector in the \\(Span(\\{v_1,v_2\\})^\\perp\\), so we can use the projection \\(P_{Span(\\{v_1,v_2\\})}\\) to \\(Span(\\{v_1,v_2\\})\\).</li> <li>Define \\(v_3 = (0,0,1) - P_{v_1}((0,0,1)) - P_{v_2}((0,0,1))\\)</li> <li>\\(\\Rightarrow (0,0,1) - \\frac{&lt;(0,0,1), (1,2,2)&gt;}{&lt;(1,2,2), (1,2,2)&gt;} (1,2,2) - \\frac{&lt;(0,0,1), (-\\frac{4}{3},-\\frac{2}{3}, \\frac{4}{3})&gt;}{&lt;(-\\frac{4}{3},-\\frac{2}{3}, \\frac{4}{3}), (-\\frac{4}{3},-\\frac{2}{3}, \\frac{4}{3})&gt;} (-\\frac{4}{3},-\\frac{2}{3}, \\frac{4}{3})\\)</li> <li>\\(\\Rightarrow (\\frac{2}{9}, -\\frac{2}{9}, \\frac{1}{9})\\)</li> </ul>"},{"location":"MATHS2/8.04%20-%20Gram-Schmidt%20Process/#finding-an-orthogonal-basis-using-the-gram-schmidt-process","title":"Finding an Orthogonal Basis using the Gram-Schmidt Process","text":""},{"location":"MATHS2/8.04%20-%20Gram-Schmidt%20Process/#algorithm","title":"Algorithm","text":"<ul> <li>Let \\(V\\) be an inner product space with basis \\(\\{ x_1, x_2, \\dots, x_n\\}\\). Define the orthogonal basis \\(\\{ v_1, v_2, \\dots, v_n\\}\\) and the corresponding orthonormal basis \\(\\{ w_1, w_2, \\dots, w_n\\}\\) as follows:</li> <li>\\(v_1 = x_1; w_1 = \\frac{v_1}{||v_1||}\\)</li> <li>\\(v_2 = x_2 - &lt;x_2,w_1&gt; w_1 ; w_2 = \\frac{v_2}{||v_2||}\\)</li> <li>\\(\\vdots\\)</li> <li>\\(v_n = x_n - &lt;x_n,w_1&gt; w_1 - \\dots - &lt;x_n,w_{n-1}&gt; w_{n-1} ; w_n = \\frac{v_n}{||v_n||}\\)</li> </ul>"},{"location":"MATHS2/8.05%20-%20Orthogonal%20Transformation%20and%20rotations/","title":"What are orthogonal transformations","text":"<ul> <li>Let \\(V\\) be an inner product space and \\(T\\) be a linear transformation from \\(V\\) to \\(V\\). \\(T\\) is said to be Orthogonal Transformation if:   \\(\\(&lt;Tv,Tw&gt; = &lt;v,w&gt; \\forall v, w \\in V\\)\\)</li> <li>When \\(V = \\mathbb{R}^n\\) with the usual inner product, a linear transformation \\(T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n\\) is orthogonal if and only if Preserves angles and lengths.</li> <li>It is enough to demand that the linear transformation pre-serves lengths.In that case, angles automatically get preserved (think of triangle congruences).</li> </ul>"},{"location":"MATHS2/8.05%20-%20Orthogonal%20Transformation%20and%20rotations/#finding-the-rotation-matrix-in-mathbbr2","title":"Finding the rotation matrix in \\(\\mathbb{R}^2\\)","text":"<ul> <li>Consider the standard basis \\(\\{ (1,0), (0,1)\\}\\) in \\(\\mathbb{R}^2\\). Rotate the plane by the angle \\(\\theta\\). The vectors obtained after the tell us the matrix corresponding to this linear transformation.   \\(\\(R_\\theta = \\begin{bmatrix} \\cos \\theta &amp; -\\sin \\theta \\\\ \\sin \\theta &amp; \\cos \\theta \\end{bmatrix}\\)\\)</li> </ul>"},{"location":"MATHS2/8.05%20-%20Orthogonal%20Transformation%20and%20rotations/#note","title":"Note","text":"<ul> <li>\\(R_\\theta^T = R_{-\\theta}\\)</li> <li>\\(R_\\theta \\times R_\\theta^T = R_\\theta^T \\times R_\\theta = I\\)</li> <li>Further note that since angles and lengths are preserved and the standard basis is orthonormal, the rotated vectors are also orthonormal and therefore yield an orthonormal basis of \\(\\mathbb{R}^2\\).</li> </ul>"},{"location":"MATHS2/8.05%20-%20Orthogonal%20Transformation%20and%20rotations/#finding-the-rotation-matrix-in-mathbbr3","title":"Finding the rotation matrix in \\(\\mathbb{R}^3\\)","text":"<ul> <li> <p>Consider the rotations about the axes in \\(\\mathbb{R}^3\\). Since these clearly preserve angles and distances and are linear transformations, they are orthogonal transformations.</p> </li> <li> <p>Rotations about the axes can be described by considering its effect on the standard basis \\(\\{e_1, e_2, e_3\\}.\\)</p> </li> <li> <p>When considering the rotation about the \\(Z-axis\\), \\(e_3\\) remains unchanged and the \\(X Y-\\text{plane}\\) gets rotated exactly as in the previous case of \\(\\mathbb{R}^2\\). Therefore its matrix is   \\(\\(T_3{\\theta} = \\begin{bmatrix} \\cos \\theta &amp; -\\sin \\theta &amp; 0 \\\\ \\sin \\theta &amp; \\cos \\theta &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix}\\)\\)</p> </li> <li>If we fix the \\(X-axis\\) and rotate the \\(Y Z-\\text{plane}\\), we get   \\(\\(T_2{\\theta} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; \\cos \\theta &amp; -\\sin \\theta \\\\ 0 &amp; \\sin \\theta &amp; \\cos \\theta \\end{bmatrix}\\)\\)</li> <li>If we fix the \\(Y-axis\\) and rotate the \\(X Z-\\text{plane}\\), we get   \\(\\(T_1{\\theta} = \\begin{bmatrix} \\cos \\theta &amp; 0 &amp; \\sin \\theta \\\\ 0 &amp; 1 &amp; 0 \\\\ -\\sin \\theta &amp; 0 &amp; \\cos \\theta \\end{bmatrix}\\)\\)</li> </ul>"},{"location":"MATHS2/8.05%20-%20Orthogonal%20Transformation%20and%20rotations/#note_1","title":"Note","text":"<ul> <li>\\(T_i{\\theta}^T = T_i{-\\theta}\\)</li> <li>\\(T_i({\\theta}) \\times T_i({\\theta})^T = T_i({\\theta})^T \\times T_i({\\theta}) = I\\)</li> </ul>"},{"location":"MATHS2/8.05%20-%20Orthogonal%20Transformation%20and%20rotations/#example","title":"Example","text":"<ul> <li>A linear transformation \\(T: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^3\\), where</li> <li>\\(T(x_1,x_2,x_3) = \\frac{1}{3}(x_1 - 2x_2 + 2x_3, 2x_1 - x_2 - 2x_3, 2x_1 + 2x_2 + x_3)\\)</li> <li>Then evaluating \\(T\\) on the standard basis \\(\\{e_1, e_2, e_3\\}\\), we get   \\(\\(T(e_1) = \\frac{1}{3}(1, 2, 2)\\)\\) \\(\\(T(e_2) = \\frac{1}{3}(-2, -1, 2)\\)\\) \\(\\(T(e_3) = \\frac{1}{3}(2, -2, 1)\\)\\)</li> <li>Therefore, the matrix corresponding to \\(T\\) is   \\(\\(T = \\frac{1}{3}\\begin{bmatrix} 1 &amp; -2 &amp; 2 \\\\ 2 &amp; -1 &amp; 2 \\\\ 2 &amp; -2 &amp; 1 \\end{bmatrix}\\)\\)   $$T^T = A^T = \\frac{1}{3}\\begin{bmatrix} 1 &amp; 2 &amp; 2 \\ -2 &amp; -1 &amp; -2 \\ 2 &amp; 2 &amp; 1 \\end{bmatrix}.</li> <li>As \\(\\{v_1,v_2,v_3\\}\\) is an othonormal basis set, the linear transformation \\(T\\) is Orthogonal Transformation.</li> <li>Because \\(A^T A = I_3\\)</li> </ul> <p>Yes, now that you have found the projections of the point \\((3,4,5)\\) onto the basis vectors \\(\\mathbf{u}_1=(1,0,-1)\\) and \\(\\mathbf{u}_2=(0,1,-1)\\), you can use them to find the closest point on the plane to the original point.</p> <p>To do this, you can use the fact that the closest point on the plane to a given point is the projection of that point onto the plane. Since the plane is defined by the equation \\(x+y+z=0\\), we can write its normal vector as \\(\\mathbf{n}=(1,1,1)\\).</p> <p>Then, the projection of the point \\((3,4,5)\\) onto the plane is given by:</p> \\[\\operatorname{proj}_{\\mathbf{n}}\\begin{pmatrix}3\\4\\5\\end{pmatrix}=\\left(\\frac{\\begin{pmatrix}3\\4\\5\\end{pmatrix}\\cdot\\mathbf{n}}{|\\mathbf{n}|^2}\\right)\\mathbf{n}=\\left(\\frac{3+4+5}{3}\\right)\\begin{pmatrix}1\\1\\1\\end{pmatrix}=\\begin{pmatrix}4\\4\\4\\end{pmatrix}\\] <p>So the closest point on the plane to the original point \\((3,4,5)\\) is \\((4,4,4)\\).</p> <p>To find the closest distance between the point \\((3,4,5)\\) and the plane, you can calculate the distance between the original point and the closest point on the plane using the distance formula:</p> \\[d=|\\begin{pmatrix}3\\4\\5\\end{pmatrix}-\\begin{pmatrix}4\\4\\4\\end{pmatrix}|=\\sqrt{(3-4)^2+(4-4)^2+(5-4)^2}=\\sqrt{3}\\] <p>So the closest distance between the point \\((3,4,5)\\) and the plane \\(x+y+z=0\\) is \\(\\sqrt{3}\\).</p>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/","title":"Scalared valued multivariable functions","text":"<ul> <li>A sclar valued multivariable function is a function \\(f : D \\rightarrow \\mathbb{R}\\) where \\(D\\) is a domain in \\(\\mathbb{R}^n\\), where \\(n &gt; 1\\).</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#example","title":"Example","text":"<ul> <li>Linear transformation</li> <li>Polynomial functions</li> <li>(Arithmetic) combinations or compositions of functions</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#vector-valued-multivariable-functions","title":"Vector valued multivariable functions","text":"<ul> <li> <p>A sclar valued multivariable function is a function \\(f : D  \\rightarrow \\mathbb{R}^m\\) where \\(D\\) is a domain in \\(\\mathbb{R}^n\\), where \\(m,n &gt; 1\\).</p> </li> <li> <p>It can be thought of as a vector of scalar valued multivariable functions.</p> </li> <li>We have seen the example of a linear transformation.</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#multivariable-functions-or-function-of-several-variables","title":"Multivariable functions (or function of several variables)","text":"<ul> <li>A multivariable function or a function of several variables is either a scalar-valued multivariable function or a vector-valued multivariable function.</li> <li>When considering a multivariable functions, we will write \\(f : D \\rightarrow \\mathbb{R}^m\\) where \\(D\\) is a domain in \\(\\mathbb{R}^n\\) where \\(n &gt; 1\\) and with no restriction on \\(m\\) (it can also be 1).</li> <li>Further, if we want to refer to an element in \\(D\\) without bothering about the coordinates, we will use \\(x \\in D\\)</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#example_1","title":"Example","text":"<ul> <li>\\(f(x,y) = 2.5x - 3.5y\\)</li> <li>\\(f(x,y) = 2x^3 - 3y^2 + \\pi\\)</li> <li>\\(f(x,y) = \\sin(x^2 + y^2)\\)</li> <li>\\(f(x,y) = \\frac{1}{2\\pi} e^{\\frac{x^2+y^2}{2}}\\)</li> <li>\\(f(x,y) = 10x^{-2x-5y}\\)</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#arithmetic-operations-on-multivariable-functions","title":"Arithmetic operations on multivariable functions","text":"<ul> <li> <p>Let \\(D \\in \\mathbb{R}^n\\) and \\(f : D \\rightarrow \\mathbb{R}^m\\) be a multivariable function on \\(D\\).</p> </li> <li> <p>Addition</p> </li> <li>The sum function \\(f+g\\) is defined on \\(D\\) by:</li> <li>Then \\((f+g)(x) = f(x) +g(x)\\) for all \\(x \\in D\\).</li> <li>Scalar multiplication</li> <li>The scalar multiplication function \\(k \\cdot f\\) is defined on \\(D\\) by:</li> <li>Then \\((k \\cdot f)(x) = k \\cdot f(x)\\) for all \\(x \\in D\\).</li> <li>Multiplication</li> <li>If \\(m=1\\), the product function \\(fg\\) is defined on \\(D\\) by:</li> <li>\\(fg(x) = f(x)g(x)\\) for all \\(x \\in D\\).</li> <li>Division</li> <li>If \\(m=1\\), the quotient function \\(\\frac{f}{g}\\) is defined on \\(D\\) by:</li> <li>\\(\\frac{f}{g}(x) = \\frac{f(x)}{g(x)}\\) for all \\(x \\in D\\).</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#functions-obtained-by-composition","title":"Functions obtained by composition","text":"<ul> <li>Let \\(D \\subset \\mathbb{R}^n\\) and \\(f : D \\rightarrow \\mathbb{R}^m\\) be a multivariable function.</li> <li>Let \\(g: E \\rightarrow \\mathbb{R}^p\\) be a function on \\(E\\) where \\(Range(f) \\subseteq E\\).</li> <li>Then for each \\(x \\in D, f(x) \\in E\\) and therefore \\(g(f(x))\\) yields a well-defined element in \\(\\mathbb{R}^p\\).</li> <li>Thus, we obtain a multivariable function \\(g \\circ f: D \\rightarrow \\mathbb{R}^p\\) called the composition of \\(g\\) and \\(f\\) defined as follows:   \\(\\(g \\circ f(x) = g(f(x)), x \\in D\\)\\)</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#example_2","title":"Example","text":"<ul> <li>\\(f(x,y) = x^2 + y^2\\) is a function \\(\\mathbb{R}^2 \\rightarrow \\mathbb{R}\\).</li> <li>\\(g(x) = \\sqrt{x}\\)</li> <li>Then \\(g \\circ f(x,y) = \\sqrt{x^2 + y^2}\\) is a function \\(\\mathbb{R}^2 \\rightarrow \\mathbb{R}\\).</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#curves-in-mathbbrm","title":"Curves in \\(\\mathbb{R}^m\\)","text":"<ul> <li>A curves in \\(\\mathbb{R}^m\\) refers to the range of a function \\(f : D \\rightarrow \\mathbb{R}^m\\) where \\(D\\) is a domain in \\(\\mathbb{R}\\)</li> </ul>"},{"location":"MATHS2/9.01%20-%20Multivariable%20functions/#examples","title":"Examples","text":"<ul> <li>Line in \\(\\mathbb{R}^m\\)</li> <li>\\(\\gamma(f)\\) where \\(f\\) is a function of one variable</li> <li>Conics in \\(\\mathbb{R}^2\\)</li> <li>Helix in \\(\\mathbb{R}^3\\)</li> </ul>"},{"location":"MATHS2/9.02%20-%20Partial%20Derivative/","title":"Rate of change w.r.t. a particular variable at a point","text":"<ul> <li>Let \\(f(x_1, x_2, \\ldots, x_n)\\) be a function on domain \\(D\\) in \\(\\mathbb{R}^n\\) containing a point \\(a\\) and an open ball around it.</li> <li>Then the rate of change of \\(f\\) at \\(a\\) w.r.t. \\(x_i\\) is defined as:   \\(\\(\\lim_{h \\rightarrow 0} \\frac{f(a + he_i) - f(a)}{h}\\)\\) \\(\\(a = (a_1, a_2, \\ldots, a_n); e_i = (0, \\ldots, 0, 1, 0, \\ldots, 0)\\)\\)</li> </ul>"},{"location":"MATHS2/9.02%20-%20Partial%20Derivative/#example","title":"Example","text":"<ul> <li>\\(f(x,y) = x + y\\) at \\((0,0)\\)</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{f((0,0) + h(1,0)) - f(0,0)}{h}\\)</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{f(h,0) - f(0,0)}{h}\\)</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{h - 0}{h}\\)</li> <li>\\(\\lim_{h\\rightarrow 0}1 = 1\\)</li> <li>The rate of change of \\(f(x,y,z) = xy + yz + zx \\text { at } (1,2,3)\\) w.r.t. \\(y\\).</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{f((1,2,3)+h(0,1,0)) - f(1,2,3)}{h}\\)</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{f(1,2+h,3) - f(1,2,3)}{h}\\)</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{4h}{h} = 4\\)</li> <li>Th rate of change of \\(f(x,y) = \\sin(xy) \\text { at } (1,0)\\) w.r.t. x</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{f((1,0)+h(1,0)) - f(1,0)}{h}\\)</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{\\sin((1+h),0) - \\sin(1,0)}{h}\\)</li> <li>\\(\\lim_{h\\rightarrow 0}\\frac{0-0}{h}=0\\)</li> </ul>"},{"location":"MATHS2/9.02%20-%20Partial%20Derivative/#partial-derivative","title":"Partial Derivative","text":"<ul> <li>Let \\(f(x_1, x_2, \\ldots, x_n)\\) be a function on domain \\(D\\) in \\(\\mathbb{R}^n\\). The partial derivative of \\(f\\) w.r.t. \\(x_1\\) is the function denoted by \\(\\frac{\\partial f}{\\partial x_1}\\) defined on \\(D\\) by:   \\(\\(\\frac{\\partial f}{\\partial x_1}(x_1, x_2, \\ldots, x_n) = \\lim_{h \\rightarrow 0} \\frac{f(x_1 + h, x_2, \\ldots, x_n) - f(x_1, x_2, \\ldots, x_n)}{h}\\)\\)</li> </ul>"},{"location":"MATHS2/9.02%20-%20Partial%20Derivative/#-its-domain-consists-of-those-points-of-d-at-which-the-limits-exist","title":"- Its domain consists of those points of \\(D\\) at which the limits exist.","text":""},{"location":"MATHS2/9.02%20-%20Partial%20Derivative/#example_1","title":"Example","text":"<ul> <li>\\(f(x,y) = x + y\\)</li> <li> \\[\\frac{\\partial f}{\\partial x}(x,y) = \\lim_{h\\rightarrow 0}\\frac{f(x+h,y) - f(x,y)}{h}\\] </li> <li> \\[\\frac{\\partial f}{\\partial x}(x,y) = \\lim_{h\\rightarrow 0}\\frac{x+h+y-x-y}{h} = \\frac{h}{h}=1\\] </li> <li>Let's say we have a function that depends on two variables, x and y, given by:</li> <li>\\(f(x,y) = x^2y + xy^2\\)</li> <li>We can find the partial derivatives of this function with respect to x and y:</li> <li>\\(\\frac{\\partial f}{\\partial x} = 2xy + y^2\\)</li> <li>\\(\\frac{\\partial f}{\\partial y} = x^2 + 2xy\\)</li> <li> <p>Another example could be a function that depends on three variables, x, y, and z, such as:</p> </li> <li> <p>\\(g(x,y,z) = 2xy + z^3 - xz\\)</p> </li> <li>We can find the partial derivatives of this function with respect to x, y, and z:</li> <li>\\(\\frac{\\partial g}{\\partial x} = -z + 2y\\)</li> <li>\\(\\frac{\\partial g}{\\partial y} = 2x\\)</li> <li> <p>\\(\\frac{\\partial g}{\\partial z} = 3z^2 - x\\)</p> </li> <li> <p>A more complicated example could be a function that depends on four variables, w, x, y, and z, such as:</p> </li> <li> <p>\\(h(w,x,y,z) = 3w^2x + yz^2 - 2wxz\\)</p> </li> <li>We can find the partial derivatives of this function with respect to each variable:</li> <li>\\(\\frac{\\partial h}{\\partial w} = 6wx - 2xz\\)</li> <li>\\(\\frac{\\partial h}{\\partial x} = 3w^2 - 2wz\\)</li> <li>\\(\\frac{\\partial h}{\\partial y} = z^2\\)</li> <li> <p>\\(\\frac{\\partial h}{\\partial z} = 2yz - 2wx\\)</p> </li> <li> <p>In each of these examples, the partial derivative with respect to a particular variable is found by differentiating the function with respect to that variable while treating all other variables as constants.</p> </li> </ul>"},{"location":"MATHS2/9.03%20-%20Directional%20Derivatives/","title":"Rate of change in a perticular direction at a point","text":"<ul> <li>Let \\(f(x_1,x_2, \\dots, x_n)\\) be a function defined on a domain \\(D \\subset \\mathbb{R}^n\\) containing a point \\(a\\) and an open ball around it.</li> <li>Suppose instead of in the direction of axes, we are interested in the rate of change of the function \\(f\\) at \\(a\\) in some other direction.</li> <li>We can use the same idea as for partial derivatives and chose a unit vector \\(\\vec{u} = (u_1, u_2, \\dots, u_n)\\) in the direction of interest.   \\(\\(\\lim_{h \\to 0} \\frac{f(a_1 + hu_1, a_2 + hu_2, \\dots, a_n + hu_n) - f(a_1, a_2, \\dots, a_n)}{h}\\)\\)</li> </ul>"},{"location":"MATHS2/9.03%20-%20Directional%20Derivatives/#example","title":"Example","text":"<ul> <li>The rate of change of \\(f(x,y) = x+y\\) at \\((0,0)\\) in the direction of the \\(y=x\\) line.</li> <li>The unit vector is \\(\\vec{u} = (\\frac{1}{\\sqrt{2}},\\frac{1}{\\sqrt{2}})\\)</li> <li>\\(\\lim_{h \\to 0} \\frac{f(0 + h\\frac{1}{\\sqrt{2}}, 0 + h\\frac{1}{\\sqrt{2}}) - f(0,0)}{h} = \\lim_{h \\to 0} \\frac{h}{\\sqrt{2}} = \\frac{\\sqrt{2}h}{h}\\)</li> <li>The rate of change of \\(f(x,y,z) = xy + yz + zx\\) at \\((1,2,3)\\) in the direction of the vector \\((4,3,0)\\)</li> <li>To get the unit vector we divide the vector by its norm.</li> <li>\\(u = \\frac{v}{||v||} = \\frac{(4,3,0)}{\\sqrt{16+9}} = \\frac{(4,3,0)}{5}\\)</li> <li>\\(lim_{h \\to 0} \\frac{f(1 + h\\frac{4}{5}, 2 + h\\frac{3}{5}, 3) - f(1,2,3)}{h} = \\frac{32}{5}\\)</li> </ul>"},{"location":"MATHS2/9.03%20-%20Directional%20Derivatives/#properties","title":"Properties","text":"<ul> <li>Linearity: Let \\(c \\in \\mathbb{R}\\). If the directional derivative at the point \\(a\\) in the direction of the unit vector \\(u\\) exists for both the functions \\(f(x) \\text{ and } g(x)\\), then it also exists for \\((cf + g)(x)\\) and   \\(\\((cf + g)_u (a) = cf_u(a)+g_u(a)\\)\\)</li> <li>The Product Rule: If the directional derivative at the point \\(a\\) in the direction of the unit vector \\(u\\) exists for both the functions \\(f(x) \\text{ and } g(x)\\), then it also exists for \\((fg)(x)\\) and   \\(\\((fg)_u (a) = f_u(a)g(a) + f(a)g_u(a)\\)\\)</li> <li>The Quotient Rule: If the directional derivative at the point \\(a\\) in the direction of the unit vector \\(u\\) exists for both the functions \\(f(x) \\text{ and } g(x)\\), then it also exists for \\((\\frac{f}{g})(x)\\) and   \\(\\((\\frac{f}{g})_u (a) = \\frac{f_u(a)g(a) - f(a)g_u(a)}{g^2(a)}\\)\\)</li> </ul>"},{"location":"MATHS2/9.03%20-%20Directional%20Derivatives/#example_1","title":"Example","text":"<ul> <li>\\(f(x,y) = x +y\\)</li> <li>\\(\\Rightarrow \\lim_{h \\rightarrow 0} \\frac{f(x+hu_1,y + hu_2) - f(x,y)}{h}\\)</li> <li>\\(\\Rightarrow \\lim_{h \\rightarrow 0} \\frac{(x+hu_1) + (y + hu_2) - (x+y)}{h}\\)</li> </ul>"},{"location":"MATHS2/9.04%20-%20Limits%20for%20scalar-valued%20multivariable%20functions/","title":"Limits of sequences in \\(R^p\\)","text":"<ul> <li>Let \\(\\{ a_n \\}\\) be a sequence in \\(\\mathbb{R}^p\\).</li> <li>\\(a_n = (a_{n1}, a_{n2}, \\dots, a_{np})\\)</li> <li>We say that \\(\\{ a_n\\}\\) has a limit \\(a = (a_1, a_2, \\dots, a_p) \\in \\mathbb{R}^p\\) if as \\(n\\) increases, the sequence in the \\(i^{th}\\) coordinate has a limit \\(a_i\\).</li> <li>A sequence \\(\\{ a_n \\}\\) is convergent if it converges to some point in \\(\\mathbb{R}^p\\).</li> <li>A sequence \\(\\{ a_n \\}\\) is divergent if it does not converge to any point in \\(\\mathbb{R}^p\\).</li> <li>Subsequences of a sequence \\(\\{ a_n \\}\\) are sequences that can be obtained by removing some elements from the original sequence.</li> </ul>"},{"location":"MATHS2/9.04%20-%20Limits%20for%20scalar-valued%20multivariable%20functions/#limits-of-scalar-valued-multivariable-functions-at-a-point","title":"Limits of scalar-valued multivariable functions at a point","text":"<ul> <li>Let \\(f\\) be a scala-valued multivariable function defined on a domain \\(D\\) in \\(\\mathbb{R}^k\\) and \\(a\\) be a point such that there exists a sequence in \\(D\\) which converges to \\(a\\).</li> <li> <p>If tehre exists a real number \\(L\\) such that \\(f(a_n) \\rightarrow L\\) for all sequences \\(a_n\\) such that \\(a_n \\rightarrow a\\), then we say that the limit of \\(f\\) at \\(a\\) exists and is equal to \\(L\\). We write   \\(\\(\\lim_{x \\rightarrow a} f(x) = L\\)\\)</p> </li> <li> <p>\\(\\lim_{x \\rightarrow a} f(x) = L\\) is equivalent to : as \\(x\\) comes closer and closer to \\(a\\) and \\(f(x)\\) eventually comes closer to to \\(L\\).</p> </li> </ul> <p>If there is no such number \\(L\\) then we say that the limit of \\(f\\) at \\(a\\) does not exist.</p>"},{"location":"MATHS2/9.04%20-%20Limits%20for%20scalar-valued%20multivariable%20functions/#rules-for-limits-of-scalar-valued-multivariable-functions","title":"Rules for limits of scalar-valued multivariable functions","text":"<p>\\(\\text{If }\\) \\(\\lim_{x \\rightarrow a} f(x) = F\\), \\(\\lim_{x \\rightarrow a} g(x) = G\\)</p> <ul> <li>\\(\\lim_{x \\rightarrow a} (cf+g)(x) = cF + G\\)</li> <li>\\(\\lim_{x \\rightarrow a} (fg)(x) = FG\\)</li> <li>\\(\\lim_{x \\rightarrow a} (\\frac{f}{g})(x) = \\frac{F}{G}; \\iff G \\neq 0\\)</li> <li>Suppose \\(f\\) is a scalar-valued multivariable function and \\(g\\) is a function of one variable such that the composistion \\(g \\circ f\\) is defined on \\(D\\).</li> <li>\\(\\lim_{x \\rightarrow a} (g \\circ f)(x) = \\lim_{x \\rightarrow a} g(f(x))\\)</li> <li>Sandwich principle: if \\(\\lim_{x \\rightarrow a} f(x) = F\\) and \\(\\lim_{x \\rightarrow a} g(x) = F\\) and \\(f(x) \\leq h(x) \\leq g(x)\\) then \\(\\lim_{x \\rightarrow a} h(x) = F\\)</li> </ul>"},{"location":"MATHS2/9.05%20-%20Limits%20of%20vector-valued%20function%20at%20a%20point/","title":"Limit of a vector valued fucntion at a point","text":"<ul> <li>Let \\(f : D \\rightarrow \\mathbb{R}^m\\) be a vector valued multivariable function defined on the domain \\(D\\) in \\(\\mathbb{R}^k\\) and \\(a\\) be a point such that there exists a sequence in \\(D\\) which converges to \\(a\\).</li> <li>If \\(f_i\\) is the \\(i^{th}\\) component of \\(f\\) then the limit of \\(f\\) at \\(a\\) is defined as scalar valued function from \\(D\\) to \\(\\mathbb{R}\\). Suppose for each \\(i\\) the limit \\(\\lim_{x \\rightarrow a} f_i(x)\\) exists. and equals \\(L_i\\) then:   \\(\\(\\lim_{x \\rightarrow a} f(x) = L\\)\\)</li> <li>This is equivalent to \\(:\\) as \\(x\\) comes closer and closer to \\(a\\), \\(f(x)\\) eventually comes closer and closer to \\(L\\).</li> <li>If for some \\(i\\), the limit \\(f_i\\) at \\(a\\) does not exist, then the limit of \\(f\\) at \\(a\\) does not exist.</li> </ul>"},{"location":"MATHS2/9.05%20-%20Limits%20of%20vector-valued%20function%20at%20a%20point/#limit-of-function-at-a-point-along-a-curve","title":"Limit of function at a point along a curve","text":"<ul> <li>Let \\(f\\) be a scalar-valued mutlivariable function defined on the domain \\(D\\) in \\(\\mathbb{R}^k\\) and \\(a\\) be a point such that there exists a sequence in \\(D\\) which converges to \\(a\\).</li> <li>Let \\(C\\) be a curve passing through the point \\(a\\) belonging to the domain \\(D\\)</li> <li>The limit of \\(f\\) at \\(a\\) along the curve \\(C\\) exists and equals \\(L\\) if for every sequence \\(a_n\\) contained in \\(C\\) which converges to \\(a\\), the sequence \\(f(a_n)\\) converges to \\(L\\).</li> </ul>"},{"location":"MATHS2/9.05%20-%20Limits%20of%20vector-valued%20function%20at%20a%20point/#theorm","title":"Theorm","text":"<ul> <li>The limit of \\(f\\) at \\(a\\) exists and equals \\(L\\) precisely when for every curve \\(C\\) in the domain \\(D\\) passing through \\(a\\) the limit of \\(f\\) at \\(a\\) along \\(C\\) exists and equals \\(L\\).</li> </ul>"},{"location":"MATHS2/9.05%20-%20Limits%20of%20vector-valued%20function%20at%20a%20point/#continuity-of-a-function","title":"Continuity of a function","text":"<ul> <li>Let \\(f\\) be a multivariable function defined on a domain \\(D\\) in \\(\\mathbb{R}^k\\) and \\(a \\in D\\) be a point such that there exists a sequence in \\(D\\) which converges to \\(a\\).</li> <li>Defination \\(:\\) \\(f\\) is conitnuous at \\(a\\) if the limit of \\(f\\) at \\(a\\) exists and \\(\\lim_{x \\rightarrow a} f(x) = f(a)\\). \\(f\\) is continuous at \\(a\\) is equivalent to \\(f(a_n) \\rightarrow f(a)\\) as \\(a_n \\rightarrow a\\).</li> <li>NOTE \\(:\\) continuity means that the limit at \\(a\\) can be obtained by evaluating the function at \\(a\\).</li> </ul>"},{"location":"MATHS2/9.06%20-%20Directional%20Derivatives%20in%20terms%20of%20Gradients/","title":"The Gradient vector / function","text":"<ul> <li>Let \\(f(x_1,x_2, \\dots, x_n)\\) be a function defined on a domain in \\(D\\) in \\(\\mathbb{R}^n\\) containing some open ball around the point \\(a\\).</li> <li>Suppose all the partial derivatives of \\(f\\) exist at \\(a\\). Then the gradient vector of \\(f\\) at \\(a\\) is the vector \\((f_{x_1}(a),f_{x_2}(a),\\dots,f_{x_n}(a))\\) in \\(\\mathbb{R}^n\\). It is denoted by \\(\\nabla f(a)\\).</li> <li>The gradient function of \\(f\\) is a function taking values in \\(\\mathbb{R}^n\\) obtained by associating to every point \\(a\\) its gradient vector \\(\\nabla f(a)\\).</li> <li>The domain of \\(\\nabla f\\)is the set of points in \\(D\\) all of whose partial derivatives exist.</li> </ul>"},{"location":"MATHS2/9.06%20-%20Directional%20Derivatives%20in%20terms%20of%20Gradients/#examples","title":"Examples","text":"<ul> <li>Let \\(f(x,y) = \\sin(xy)\\)</li> <li>Then \\(\\nabla f(a) = (y\\cos(xy),x\\cos(xy))\\)</li> <li>Let \\(f(x,y,z) = x^2+y^2+z^2\\)</li> <li>Then \\(\\nabla f(a) = (2x,2y,2z)\\)</li> </ul>"},{"location":"MATHS2/9.06%20-%20Directional%20Derivatives%20in%20terms%20of%20Gradients/#properties-of-the-gradient","title":"Properties of the Gradient","text":"<ul> <li> <p>Linearity</p> </li> <li> \\[\\nabla (cf+g)(x) = c\\nabla f(x) + \\nabla g(x)\\] </li> <li> <p>Chain Rule</p> </li> <li> \\[\\nabla (fg)(x) = f(x)\\nabla g(x) + g(x)\\nabla f(x)\\] </li> <li> <p>Quotient Rule</p> </li> <li> \\[\\nabla \\frac{f}{g}(x) = \\frac{g(x)\\nabla f(x) - f(x)\\nabla g(x)}{g^2(x)}\\] </li> </ul>"},{"location":"MATHS2/9.06%20-%20Directional%20Derivatives%20in%20terms%20of%20Gradients/#note","title":"Note","text":"<ul> <li>Suppose \\(\\nabla f\\) exists and is continuous on some open vall around the point \\(a\\). Then for every unit vector \\(u\\), the directional derivative \\(f_u(a)\\) exists and equals \\(\\nabla f(a) \\cdot u\\).er</li> </ul>"},{"location":"MLF/G%20Strang%20Solutions/Chapter%201/","title":"Matrices and Gaussian Elimination","text":""},{"location":"MLF/G%20Strang%20Solutions/Chapter%201/#section-12","title":"Section 1.2","text":""},{"location":"MLF/G%20Strang%20Solutions/Chapter%201/#solution-121","title":"Solution 1.2.1","text":"<p>The exercise asks to draw the row and the column pictures for the system of equations</p> \\[\\begin{align} x + y &amp;= 4 \\\\ 2x -2y &amp;= 4 \\end{align}\\] <p>Let's start with the row picture. The first equation produces a line passing through the points  (0,4) and (4,0) (see Figure 1). These points can be easily found if you set a value of one of the variables equal to zero and solve the equation for the other one.</p> <p>In the same way, we can find that the second equation produces the line passing through the points (0,\u22122) and (2,0) (see Figure 1).</p> <p>The point of intersection lies on both lines. It is the only solution to both equations. </p> Figure 1 : Lines meet at x=3 , y=1 <p>The second approach looks at the columns of the linear system. The two separate equations are really one vector equation:</p> \\[x \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} + y \\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 4 \\end{bmatrix}\\] <p>The problem is to find the combination of the column vectors on the left side that produces the vector on the right side</p> <p>Those vectors  (1,2) and (1,\u22122) are represented by the bold arrows in Figure 2. The unknowns are the numbers  \\(x\\) and \\(y\\) that multiply the column vectors. The whole idea can be seen in that figure, where  3 times column 1 is added to column 2. Geometrically this produces a famous parallelogram. Algebraically it produces the correct vector (4,4), on the right side of our equations. The column picture confirms that \\(x =3\\) and \\(y=1\\).</p> <p></p> Figure 2: Columns Combine with 3 and 1"},{"location":"MLF/G%20Strang%20Solutions/Chapter%201/#solution-122","title":"Solution 1.2.2","text":"<p>Step 1 Solve to find a combination of the columns that equals b.</p> \\[\\begin{align} u - v - w &amp;= b_1 \\\\ v + w &amp;= b_2 \\\\ w &amp;= b_3 \\end{align}\\] <p>Step 2 Using Substitution,</p> \\[\\begin{align} \\boxed{w = b_3} \\\\ \\boxed{v} = b_2 - w \\boxed{= b_2 - b_3} \\\\ \\boxed{u} = b_1 + v + w = b_1 + b_2 - b_3 + b_3 \\boxed{= b_1 + b_2} \\end{align}\\] <p>Step 3 (Result)</p> \\[\\begin{align} u &amp;= b_1 + b_2 \\\\ v &amp;= b_2 - b_3 \\\\ w &amp;= b_3 \\end{align}\\]"},{"location":"MLF/G%20Strang%20Solutions/Introduction/","title":"Whats this for?","text":"<p>These are the well explained solutions for the exercises found in \"Linear Algebra and Its Applications (4th Ed)\" by Gilbert Strang.</p> <p>Link to the Book</p>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/","title":"Four Fundamental Subspaces","text":""},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#column-space-ca","title":"Column Space C(A)","text":"<p>The column space of a matrix is the span (set of all possible linear combinations) of its columns.</p> <p>Example</p> <pre><code>A = \n[1,2,3]\n[2,4,6]\n</code></pre> <ul> <li>C(A) = span([1,2])</li> <li>The 2nd and the 3rd column are multiples of the first column.</li> <li>Therefore column space of matrix A is span([1,2])</li> </ul> <p>Note</p> <p>\\(Ax = b\\) will always have a solution for all \\(b \\in C(A)\\) </p>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#null-space-na","title":"Null Space N(A)","text":"<p>The nullspace (also called kernel) of a matrix A is the set of all vectors x that satisfy the equation Ax = 0.</p> <p>Example</p> <pre><code>A = \n[1 2]\n[3 6]\n[4 8]\n</code></pre> <ul> <li>The 2nd and the 3rd rows are the multiples of the first row.</li> <li>Therefore null space of matrix A is \\(x_1 + 2x_2 = 0\\) </li> <li>\\(N(A) = span([-2 , 1])\\)</li> </ul> <p>Note</p> <ul> <li>If A is invertible , then \\(N(A)\\) has \\(\\phi\\) only and \\(C(A)\\) is the whole space.   (If A is invertible means a unique solution exists for \\(Ax = b\\))</li> <li>If \\(N(A)\\) has \\(x_n \\neq 0\\) then , \\(Ax = b\\) solutions are of the form \\(x = x_n + x_p\\) where, \\(Ax_p = b ,     Ax_n = 0\\) </li> </ul>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#row-space-ra","title":"Row Space R(A)","text":"<p>The row space of a matrix A is the span of its row vectors. In other words, it is the set of all possible linear combinations of the rows of A.</p> <p>Example</p> <pre><code>A = \n[1 2 3]\n[4 5 6]\n[7 8 9]\n</code></pre> <ul> <li>The 3rd row is linear combination of the first 2 rows.</li> <li>Therefore \\(R(A) = span([1,2,3] , [4,5,6])\\)</li> </ul> <p>Note</p> <p>The row space of a matrix A can also be written as \\(R(A) = C(A^T)\\)</p>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#left-null-space","title":"Left Null space","text":"<p>It is the same as null space but its for \\(A^T\\)</p>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#orthogonal-vectors-and-subspaces","title":"Orthogonal Vectors and Subspaces","text":""},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#orthogonal-vectors","title":"Orthogonal Vectors","text":"<p>Orthogonal vectors are two or more vectors that are perpendicular to each other, meaning that they form a 90-degree angle at their intersection. Geometrically, two vectors are orthogonal if and only if their dot product is equal to zero. If \\(x = \\begin{bmatrix}x_1 &amp; x_2 &amp; x_3\\end{bmatrix}\\) and \\(y = \\begin{bmatrix}y_1 &amp; y_2 &amp; y_3\\end{bmatrix}\\) then \\(x\\) and \\(y\\) are orthogonal only if  \\(y^T x = 0\\)</p>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#orthogonal-subspaces","title":"Orthogonal Subspaces","text":"<p>Orthogonal subspaces are subspaces of a vector space that are perpendicular to each other. Specifically, two subspaces S and T of a vector space V are said to be orthogonal if every vector in S is orthogonal to every vector in T. This is denoted as S \u22a5 T.</p>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#projections","title":"Projections","text":"<p>\\(p = \\hat{x}a\\) \\(e = b-p\\) \\(e = b - \\hat{x}a\\)</p> <p>\\(e \\perp a\\) \\(b - \\hat{x}a \\perp a\\) \\(a^T(b - \\hat{x}a) = 0\\) \\(\\hat{x} = \\frac{a^Tb}{a^Ta}\\) \\(\\implies p = \\hat{x}a = \\frac{a^Tb}{a^Ta}a\\)</p>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#projection-matrix","title":"Projection matrix","text":"<p>Let \\(\\mathbb{P} = \\frac{aa^T}{a^Ta}\\) , then projection of \\(b\\) onto \\(a\\) is \\(\\mathbb{P}b\\)</p> <p>We can see that to get the projection , we can left multiply the projection matrix on \\(b\\)</p> <p>Projection Matrix Properties</p> <ul> <li>Its idempotent , i.e. \\(\\mathbb{P} = \\mathbb{P}^2\\)</li> <li>It is a symmetric matrix , i.e. \\(\\mathbb{P} = \\mathbb{P}^T\\)</li> <li>The converse of this is also true , if a matrix is idempotent and symmetric then it is  called a projection matrix.</li> </ul>"},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#least-squares","title":"Least Squares","text":""},{"location":"MLF/WEEK%203/Four%20Fundamental%20Subspaces/#minimizing-least-sqaures","title":"Minimizing Least Sqaures","text":"<p>Suppose for a system of linear equations like</p> \\[\\begin{align} 2x = b_1 \\\\ 3x = b_2 \\\\  4x = b_3 \\end{align}\\] <p>The system of linear equations is only solvable if \\(b\\) is on the line through \\(\\begin{pmatrix} 2 \\\\ 3 \\\\ 4\\end{pmatrix}\\)</p> <ul> <li>Problem: The problem with this approach is that for some inputs there is no error and some there might be huge error.</li> <li>Solution: A solution to this problem can be minimizing the average error</li> </ul> \\[E^2 = (2x-b_1)^2 + (3x-b_2)^2 + (4x - b_3)^2\\] <p>To minimize this we will derivate it w.r.t. x and equate it to zero </p> \\[\\begin{align} 2[ 2(2x - b_1) + 3(3x - b_2) + 4(4x - b_3)] &amp;= 0 \\\\ x &amp;= \\frac{2b_1 + 3b_2 + 4b_3}{2^2 + 3^2 + 4^2} \\end{align}\\] <p>We can see that \\(x\\) is very similar to the projection matrix \\(\\frac{a^Tb}{a^Ta}\\) with \\(a = \\begin{pmatrix} 2 \\\\ 3 \\\\ 4\\end{pmatrix}\\)</p> <ul> <li>Projection of \\(b\\) onto \\(S\\) is \\(p = A\\hat{x}\\)</li> <li>Orthogonal vector \\(e = b - p = b - A\\hat{x}\\)</li> </ul> <p>Note</p> <ul> <li>\\(e \\perp\\) to every vector in \\(C(A)\\).</li> <li>Also \\(C(A) \\perp N(A^T)\\) , every vector in \\(C(A)\\) is orthogonal to every vector in \\(N(A^T)\\)</li> <li>\\(e \\in N(A^T)\\) \\(\\implies A^Te = 0\\) \\(\\implies A^T(b - A\\hat{x}) = 0\\)</li> </ul> <p>Final Equation</p> <p>\\(A^TA\\hat{x} = A^Tb\\)</p> <ul> <li>This equation gives the projection of \\(b\\) onto \\(C(A)\\)</li> <li>Even if \\(Ax =b\\) has no solution , this equation has a solution</li> </ul> <p>Properties</p> <p>When columns of \\(A\\) are linearly independent:-</p> <ul> <li>\\(A^TA\\) is invertible </li> <li>Solving \\(A^TA\\hat{x} = A^Tb\\) when \\((A^TA)\\) is invertible gives \\(\\hat{x} = (A^TA)^{-1}A^Tb\\)</li> <li>Projection \\(\\mathbb{P} = A\\hat{x} = A(A^TA)^{-1}A^Tb\\)</li> </ul> <p>When \\(b\\) belongs to \\(C(A)\\) , \\(\\mathbf{Ax= b}\\):-</p> <ul> <li>\\(\\mathbb{P} = A(A^TA)^{-1}A^Tb = A(A^TA)^{-1}A^TAx = Ax = b\\)</li> </ul> <p>When \\(b\\) belongs to \\(N(A^T)\\) :-</p> <ul> <li>\\(\\mathbb{P} = A(A^TA)^{-1}A^Tb = 0\\) , since \\(A^Tb = 0\\)</li> </ul> <p>When \\(A\\) is a square matrix and inveritible :-</p> <ul> <li>\\(\\mathbb{P} = A(A^TA)^{-1}A^Tb = b\\)</li> </ul> <p>When \\(A\\) is rank one:-</p> <ul> <li>\\(\\hat{x} = \\frac{a^{T}a}{a^{T}b}\\)</li> </ul>"},{"location":"MLT/Solved%20PYQ/Quiz1%20PYQ/","title":"Quiz 1","text":""},{"location":"MLT/Solved%20PYQ/Quiz2%20PYQ/","title":"Quiz 2","text":""},{"location":"MLT/WEEK%201/Representation%20Learning/","title":"Principal Component Analysis (PCA)","text":""},{"location":"MLT/WEEK%201/Representation%20Learning/#introduction","title":"Introduction","text":"<p>Unsupervised learning, specifically \"representation learning,\" is a subset of  machine learning where the goal is to automatically discover meaningful representations or features from raw data without explicit supervision or labeled examples.  In representation learning, the algorithms aim to capture the underlying structure,  patterns, or features within the data itself.  This can be highly valuable for various tasks like data compression, feature extraction,  data visualization, and even for improving the performance of other machine learning models.</p>"},{"location":"MLT/WEEK%201/Representation%20Learning/#representation-learning-1","title":"Representation Learning (1)","text":"<p>The main objective of representation learning is to transform  the input data into a more meaningful and compact representation. This representation should capture the essential characteristics  of the data, making it easier to analyze or use in downstream tasks.</p> <p>What is the need for compression of data points?</p> <p>Compressing a dataset, especially in the context of unsupervised learning  or data preprocessing, can serve several important purposes and  provide various benefits , mainly:</p> <ul> <li> <p>Reduced Storage Space: Large datasets can require significant storage space.  Compressing the dataset reduces storage requirements, which can be cost-effective, especially when dealing  with massive datasets in cloud storage or on limited storage devices.</p> </li> <li> <p>Faster Data Transfer: Smaller datasets transfer more quickly over networks,  which is crucial when moving data between systems or  uploading/downloading data from the internet.</p> </li> <li> <p>Faster Training: When working with machine learning models,  smaller datasets can lead to faster training times.  This is particularly important when experimenting  with different models, hyperparameters, or architectures.</p> </li> </ul> <p>How to Compress Data Points?</p> <p>Lets say there are 4 data points \\(\\left\\{ \\stackrel{x_1}{\\begin{bmatrix} -7 \\\\ -14 \\end{bmatrix}} ,  \\stackrel{x_2}{\\begin{bmatrix} 2.5 \\\\ 5 \\end{bmatrix}} , \\stackrel{x_3}{\\begin{bmatrix} 0.5 \\\\ 1 \\end{bmatrix}} , \\stackrel{x_4}{\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}} \\right\\}\\)</p> <p>Now one might ask , \"how many data points are needed to store this dataset?\"</p> <p>The naive answer would be to say , \"as there are 8 data points , hence 8 real numbers are required to store this dataset.\"</p> <p>A better way to represent this dataset would be to find a \"function\" which takes  1 real number and outputs a matrix of 2 real numbers. If we look at the dataset we can see that the first coordinate is half of the second coordinate. We can exploit this feature of the dataset to reduce the number of data points to be  stored.</p> <p>One way to form this \"function\" would be to get a \"representative\" \\(\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\\) and \"coefficients\" \\(\\{ -7 , 2.5 , 0.5 ,1 \\}\\). Now we can get the back our dataset by multiplying them with  the coefficients.</p> <p>Using this way we only need to store 6 real numbers (4 for coefficients + 2 for representative). Similarly, on a dataset of \\(2n\\) points , we can store them as \\(n +2\\) real numbers (\\(n\\) coefficients + 2 for representative).</p>"},{"location":"MLT/WEEK%201/Representation%20Learning/#working-with-a-realistic-dataset","title":"Working with a Realistic Dataset","text":"<p>In the above example we were able construct a function which reduced the number of real numbers required to represent the dataset , but in a realistic dataset all the points do not lie on the same line , they are scattered and its very hard to derive meaningful conclusions from them.</p> <p>\"What to do if all the points dont lie in the dataset?\"</p> <p>A simple answer would be, \"We can get more representatives to accommodate the points which do not lie on the same line.\" This approach does accommodate the outliers but it also increases the number of real numbers required to represent the dataset.</p> <p>\"Whats the solution then?\"</p> <p>There has to be a tradeoff between the \"accuracy\" or the \"size\" of the dataset. If we want to reduce the size  of the \"size\" then approximating the outlier to the \"line\" with least lost would be the best bet.</p> <p>To represent outliers and reduce the size of the dataset at the same time , we must project the  outlier onto the line.</p> <p></p> <p>Let there be a vector \\(\\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix}\\) which represents the \"line\". The projection of the vector \\(\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\) onto the line would be </p> \\[ \\left[ \\frac{x_1w_1 + x_2w_2}{w_1^2 + w_2^2} \\right] \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\] <p>This will give us a point on the \"line\" with the least loss/distance.</p> <p>Now if we pick vector \\((w_1 , w_2)\\) which lies on the \"line\" such that \\(w_1^2 + w_2^2 = 1\\), the above equation becomes</p> \\[ \\left[ {x_1w_1 + x_2w_2} \\right] \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\]"},{"location":"MLT/WEEK%201/Representation%20Learning/#representation-learning-2","title":"Representation Learning (2)","text":"<p>Our original objective was to find a \"compressed\" representation of the data  when all the data-points not necessarily fall on the same line.</p> <p>\"How do we know that the line we picked is the best line?\"</p> <p>One could argue that the same line doesnt fit all the data-points with the \"least loss\" , where \"loss\" is the average of all the \"errors\" when projecting outliers onto the given \"line\".</p> <p>How to find the Best Line?</p> <p>To find the Best Line we should first have a certain way to compare  2 different lines. In our case it would be the line with the least \"reconstruction error\".</p> <p>Lets say for a dataset \\(\\{ x_1 , x_2 , .... x_n \\}\\) , where \\(x_i \\in \\mathbb{R}^d\\)</p> \\[\\begin{equation*} \\begin{split} \\text{Error}(\\text{line} , \\text{dataset}) &amp; = \\sum_{i=1}^n \\text{error}(\\text{line} , x_i) \\\\  &amp; = \\sum_{i=1}^n \\text{length}^2(x - (x^Tw)w) \\\\ &amp; = \\sum_{i=1}^n || x - (x^Tw).w||^2 \\\\ \\end{split} \\end{equation*}\\] <p>To minimize the above equation we can think of it as a function \\(f(W)\\)</p> \\[\\begin{equation*} \\begin{split} f(W) &amp;= \\frac{1}{n}\\sum_{i=1}^{n} || x - (x^Tw).w ||^2 \\\\ &amp;= \\frac{1}{n}\\sum_{i=1}^{n} (x - (x^Tw).w)^T(x - (x^Tw).w)  \\\\ &amp;= \\frac{1}{n}\\sum_{i=1}^{n} \\left[ x_i^Tx_i - (x_i^Tw)^2 - (x_i^Tw)^2 + (x_i^Tw)^2(1) \\right] \\\\ &amp;= \\frac{1}{n}\\sum_{i=1}^{n} \\left( x_i^Tx_i - (x_i^Tw)^2 \\right) \\end{split} \\end{equation*}\\] <p>Here we are minimzing \\(f(W)\\) with respect to \\(w\\) , the first term of the above  equation \\(x_i^Tx_i\\) can be ignored as its a constant.</p> <p>So we can write the new function as \\(g(W)\\)</p> \\[\\begin{equation*} \\begin{split} \\min_{W_{||w||^2 = 1}} g(W) &amp;= \\frac{1}{n}\\sum_{i=1}^n - (x_i^Tw)^2 \\end{split} \\end{equation*}\\] <p>Alternatively this same function can be written as </p> \\[\\begin{equation*} \\begin{split} \\max_{W_{||w||^2 = 1}} g(W) =  \\frac{1}{n}\\sum_{i=1}^n (x_i^Tw)^2 &amp;= \\frac{1}{n} \\sum_{i=1}^{n} (w^Tx_i)(x_i^Tw) \\\\  &amp;= \\frac{1}{n} \\sum_{i=1}^{n} w^T(x_ix_i^T)w \\\\ &amp;= \\frac{1}{n} w^T(\\sum_{i=1}^{n} x_ix_i^T)w \\\\ \\end{split} \\end{equation*}\\] <p>The above equation can also be written as </p> \\[ \\max_{w_{||w||^2 = 1}} w^TCw \\] <p>where \\(C = \\frac{1}{n}\\sum_{i=1}^{n}x_ix_i^T\\)</p> <p>Note that \\(C\\) is also the covariance matrix and the solution for the above maximization equation  would be the eigenvector corresponding to the largest eignevalue of \\(C\\).</p>"},{"location":"MLT/WEEK%201/Representation%20Learning/#error-vector-has-information","title":"Error Vector has Information","text":"<p>Our hypothesis was that there is a line which best represents the data but , if all the  data points lied along a plane then this part (dotted orange lines) which we are imagining to be error may not be  the error but rather useful information because the necessary information , the structure is in a plane but not on a line , so the bits we lose while selecting the best line will also contain some information.</p> <p>How do we extract this information?</p> <p>One possible algorithm could be ,</p> <ul> <li>Input : \\(\\{ x_1 , x_2 , x_3 ...... x_n \\}  x_i \\in \\mathbb{R}^d\\)</li> <li>Find the \"best\" line \\(w_1 \\in \\mathbb{R}^d\\)</li> <li>Replace \\(x_i\\) with \\(x_i - (x_i^Tw)w\\)</li> <li>Repeat to obtain \\(w_2\\)</li> </ul> <p>Note</p> <p>Sometimes the data might not be centered around the origin. To counter that we can subtract the average of the dataset  from the points.</p>"},{"location":"MLT/WEEK%201/Representation%20Learning/#principal-component-analysis-1","title":"Principal Component Analysis (1)","text":"<p>From the algorithm above we can find a \\(w_2\\) vector which represents the line which passes through the \"error/residues\" generated while finding out \\(w_1\\).</p> Observations made while finding out \\(\\mathbf{w_2}\\) <ul> <li>All \"residues/errors\" are orthogonal to \\(w_1\\).</li> <li>Any line which minimizes sum of errors w.r.t. residues  must also be orthogonal to \\(w_1\\)</li> </ul> <p>A question which comes to mind is , \"is there a relationship between \\(w_1\\) and \\(w_2\\)?\"</p> <p>The answer is \"Yes , there is a relationship.\"</p> <p>\\(w_1\\) and \\(w_2\\) are orthognal to each other.</p> \\[\\implies w_1^Tw_2 = 0\\] <p>By continuing this procedure for dataset of \\(d\\) dimension, we get a set of vectors \\(\\{ w_1 , w_2 , w_3 .... w_d \\}\\) with the  following properties.</p> <ul> <li>\\(||w_k||^2 = 1 \\; \\; \\; \\forall k\\)</li> <li>\\(w_iw_j = 0  \\;\\;\\;\\;\\; \\forall i \\neq j\\)</li> </ul> <p>Hence , we get a set of Orthonormal Vectors.</p> <p>What is the use of Set \\(D\\) of Orthonormal Vectors?</p> <p>Residue after round 1 is </p> <p>\\(\\left\\{ x_1 - (x_1^Tw_1)w_1 , ..... , x_n - (x_n^Tw_1)w_1   \\right\\} \\;\\;\\;\\; \\forall \\;\\; \\text{vectors} \\in \\mathbb{R}^d\\)</p> <p>Residue after round 2 is </p> <p>\\(\\{ x_1 - (x_1^Tw_1)w_1 - (x_1 - (x_1^Tw_1)w_1)^Tw_2 , ..... \\}\\)</p> <p>\\(\\{ x_1 - (x_1^Tw_1)w_1 - (x_1^Tw_2 - (x_1^Tw_1).w_1^Tw_2)w_2 , ......   \\}\\)</p> <p>\\(\\{ x_1 - (x_1^Tw_1)w_1 - (x_1^Tw_2)w_2 , ......  \\}\\) as \\([w_1^Tw_2 = 0]\\)</p> <p>Residue after \\(d\\) rounds is </p> <p>\\(\\forall i \\;\\;\\;\\;\\;\\; x_i - ((x_i^Tw_1)w_1 + (x_i^Tw_2)w_2 + ...... (x_i^Tw_d)w_d) = 0\\)</p> <p>After \\(d\\) rounds all the error vectors become zero vectors. </p> <p>\\(\\forall i \\;\\;\\;\\;\\;\\; x_i = ((x_i^Tw_1)w_1 + (x_i^Tw_2)w_2 + ...... (x_i^Tw_d)w_d)\\)</p> <p>This leads to the conclusion that if data lives in a \"low\" dimensional linear sub-space, then residue becomes 0 much earlier than \\(d\\) rounds.</p> <p>What does the above statement actually mean?</p> <p>Lets say for a dataset \\(\\{x_1 , x_2 \\cdots , x_n \\}\\) , where \\(x_i \\in \\mathbb{R}^d\\) ,  all the residues/error vectors become 0 after 3 rounds.</p> <p>This means that every datapoint can be expressed as the sum of projections itself onto the residues/error vectors.</p> \\[ \\forall i \\;\\; x_i = (x_i^Tw_1)w_1 + (x_i^Tw_2)w_2 + (x_i^Tw_3)w_3 \\] <p>where \\(\\{w_1 ,w_2 ,w_3 \\} \\in \\mathbb{R}^d\\)</p> <p>Note that the \\(\\{w_1 ,w_2 ,w_3 \\}\\) are the representatives and  \\(\\{x_i^T w_1 , x_i^T w_2 , x_i^T w_3 \\}\\) are the coefficients for a datapoint \\(x_i\\)</p> <p>Example</p> <p>Lets assume for a dataset of dimension \\(d\\) and \\(n\\) points , after \\(k\\) rounds the  error vectors become zero vectors.</p> <p>This means that now the dataset can be represented with \\(\\mathbf{d \\times k + k \\times n}\\) points instead of \\(d \\times n\\) points.</p> <p>In the case shown above where the residues/error vectors become 0 after \\(k = 3\\) rounds, we can represent the whole dataset as, \\(d \\times 3\\)  +  \\(3 \\times n\\)</p> <p>Where , \\(d \\times 3\\) = Total numbers required to store the representatives</p> <p>\\(3 \\times n\\) = Total numbers required to store datapoints</p>"},{"location":"MLT/WEEK%201/Representation%20Learning/#principal-component-analysis-2","title":"Principal Component Analysis (2)","text":"<p>Our original problem was </p> \\[ \\max_{w_{||w||^2 = 1}} w^TCw \\] <p>where \\(C = \\frac{1}{n}\\sum_{i=1}^{n}x_ix_i^T\\) , and the solution for this problem  was the eigenvector corresponding to the maximum eigenvalue.</p> <p>We also observed that the set of eigenvectors \\((\\{w_1 , w_2 , .... w_d\\})\\) coresspnding to the eigenvalues of \\(C\\) form an orthonormal basis. </p> <p>Now lets look at this problem in a more \"linear algebraic\" way,</p> <p>We know,</p> \\[\\begin{equation*} \\begin{split} Cw_1 &amp;= \\lambda_1 w_1 \\\\  w_1^TCw_1 &amp;= w_1^T(\\lambda_1w_1) = \\lambda_1 \\\\ \\lambda_1 &amp;= w_1^TCw_1 = w_1^T(\\frac{1}{n}\\sum_{i=1}^{n}x_ix_i^T)w_1 \\\\ \\lambda_1 &amp;= \\frac{1}{n}\\sum_{i=1}^{n}(x_i^Tw_1)^2 \\end{split} \\end{equation*}\\] <p>Usually we take highest \\(L\\) lambdas such that 95% of the variance in the dataset is captured,</p> \\[\\frac{\\sum_{i=1}^L \\lambda_i }{ \\sum_{i=1}^d \\lambda_i } \\geq 0.95\\] <p>where , \\(\\lambda_i\\) are the eigenvalues of the covariance matrix .</p>"},{"location":"MLT/WEEK%201/Representation%20Learning/#relation-between-variance-and-mathbflambda","title":"Relation between Variance and \\(\\mathbf{\\lambda}\\)","text":"<p>For an arbitrary set of points \\((\\{(x_1^Tw) , (x_2^Tw) ...... (x_n^T)w   \\})\\) projected onto line represented by vector \\(w\\).</p> <p></p> <p>The average \\(\\mu\\) of the projected points will be \\(\\frac{1}{n}\\sum_{i=1}^{n}(x_i^Tw)\\). If the data is centered then,</p> \\[\\frac{1}{n}\\sum_{i=1}^{n}(x_i^Tw) = (\\frac{1}{n}\\sum_{i=1}^{n}x_i)w = 0w = 0\\] <p>This implies that average for a centered dataset is \\(\\mu = 0\\).</p> <p>The variance of this same dataset will be ,</p> \\[\\frac{1}{n}\\sum_{i=1}^{n}(x_i^Tw - \\mu)^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i^Tw)^2\\] <p>We can see that the variance is same as \\(\\lambda\\) required to solve the maximization problem.</p> <p>Hence we can say that , variance maximization is the same as error minimization on  centered dataset</p>"},{"location":"MLT/WEEK%2010/SVM/","title":"Support Vector Machine","text":""},{"location":"MLT/WEEK%2010/SVM/#perceptrons-and-margin","title":"Perceptrons and Margin","text":"<p>We know that in the Perceptron Algorithm the number of mistakes is given by, \\(\\text{#mistakes} \\leq \\frac{R^2}{\\gamma^2}\\) , we also said that data is linearly  separable with margin \\(\\gamma\\) , which means that there exists some \\(w^*\\) such that  \\(w^{*^T} x_i \\geq \\gamma \\quad \\forall i , \\gamma&gt;0\\) </p> <p></p> Question <p>If we were given a dataset like in the above image , which of the 2 \\(w^*\\) would be  a better choice?</p> <ul> <li> <p>We can see that \\(w_1^*\\) has a greater margin \\(\\gamma_1\\) when compared to \\(w_2^*\\) which  has a smaller margin \\(\\gamma_2\\).</p> </li> <li> <p>If we want to decrease the number if mistakes our algorithm makes, we can increase  the value of \\(\\gamma\\) because \\(\\text{#mistakes} \\leq \\frac{R^2}{\\gamma^2}\\) , in other words number of mistakes is inversely proportional to \\(\\gamma^2\\).The greater the \\(\\gamma\\) the lower will be the number of mistakes.</p> </li> <li> <p>Therefore , the better of the 2 \\(w^*\\) here is \\(w_1^*\\).</p> </li> </ul>"},{"location":"MLT/WEEK%2010/SVM/#maximum-margin-formulation","title":"Maximum Margin: Formulation","text":"<p>Now that we know that \\(w^*\\) which have larger \\(\\gamma\\) margin are better than other \\(w^*\\) , our goal now is to come up with a formulation that maximizes \\(\\gamma\\) margin.</p> \\[\\label{max-margin-formulation} \\tag{1} \\underset{w,\\gamma}{\\max} \\quad \\gamma \\quad \\text{such that } (w^T x_i)y_i \\geq \\gamma \\;\\; \\forall i\\] <p>We want to maximize \\(\\gamma\\) over \\(w\\) , but we arent choosing any random \\(w\\) , the \\(w\\) should satisfy the condition of \\((w^T x_i)y_i \\geq \\gamma\\).</p> <p>Problem With Above Formulation</p> <p>Lets say for some \\(w\\) the \\(\\gamma\\) margin is , \\(\\{ x:w^T x = 5 \\}\\) , it can  be argued that there exists another \\(w\\) such that \\((2 w)^T x = 2 \\times 5 = 10\\). So for this \\(w\\) , there exist infinitely many \"scaled versions\".</p> <p>To solve the above stated problem , we will \"ground\" the value of \\(w\\) such that  \\(||w||^2 = 1\\). Therefore our new formulation will be,</p> \\[\\begin{split} \\underset{w , \\gamma}{\\max} \\gamma \\\\  \\\\ \\text{such that } \\\\ (w^T x_i)y_i \\geq \\gamma \\quad \\forall i \\\\ \\text{and } ||w||^2 = 1 \\end{split}\\]"},{"location":"MLT/WEEK%2010/SVM/#simplified-formulation","title":"Simplified Formulation","text":"<p>The above maximization can be reformulated into an expression with just  one variable (\\(w\\)). </p> \\[\\label{abcd} \\tag{1} \\begin{split} \\underset{w}{\\max} \\;\\; \\text{width}(w) \\\\  \\\\ \\text{such that} \\\\ (w^T x_i)y_i \\geq 1 \\quad \\forall i \\\\ \\end{split}\\] <p>The equation here basically means that , we are allowing any \\(w\\) which linearly  separates our dataset with \\(\\gamma\\) margin and the norm square  of that \\(w\\) must be 1 and instead of  maximizing \\(\\gamma\\), we are maximizing the width. The width here is  the distance between to parallel lines of \\(\\gamma\\) margins.</p> <p>What is width(w)?</p> <p>For some \\(w\\) which classifies a dataset , \\(x_1\\) and \\(x_2\\) be the points lying on  the \\(\\gamma\\) margins. The distance between these points (width(w)) can be given by,</p> \\[\\begin{equation*} \\begin{split} x_1 ^T w - x_2 ^T w &amp;= 2 \\\\ (x_1 - x_2)^T w &amp;= 2 \\\\  ||x_1 - x_2||_2 \\; ||w||_2 \\; \\cos(\\theta) &amp;= 2 \\quad \\quad (\\theta =  0\u00b0) \\\\  \\therefore || x_1 - x_2 ||_2 &amp;= \\frac{2}{||w||_2} \\end{split} \\end{equation*}\\] <p></p>"},{"location":"MLT/WEEK%2010/SVM/#re-simplified-formulation","title":"Re-Simplified Formulation","text":"<p>Now that we know what width(w) is , we can reformulate our maximization equation as ,</p> \\[\\begin{split} \\underset{w}{\\max} \\;\\; \\frac{2}{||w||^2} \\\\ \\\\ \\text{such that} \\\\ (w^T x_i)y_i \\geq 1 \\quad \\forall i \\\\ \\end{split}\\] <p>Equivalently , the above experession can be turned into a minimization equation,</p> \\[\\begin{split} \\boxed{\\underset{w}{\\min} \\;\\; \\frac{1}{2} ||w||^2} \\\\ \\\\ \\text{such that} \\\\ (w^T x_i)y_i \\geq 1 \\quad \\forall i \\\\ \\end{split}\\]"},{"location":"MLT/WEEK%2010/SVM/#constrained-optimization","title":"Constrained Optimization","text":"<p>Our goal now is to formulate a \"dual problem\" for the above minimization (\"primal\") problem.</p> <p>But for now we will look at,</p> \\[\\begin{split} \\underset{w}{\\min} f(w) \\\\  \\\\ \\text{such that } \\\\ g(w) \\leq 0 \\\\ \\end{split}\\] <p>To solve for the above minimization problem we will form a lagrangian function,</p> \\[ \\mathcal{L}(w , \\alpha) = f(w) + \\alpha g(w) \\] <p>For a fixed value of \\(w\\) , consider , </p> \\[ \\underset{\\alpha \\geq 0}{\\max} \\mathcal{L}(w , \\alpha) = \\underset{\\alpha \\geq 0}{\\max} f(w) + \\alpha g(w) \\]"},{"location":"MLT/WEEK%2010/SVM/#case-1","title":"Case 1","text":"<ul> <li>Now that we have fixed a value of \\(w\\) , lets assume that \\(g(w) &gt; 0\\).</li> <li>If \\(g(w) &gt; 0\\) and \\(f(w) \\in \\{-\\infty , \\infty \\}\\) , to maximize the above function, we can keep increasing the value \\(\\alpha\\). When the value of alpha is increased , the  value of \\(g(w)\\) will also increase.</li> <li>Hence , when \\(g(w) &gt; 0\\) the solution if \\(\\infty\\)</li> </ul> <p>Example1 f(w) &gt; 0</p> <ul> <li>Lets say \\(f(w) = 10\\) and \\(g(w) = 20\\) , if the value of \\(\\alpha\\) is increased, the value of overall function will also increase. We can keep on increasing the  value of \\(\\alpha\\) and the value of overall function will keep on increasing.</li> <li>Hence , we say that the solution in this subcase is \\(\\infty\\)</li> </ul> <p>Example2 f(w) &lt; 0</p> <ul> <li>Lets say \\(f(w) = -100\\) and \\(g(w) = 20\\) , if the value of \\(\\alpha\\) is increased, just like above , the value of overall function will also increase. <ul> <li>When \\(\\alpha = 5\\) ,the function will evalute to zero.</li> <li>When \\(\\alpha = 100\\) , the function will evalute to 1900.</li> </ul> </li> <li>Hence , we can say that the solution in this subcase also is \\(\\infty\\)</li> </ul>"},{"location":"MLT/WEEK%2010/SVM/#case-2","title":"Case 2","text":"<ul> <li>In Case 2 we will assume that \\(g(w) \\leq 0\\).</li> <li>If \\(g(w) &lt; 0\\) and \\(f(w) \\in \\{-\\infty , \\infty \\}\\) , the only way to maximize the above  function is to put \\(\\alpha = 0\\). When \\(\\alpha =0\\) , \\(g(w)\\) will also become zero.</li> <li>Hence , when \\(g(w) &lt; 0\\) the solution is always \\(f(w)\\).</li> </ul> <p>Example1 f(w)&gt;0</p> <ul> <li>Lets say \\(f(w) = 10\\) and \\(g(w) = -20\\) , no matter what value (except 0) of \\(\\alpha\\) we use here the overall function value will always decrease. The only way to maintain the value of the overall function is to put \\(\\alpha = 0\\).</li> <li>Hence, we say that the solution in this subcase is always \\(f(w)\\).</li> </ul> <p>Example2 f(w)&lt;0</p> <ul> <li>Lets say \\(f(w) = -10\\) and \\(g(w) = -20\\) , no matter what value (except 0) of \\(\\alpha\\) we use here the overall value of the function (just like above) will decrease.<ul> <li>When \\(\\alpha = 5\\) the function will evaluate to -110.</li> <li>When \\(\\alpha = 100\\) the function will evaluate to -2010.</li> <li>It can be seen that if the value of \\(\\alpha\\) is increased , the overall value of the  function decreases.</li> </ul> </li> <li>Hence , we can say that the solution in this subcase is always \\(f(w)\\).</li> </ul> <p>Therefore the solutions for the above lagrangian maximization are,</p> \\[ \\underset{\\alpha \\geq 0}{\\max} \\mathcal{L}(w , \\alpha) =  \\begin{cases} \\infty &amp; g(w)&gt;0 \\\\  f(w) &amp; g(w) \\leq 0 \\\\ \\end{cases}\\]"},{"location":"MLT/WEEK%2010/SVM/#langrangian-function-maximization","title":"Langrangian Function Maximization","text":"<p>Inside the shaded region , the function evaluates to \\(f(w)\\) , while outside the  shaded region the function evaluates to \\(\\infty\\).</p> <p>From the above diagram we can see that for multiple values of \\(w\\) the function evalutes to \\(f(w)\\). We want to find the minimum \\(w\\) at which the function evaluates to \\(f(w)\\),</p> \\[\\underset{w}{\\min} \\left[ \\underset{\\alpha \\geq 0}{\\max} f(w) + g(w)  \\right] \\] <p>Note</p> <p>Note that this expression is same as the original  minimization problem we started with,</p> \\[\\begin{split} \\underset{w}{\\min} f(w) \\\\  \\\\ \\text{such that } \\\\ g(w) \\leq 0 \\\\ \\end{split}\\] <p>To gain more insight over our newly derived min-max problem we will try to turn it into a max-min problem.</p> <p>The max-min expression will be,</p> \\[\\underset{\\alpha \\geq 0}{\\max} \\left[ \\underset{w}{\\min} f(w) + g(w)  \\right] \\] <p>Note that we can turn it into a max-min problem because both \\(f\\) and \\(g\\) are  convex functions.</p>"},{"location":"MLT/WEEK%2010/SVM/#multiple-constraints","title":"Multiple Constraints","text":"<p>If there are problems which require multiple constraints , they can be formulated  as,</p> \\[\\begin{split} \\underset{w}{\\min} f(w) \\\\  \\\\ \\text{such that } \\\\ g_i(w) \\leq 0 \\;\\; \\forall i \\\\ \\end{split}\\] <p>Equivalently this can also be written as,</p> \\[\\underset{w}{\\min} \\left[ \\underset{\\underset{\\geq 0}{\\alpha_1} , \\underset{\\geq 0}{\\alpha_2} , ... \\underset{\\geq 0}{\\alpha_k}}{\\max} f(w) + \\alpha_1 g_1(w) + \\alpha_2 g_2(w) \\cdots + \\alpha_k g_k(w)  \\right] \\] <p>Note that \\(i\\) here represents the number constraints and there are total \\(k\\) constrains.</p>"},{"location":"MLT/WEEK%2010/SVM/#formulating-the-dual-problem","title":"Formulating the Dual Problem","text":"<ul> <li>We started off with maximizing  \\(\\gamma\\) so that the number of mistakes made by our algoritm are less/reduced. </li> <li>We then turned it into a expression with only one variable \\(w\\)</li> <li>After that , we resimplified the  maximization expression for \\(||w||\\) instead of width(w).</li> <li>Then we took a detour and solved for a constrained opitmization problem.</li> <li>We then modified the constrained optimization problem and ended with  lagrangian maximization expression.</li> </ul> <p>But where does this all lead to?</p> <p>This leads us to getting back to the re-simplified problem and  change it in such a way that it matches with the constrained optimization problem.</p> <p>Our Re-Simplified Expression was,</p> \\[\\begin{split} \\underset{w}{\\min} \\;\\; \\frac{1}{2} ||w||^2 \\\\ \\\\ \\text{such that} \\\\ (w^T x_i)y_i \\geq 1 \\quad \\forall i \\\\ \\end{split}\\] <p>To treat this expression as a constrained optimization problem that we did above , we have to convert this to standard form. Here the constraint is \\((w^T x_i)y_i \\geq 1\\) but in our constrained optimization problem the constraint was \\(g(w) \\leq 0\\).</p>"},{"location":"MLT/WEEK%2010/SVM/#standardized-form","title":"Standardized Form","text":"<p>The standard form will be,</p> \\[\\label{efgh} \\tag{2} \\begin{split} \\underset{w}{\\min} \\;\\; \\frac{1}{2} ||w||^2 \\\\ \\\\ \\text{such that} \\\\ 1 - (w^T x_i)y_i \\leq 0 \\quad \\forall i \\\\ \\end{split}\\] <p>Now the langrangian function for this standardized form will be,</p> \\[\\mathcal{L}(w , \\alpha) = \\frac{1}{2} ||w||^2 + \\sum_{i=1}^{n} \\alpha_i (1 - (w^T x_i)y_i)\\] <p>We know that a langrangian function can be written as an  min-max expression,</p> \\[\\underset{w}{\\min} \\underset{\\alpha \\geq 0}{\\max} \\left[ \\frac{1}{2} ||w||^2 + \\sum_{i=1}^n \\alpha_i \\left( 1 - (w^T x_i)y_i  \\right) \\right]\\] <p>Similarly , this can also be written as max-min problem,</p> \\[\\underset{\\alpha \\geq 0}{\\max} \\underset{w}{\\min} \\left[ \\frac{1}{2} ||w||^2 + \\sum_{i=1}^n \\alpha_i \\left( 1 - (w^T x_i)y_i  \\right) \\right]\\] <p>Note that \\(\\alpha \\geq 0\\) means that \\(\\alpha\\) is a column matrix with  all the \\(\\alpha_i\\) to be \\(\\geq 0\\).</p> <p>We will now work with this max-min problem to further deepen our understanding  about our original \\(||w||\\) maximization problem. </p>"},{"location":"MLT/WEEK%2010/SVM/#solution-for-langrangian-max-min-problem","title":"Solution for Langrangian Max-Min Problem","text":"<p>For some \\(\\alpha \\geq 0\\),the inner minimization problem becomes an unconstrained optimization problem. We will try to find its solution using gradients,</p> \\[\\underset{w}{\\min} \\quad \\frac{1}{2} ||w||^2 + \\sum_{i=1}^{n} \\alpha_i (1 - (w^T x_i)y_i )\\] <p>The gradient of above expression is ,</p> \\[\\begin{split} w^*_{\\alpha} + \\sum_{i=1}^n \\alpha_i (-x_i y_i) = 0 \\\\ w^*_{\\alpha} = \\sum_{i=1}^n \\alpha_i ( x_i y_i) \\\\ \\end{split}\\] <p>From this we can conclude that for a fixed value of \\(\\alpha\\) our best \\(w\\) would be  a linear combination of \\(x_i,y_i,\\alpha_i\\)</p> <p>If we substitute this value of \\(w^*_\\alpha\\) we can find the minimizer of the min-max  expression above. On simplification after substitution,</p> \\[ \\alpha^T I - \\frac{1}{2} (XY \\alpha)^T (XY \\alpha) \\] <p>Note that here \\(w^*_\\alpha\\) here is in matrix notation form (\\(w^*_\\alpha = XY \\alpha\\)).</p> <p>Therefore the \"dual\" problem to the \"primal\" problem will be,</p> \\[\\underset{w \\geq 0}{\\max} \\alpha^T I - \\frac{1}{2} \\alpha^T Y^T X^TX Y \\alpha \\] <p>So what have we gained after finally arriving at this dual problem?</p> <ul> <li>Dual Variable is in \\(\\mathbb{R}^n\\) dimension , while the primal problem is in  \\(\\mathbb{R}^d\\) space.<ul> <li>If \\(d &gt;&gt; n\\) , its better to solve the dual problem.</li> </ul> </li> <li>The objective in dual problem depends on \\(X^TX\\) , which can be kernalized.</li> </ul>"},{"location":"MLT/WEEK%2010/SVM/#recap-flowchart","title":"Recap Flowchart","text":""},{"location":"MLT/WEEK%2010/SVM/#support-vector-machine_1","title":"Support Vector Machine","text":"<p>Now that we know that \\(w^*_\\alpha\\) depends on \\(\\alpha_i\\) , where importance of a  datapoint is given by \\(\\alpha_i\\) , we want to find out the points where \\(\\alpha_i &gt; 0\\).</p> <p>We will take a small detour and get back to this question.</p> \\[\\begin{equation*} \\begin{split} \\underset{\\mathbf{w^*} \\text{ is the primal solution}}{\\overset{\\textbf{Primal}} {\\underset{w}{\\min} \\left[ \\underset{\\alpha \\geq 0}{\\max} f(w) + \\alpha g(w)  \\right]}} &amp;= \\ \\underset{\\pmb{\\alpha^*} \\text{ is the dual solution}}{\\overset{\\textbf{Dual}} { \\underset{\\alpha \\geq 0}{\\max} \\left[ \\underset{w}{\\min}  f(w) + \\alpha g(w)  \\right]}} \\\\ \\end{split} \\end{equation*}\\] <p>Now we will input the solutions of the dual and primal problems back into their  equations,</p> \\[ \\underset{\\alpha \\geq 0}{\\max} f(w^*) + \\alpha g(w^*) \\quad \\quad \\quad \\quad  \\underset{w}{\\min} f(w) + \\alpha^* g(w) \\] <p>The function on the left (primal problem) will evaluate to \\(f(w^*)\\)</p> <p>$$$$</p> \\[\\begin{equation*} \\begin{split} f(w^*) = \\underset{w}{\\min} f(w) + \\alpha^* g(w) &amp;\\leq f(w^*) + \\alpha^* g(w^*) \\\\ f(w^*) &amp;\\leq f(w^*) + \\alpha^* g(w^*) \\\\ \\alpha^* g(w^*) &amp;\\geq 0 \\\\ \\end{split} \\end{equation*}\\] <p>But we already know  \\(\\alpha^* \\geq 0\\) and \\(g(w^*) \\leq 0\\).  The only point where both our equations are true is,</p>"},{"location":"MLT/WEEK%2010/SVM/#complementary-slackness","title":"Complementary Slackness","text":"\\[\\alpha^* g(w^*) = 0\\] <p>Similarly , for multiple constraints</p> \\[\\alpha_i^* g_i(w^*) = 0 \\quad \\forall i\\] <p>Also , \\(g(w^*) = 1 - (w^T x_i)y_i\\) , this means the above equation  can also be written as, $$ \\alpha_i ( 1 - (w^T x_i)y_i) = 0 \\quad \\forall i $$</p> <p>Now, according to Complementary Slackness , if \\(\\alpha_i &gt; 0\\) , then \\(1 - (w^T x_i)y_i = 0\\),</p> \\[ \\boxed{(w^T x_i)y_i = 1} \\] <p>From the above equation we can conclude that, points which have \\(\\alpha_i &gt; 0\\) lie on some line denoted by \\((w^T x_i)y_i = 1\\). This means that the points which contribute to the best \\(w^*\\) only lie on the  \\((w^T x_i)y_i = 1\\) line. Rest of the datapoints which dont lie on this line do not matter for formulation of \\(w^*\\).</p> <ul> <li>Only the points that are on the \"Supporting\" hyperplane (\\((w^T x_i)y_i = 1\\)) contribute to \\(w^*\\).</li> <li>These special points are called supoort vectors.</li> <li>Hence , this algorithm is called \"Support Vector Machine (SVM)\".</li> <li>\\(w^*\\) is a sparse linear combination of the datapoints.</li> </ul>"},{"location":"MLT/WEEK%2010/SVM/#kernalization-of-svm","title":"Kernalization of SVM","text":"<p>Given a point \\(x_\\text{test}\\) the prediction for that point is ,</p> \\[\\begin{equation*} \\begin{split} (w^*)^T x_\\text{test} &amp;= \\left( \\sum_{i=1}^n \\alpha_i \\; x_i y_i  \\right)^T x_\\text{test} \\\\ &amp;= \\sum_{i=1}^n \\alpha_i \\; y_i (x_i^T x_\\text{test}) \\\\ (w^*)^T \\phi(x_\\text{test}) &amp;= \\sum_{i=1}^n \\alpha_i \\; y_i K(x_i , x_\\text{test}) \\end{split} \\end{equation*}\\]"},{"location":"MLT/WEEK%2011/SVM2/","title":"Support Vector Machine","text":""},{"location":"MLT/WEEK%2011/SVM2/#dual-formation-for-soft-margin-svm","title":"Dual Formation for Soft Margin SVM","text":"<p>We know that SVM works well on a linearly separable dataset, but our goal was to accommodate outliers/noise in the dataset and hence we created a new formulation from SVM called \"Soft Margin SVM\" , given by the formula,</p> \\[\\begin{split}  \\underset{w \\in \\mathbb{R}^d}{\\min} \\frac{1}{2}||w||^2 + C \\sum_{i=1}^n \\xi_i  \\\\ \\text{such that } (w^T x_i)y_i + \\xi_i \\geq 1 \\;\\; \\forall i \\\\ \\xi_i \\geq 0 \\;\\; \\forall i \\\\ \\end{split}\\] <p>We want to kernalize this equation so that it is able to  perform even on \"non-linear\" datasets.</p> <p>Example</p> <p></p> <p>This example depicts how we want our \"Kernalized Soft Margin SVM\" to be.</p> <ul> <li>It should be able to work on a non-linearly separable dataset.</li> <li>It should also be able to identify \"non-linear\" structures within  the dataset.</li> </ul> <p>The first step towards our goal would be to form a \"Dual Problem\" for the  \"Soft Margin SVM\" equation.</p> <p>To formulate the \"Dual Problem\" we will first make a langrangian function,</p> \\[ \\mathcal{L}(w, \\xi , \\alpha , \\beta) =  \\frac{1}{2}||w||^2 + C \\sum_{i=1}^{n}\\xi_i + \\sum_{i=1}^n \\alpha_i(1 - w^T x_i y_i - \\xi_i)  + \\sum_{i=1}^n \\beta_i (- \\xi_i)\\] <p>Note</p> <ul> <li>\\(\\alpha\\) corresponds to the first constraint (\\((w^T x_i)y_i + \\xi_i \\geq 1\\)).</li> <li>\\(\\beta\\) corresponds to the second constraint (\\(\\xi_i \\geq 0\\)).</li> <li>The constraints are written in standard form , in the above equations.</li> </ul> <p>Therefore , the \"Dual Problem\" will be,</p> \\[ \\underset{w , \\xi}{\\min} \\left[  \\underset{\\substack{\\alpha \\geq 0 \\\\ \\beta \\geq 0}}{\\max} \\frac{1}{2}  ||w||^2 + C \\sum_{i=1}^n \\xi_i + \\sum_{i=1}^n \\alpha_i (1 - (w^T x_i)y_i - \\xi_i)) + \\sum_{i=1}^n \\beta_i (- \\xi_i) \\right] \\] <p>For a fixed value \\(\\alpha\\) and \\(\\beta\\),</p> <p>The derivative of \"Dual Problem\" with respect to \\(w\\) will be,</p> \\[ w^*_{\\alpha , \\beta} = \\sum_{i=1}^n \\alpha_i x_i y_i \\label{w-star} \\tag{1} \\] <p>The derivative of \"Dual Problem\" with respect to \\(\\xi\\) will be,</p> \\[\\begin{equation*} \\tag{2} \\begin{split} C + \\alpha_i(-1) + \\beta_i(-1) &amp;= 0 \\\\ \\alpha_i + \\beta_i &amp;= C \\\\ \\end{split} \\end{equation*}\\] <p>From Equation 1 and Equation 2 , Our new dual problem will be,</p> \\[\\boxed{\\underset{\\substack{\\alpha \\geq 0 \\\\ \\beta \\geq 0 \\\\ \\alpha + \\beta = C}}{\\max}  \\alpha^T I - \\alpha^T Y^T X^TX Y \\alpha}\\] <p>Note that this is same as the dual problem we had in \"SVM/Hard SVM\".</p> <p>\\(\\alpha \\geq 0\\) and \\(\\alpha + \\beta = C\\) , which means \\(\\beta\\) is restricting  the range of \\(\\alpha\\), in other words , \\(\\alpha\\) can be at most \\(C\\).</p> <p>We can equivalently say that,</p> \\[\\boxed{\\underset{0 \\leq \\alpha \\leq C}{\\max}  \\alpha^T I - \\alpha^T Y^T X^TX Y \\alpha}\\]"},{"location":"MLT/WEEK%2011/SVM2/#cases-of-different-value-of-c","title":"Cases of Different Value of \\(C\\)","text":"<p>When \\(C = 0\\)</p> <p>If \\(C = 0\\) , this means that \\(\\alpha = 0\\) , also from Equation \\(\\eqref{w-star}\\), \\(w^*_{\\alpha , \\beta} = 0\\).</p> <p>When \\(C = \\infty\\)</p> <p>If \\(C = \\infty\\) , that means there is no upper bound on \\(\\alpha\\) and  the above \"Dual Problem\" becomes exactly the same as Hard-Margin SVM.</p>"},{"location":"MLT/WEEK%2011/SVM2/#complementary-slackness-conditions-for-soft-margin-svm","title":"Complementary Slackness Conditions for Soft-Margin SVM","text":"<ul> <li>Let (\\(w^* , \\xi^*\\)) be the \"Primal\" optimal solutions.</li> <li>Let (\\(\\alpha^* , \\beta^*\\)) be the \"Dual\" optimal solutions.</li> </ul>"},{"location":"MLT/WEEK%2011/SVM2/#complementary-slackness-conditions","title":"Complementary Slackness Conditions","text":"<p>At optimality , </p> \\[\\forall i \\quad \\alpha_i^* (1 - (w^{*^T} x_i)y_i - \\xi_i^*) = 0 \\label{CS1} \\tag{1}\\] \\[\\forall i \\quad \\beta_i^* (- \\xi_i^*) = 0 \\label{CS2} \\tag{2}\\]"},{"location":"MLT/WEEK%2011/SVM2/#cases-for-complementary-slackness","title":"Cases for Complementary Slackness","text":"<p>When \\(\\alpha_i^* = 0\\)</p> <ul> <li>\\(\\implies \\beta_i^* = C\\) as \\(\\alpha_i^* + \\beta_i^* = C\\).</li> <li>\\(\\implies \\xi_i^* = 0\\) as \\(\\beta_i^* = C\\) (From \\(\\eqref{CS2}\\))</li> <li>We know that , \\(w^{*^T} x_i y_i + \\xi_i^* \\geq 1\\)<ul> <li>\\(\\implies w^{*^T} x_i y_i \\geq 1\\) as \\(\\xi_i = 0\\)</li> <li>\\(w^*\\) classifies \\((x_i ,y_i)\\) correctly. </li> </ul> </li> </ul> <p>When \\(\\alpha*_i \\in (0,C)\\)</p> <ul> <li>\\(\\implies \\beta_i^* \\in (0,C)\\)</li> <li>\\(\\implies \\xi_i^* = 0\\) (From \\(\\eqref{CS2}\\))</li> <li>\\(\\implies 1 - (w^{*^T}x_i)y_i - \\xi_i = 0\\) (From \\(\\eqref{CS1}\\))<ul> <li>\\(\\implies 1 - (w^{*^T}x_i)y_i  = 0\\) as \\(\\xi_i^* = 0\\)</li> <li>\\(\\implies  (w^{*^T}x_i)y_i  = 1\\) </li> </ul> </li> </ul> <p>When \\(\\alpha^*_i = C\\)</p> <ul> <li> <p>\\(\\implies \\beta_i^* = 0\\) as \\(\\alpha_i^* + \\beta_i^* = C\\)</p> <ul> <li>\\(\\xi_i^* \\geq 0\\) as \\(\\beta_i^* = 0\\)</li> </ul> </li> <li> <p>\\(1 - (w^{*^T}x_i)y_i + \\xi_i = 0\\) (From \\(\\eqref{CS1}\\))</p> <ul> <li>\\(\\implies \\xi_i^* = 1 - (w^{*^T}x_i)y_i\\)</li> <li>\\(\\implies 0 \\leq 1 - (w^{*^T}x_i)y_i\\) as \\(\\xi_i^* \\geq 0\\)</li> <li>\\(\\implies (w^{*^T}x_i)y_i \\leq 1\\) </li> <li>\\(w^*\\) will either classify the points incorrectly or</li> <li>\\(w^*\\) will correctly classify the points but not with enough margin.</li> </ul> </li> </ul>"},{"location":"MLT/WEEK%2011/SVM2/#summary-for-soft-margin-svm","title":"Summary for Soft-Margin SVM","text":"<p>Lets see things from the \"Primal\" point of view,</p> <p>\\((w^{*^T}x_i)y_i &lt; 1\\)</p> <ul> <li>We know that, \\((w^{*^T}x_i)y_i + \\xi_i^* \\geq 1\\)</li> <li>\\(\\implies \\xi_i^* \\geq 1 - (w^{*^T}x_i)y_i\\)</li> <li>\\(\\beta_i^* = 0\\) as \\(\\xi_i^* &gt; 0\\) (From \\(\\eqref{CS2}\\))<ul> <li>\\(\\alpha_i^* = C\\)</li> </ul> </li> </ul> <p>\\((w^{*^T}x_i)y_i = 1\\)</p> <ul> <li>We know that , \\((w^{*^T}x_i)y_i + \\xi_i^* \\geq 1\\)</li> <li>\\(\\implies \\xi_i^* \\geq 1 - (w^{*^T}x_i)y_i\\)</li> <li>\\(\\implies \\xi_i^* \\geq 0\\) as  \\((w^{*^T}x_i)y_i = 1\\)<ul> <li>\\(\\alpha_i^* \\in [0,C]\\)</li> </ul> </li> </ul> <p>\\((w^{*^T}x_i)y_i &gt; 1\\)</p> <ul> <li>\\(\\implies \\underbrace{1 - (w^{*^T}x_i)y_i}_{&lt;0} - \\underbrace{\\xi_i^*}_{\\leq 0} &lt; 0\\)<ul> <li>\\(\\implies \\alpha_i^* = 0\\) (From \\(\\eqref{CS1}\\))</li> </ul> </li> <li>Points which are strictly greater than 1 , do not constribute to \\(w^*\\).</li> </ul>"},{"location":"MLT/WEEK%2011/SVM2/#summary","title":"Summary","text":"<ul> <li>Black Points have either \\(\\gamma\\)(margin) greater than 1 or less than 1.<ul> <li>These points do not constribute to \\(w^*\\)</li> </ul> </li> <li>Blue Points are classified correctly but not with enough margin.</li> <li>From Orange Points there is nothing much to conclude except the fact  that they will lie on the hyperplane.</li> </ul> <p>The only points which contribute to our \\(w^*\\) are either on the supporting hyperplane (Orange Points) or they are on the wrong side of supporting  hyperplane (Blue Points).</p> <p>Our assumption is that these (Blue and Orange) points will be much lesser than the other (Black) points. Hence, we will get a sparse solution.    </p>"},{"location":"MLT/WEEK%2011/SVM2/#overfitting-and-underfitting","title":"Overfitting and Underfitting","text":"<p>We will take a look at meta/ensemble classifiers. These type of classifying  techniques help in transforming \"Weak Learners\" into \"Strong Learners\". By \"Weak Learners\" we mean , algorithms which are better than random  performance but dont have high accuracy.</p> <p>To broaden our understanding about \"Weak Learners\" we will first  take a look at Overfitting and Underfitting,</p> <p>Note</p> <p>The relationship between input and output is assumed to be  some structure + noise.</p> \\[ \\text{Input} = \\underbrace{\\text{Structure + Noise}}_{\\text{Output}} \\] <p>Error is given by,</p> \\[\\text{Error} = \\text{Bias} + \\text{Variance}\\] <p>Example</p> <p></p>"},{"location":"MLT/WEEK%2011/SVM2/#overfitting","title":"Overfitting","text":"<p>Overfitting happens when our algorithm \"fits noise\" as a part of  the structure.</p> <p>Overfit models change a lot when theres a change in variance of the  dataset.These models suffer from high Variance.</p> <p>Example</p> <p>In the case of a Decision Tree , we can keep increasing the depth of the Decision Tree to an arbitrary amount to get the least  possible error on the training dataset. The problem with this  training method is that it may produce great results on the training dataset but its accuracy will reduce significantly when on testing dataset.</p> <p>  In the Overfit Dataset , the training error is zero. Even though the actual structure is sinusoidal the overfit dataset \"fits noise\" thinking that the noise is part of the structure."},{"location":"MLT/WEEK%2011/SVM2/#underfitting","title":"Underfitting","text":"<p>Underfitting is the opposite of Overfitting. It happens when our  algorithm assumes some part of the structure to be noise.</p> <p>Underfit models dont change much even if the variance of the dataset increases a lot. These type of models suffer from high Bias.</p> <p>Example</p> <p>  In the Underfit Dataset , even though the Actual Dataset is sinusoidal ,  the structure is assumed to be a linear structure. Our algorithm thinks that some of the input is noise not structure."},{"location":"MLT/WEEK%2011/SVM2/#bagging-boostrap-aggregation","title":"Bagging (Boostrap Aggregation)","text":"<p>Lets say some points \\(\\{x_1 , x_2 , \\cdots x_n  \\} \\in \\mathcal{N}(\\mu , 1)\\) with some mean \\(\\mu\\) and variance 1.</p> <p>The estimator of unknown mean \\(\\mu\\) can be,</p> \\[\\begin{equation*}\\begin{split} \\hat{\\mu_1} &amp;= x_1 \\\\   \\hat{\\mu_2} &amp;= x_2 \\\\   &amp; \\vdots \\\\ \\hat{\\mu_n} &amp;= x_n \\\\   \\end{split}\\end{equation*}\\] <p>Though the best way to estimate \\(\\mu\\) would be to use maximum  likelihood estimator , \\(\\hat{\\mu_\\text{ML}} = \\frac{1}{n} \\sum_{i=1}^n x_i\\)</p> <p>But why is the Maximum Likelihood the best estimator? </p> <p>When take an average over a huge dataset for mean \\(\\mu\\) the , averaging, reduces the variance/fluctuation of the mean \\(\\mu\\).</p> <p>We can use this technique of averaging to counter the \"High Variance Issue\" in Overfitted Datasets.</p>"},{"location":"MLT/WEEK%2011/SVM2/#bagging","title":"Bagging","text":"<p>Lets say there are \\(D_1 , D_2 , \\cdots , D_m\\) datasets , each with \\(n\\)  datapoints.</p> <p>We will now make \"Overfit\" Decision Trees for each of these datasets.</p> <p>Yes , we are specifically making overfit decision trees.</p> <ul> <li>Where each Decision Tree is represented as \\(DT_1 , DT_2 , \\cdots , DT_m\\).</li> <li>Each Decision Tree outputs a Classifier \\(h\\) , which is represented as,  \\(h_1 , h_2 , \\cdots , h_m\\). Moreover , each \\(h_i:\\mathbb{R} \\to [0,1]\\)</li> <li>Our assumption is that each classifier (\\(h_i\\)) is trained independently.</li> <li>As we are making the Decision Trees \"Overfit\" on the training dataset, these models will suffer from high variance.</li> </ul> <p>To reduce their variance , we can average the \\(h_i\\) classifiers such that,</p> \\[\\begin{split} h^*(x) = \\text{sign} \\left(\\frac{1}{m} \\sum_{i=1}^n h_i(x) \\right) \\\\ \\text{where,} \\\\  h(z) = \\begin{cases} +1 &amp; \\text{if } z \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\end{split}\\] <p>This aggregate classifier (\\(h^*(x)\\)) will have lower variance than the  original classifiers.</p> <p>The problem with this approach is that , we only get a single dataset not \\(m\\) different datasets.</p> <p>In general , we only get a single dataset , where \\(D = \\{(x_1,y_1) , (x_2,y_2) , \\cdots (x_n,y_n)\\}\\) and \\(x_i \\in \\mathbb{R}^d\\) and \\(y \\in [0,1]\\). To apply this method of  averaging (shown above) , our input needs to be \\(m\\) different datasets.</p> <p>A simple approach to divide the single dataset into \\(m\\) different  datasets would be to just make \\(m\\) datasets each having \\(n/m\\) ,  datapoints , where \\(n\\) is equal to total number of datapoints in the  single dataset.</p> <p>The issue with this type of approach is that , each of these \\(m\\) datasets will not have full \"information\" about the overall dataset.</p> <p>To divide the dataset into \\(m\\) different datasets , we will make it so  that each dataset (\\(D_i\\)) has repeated points in them. This procedure  of creating different datasets with repeated points in called Bootstrapping.</p> <p>We will create \\(m\\) different \"Bags\" and draw datapoints at random with replacement from the original (single) dataset. Each \"Bag\" will have the same number of datapoints as in the original (single) dataset.</p> <p>This makes it so that some \"Bags\" have may have datapoints common and even have  repeated datapoints within them.</p> <p>At the end when we have \\(m\\) \"Bags\" , we can run an algorithm (Example :  Decision Tree)  over the \"Bags\" and reduce their variance by the \"Bagging (Bootstrap Aggregation) Method\".</p>"},{"location":"MLT/WEEK%2011/SVM2/#probability-of-repetition-of-points","title":"Probability of Repetition of Points","text":"<p>Now that we know that , datapoints are repeated inside the Bags ,  we want to get a general Probability for the amount of repetition that happens.</p> <ul> <li>A point appears with the chance of \\(1 / n\\) in a bag.</li> <li>Probability that it does not appear in the bag is \\((1 - (\\frac{1}{n}))^n\\)</li> <li>Probability that it actually appears in the bag \\(1 - (1 - (\\frac{1}{n}))^n\\)<ul> <li>For large enough \\(n\\) , this probability approximates to around 67%.</li> </ul> </li> </ul> <p>Overfit datasets have low Bias and high Variance , but after applying the  \"Bagging Method\" the Variance also reduces (in most cases).</p>"},{"location":"MLT/WEEK%2011/SVM2/#boosting-adaptive-boosting","title":"Boosting (Adaptive Boosting)","text":"<p>The Adaptive Boosting Algorithm can be used to convert \"Weak Learners\" into \"Strong Learners\" , underfit models are one such example, as they suffer from High Bias and Low Variance.</p> <p>The input for Adaptive Boosting is our usual \\(D = \\{(x_1 , y_1) , (x_2 , y_2) \\cdots , (x_2 , y_2) \\}\\) where \\(x_i \\in \\mathbb{R}^d\\) and \\(y_i \\in [0,1]\\).</p> <ol> <li> <p>The first step is to initialize the weights for Boosting.</p> <ul> <li>\\(D_0(i) = \\frac{1}{n}\\) , \\(D_0\\) represents the weights at  initilization (iteration 0).</li> </ul> </li> <li> <p>We will now create a \"Bag\" and sample points with replacement from \\(D_t\\). Then we will input our dataset and distribution/weights (\\(S,D_t\\)) into a weak learner to get \\(h_t\\).</p> <ul> <li>If the weak learner/algorithm is not able to handle both the  dataset and its distribution/weights then we create a \"Bag\" and use the distribution/weights as probabilities for sampling points with replacement.</li> <li>\\(h_t\\) is the classifier , \\(h_t : \\mathbb{R}^d \\to [0,1]\\)</li> </ul> </li> </ol> <p>After performing step 1, we get the weights for a dataset \\(S\\).</p> <p>Lets say at the end of step 2 , we get a decision tree (\\(h_t\\)) which classifies 600 points correctly and 400 points incorrectly. We can change the weights such that , those  400 incorrectly classified  datapoints they are classified correctly in the next round , but how? , what changes should we make?</p> <ol> <li>The third step would be to increase or decrease the weights  of the points for the next iteration.</li> </ol> \\[ \\hat{D_{t+1}}(i) = \\begin{cases}  D_t(i) \\cdot e^{\\alpha_t} &amp; \\text{if } h_t(x_i) \\neq y_i \\\\ D_t(i) \\cdot e^{-\\alpha_t} &amp; \\text{if } h_t(x_i) = y_i \\\\ \\end{cases} \\] <ul> <li>We are going to decrease the weights of the points which are classified correctly and</li> <li>Increase the weights of the points classified incorrectly.</li> </ul> <p>Failure</p> <p>The problem with current formulation of distribution/weights is that, when we increase or decrease the weights , they no longer sum upto 1.</p> <ul> <li>At the end we will normalize the weights,</li> </ul> \\[ D_{t+1}(i) = \\frac{\\hat{D_{t+1}(i)}}{\\sum_{i=1}^n \\hat{D_{t+1}}(j)} \\] <ol> <li>Repeat step3 unless training error is zero.</li> </ol> <p>At the end of all these steps we are left with \\(t\\) classifiers  \\((h_1 , h_2 , \\cdots h_t)\\) for \\(t\\) iterations. To combine these classifiers somehow into one single  classifier,</p> \\[ h^*(x) = \\text{sign}\\left(\\sum_{i=1}^n \\alpha_t h_t(x) \\right) \\] <p>Note</p> \\[ \\alpha_t = \\ln \\sqrt{\\frac{1 - \\text{err}(h_t)}{\\text{err}(h_t)}} \\] <p>Also, one can prove that </p> \\[ \\text{If } T \\geq \\frac{1}{2 \\gamma^2} \\ln(2n) \\] <p>then , Training error becomes 0. Here \\(T\\) is total number of iterations and  \\(\\gamma\\) is the value which determines \"By how much is the weak  learner better than random classifier\".</p> <p>If the random classifier has the accuracy of 55% and Weak Learner  has accuracy of 60% then \\(\\gamma = 60\\% - 55\\% = 5\\% = 0.05\\)</p> <p>111</p>"},{"location":"MLT/WEEK%202/Kernel%20PCA/","title":"Kernel PCA","text":""},{"location":"MLT/WEEK%202/Kernel%20PCA/#issues-with-pca","title":"Issues with PCA","text":"<p>In the previous week we learned about using PCA to reduce  the number of features required to represent the dataset  without much loss.</p> <p>There are 2 main issues/concerns with PCA</p> <ul> <li> <p>Time Complexity : Finding the eigenvector and eigenvalues of  matrix \\(C \\in \\mathbb{R}^(d \\times d)\\) typically takes \\(O(d^3)\\) time. This becomes an issue when the number of features is much higher than number of points.</p> </li> <li> <p>PCA works only linearly : For a dataset with 3 features , if the  features are not related linearly then using PCA does not give good  results.</p> </li> </ul>"},{"location":"MLT/WEEK%202/Kernel%20PCA/#time-complexity-issue-with-pca","title":"Time Complexity Issue with PCA","text":"<p>The time complexity issue occurs when the number of features is  much much greater than the number of points in the dataset , i.e.  \\(d &gt;&gt; n\\).</p> <p>According to our algorithm the solution for maximizing the variance  of the dataset was to find the eigenvector corresponding to the max  eigenvalue of \\(C\\) , where \\(C = \\frac{1}{n}\\sum_{i=1}^{n}x_ix_i^T\\)</p> <p>if \\(X \\in \\mathbb{R}^{d \\times n}\\) is the matrix which represents  all the points in the dataset , \\(C\\) can also be written as \\(C = \\frac{1}{n}XX^T\\)</p> <p>This was just recalling and putting in the context to what is  about to happen now </p> <p>Let \\(w_k\\) be the eigenvector corresponding to the \\(k^{th}\\) largest eigenvalue  of \\(C\\) (\\(\\lambda_k\\)).</p> \\[\\begin{equation*}  \\begin{split} C w_k &amp;= \\lambda_k w_k \\\\ \\left(\\frac{1}{n} \\sum_{i=1}^{n} x_ix_i^T \\right) w_k &amp;= \\lambda_k w_k \\\\ w_k &amp;= \\frac{1}{n \\lambda_k} \\sum_{i=1}^{n} (x_i^Tw_k)x_i \\\\ w_k &amp;= \\sum_{i=1}^{n} \\left( \\frac{x_i^Tw_k }{n \\lambda_k} \\right)x_i \\\\ \\end{split} \\end{equation*} \\tag{1} \\label{Wk1}\\] <p>From this equation we can obeserve that \\(\\mathbf{w_k}\\) is a linear combination of datapoints, assuming \\(\\lambda_k \\neq 0\\).</p> \\[\\implies w_k = X\\alpha_k \\tag{2} \\label{Wk2}\\] <p>for some \\(\\alpha_k \\in \\mathbb{R}^n\\)</p> <p>To find the value \\(w_k\\) from the above equation , we need to know the value of \\(\\alpha_k\\)</p> <p>But if we compare \\(\\eqref{Wk1}\\) and \\(\\eqref{Wk2}\\) we can see that ,  \\(\\alpha_k = \\sum_{i=1}^{n} \\left( \\frac{x_i^Tw_k }{n \\lambda_k} \\right)\\)</p> <p>From the above equation , if we want to find \\(\\alpha_k\\) we need to know the  value \\(w_k\\) itself. This is a chicken and egg problem,to solve this problem we will take a look at another equation.</p> <p>We know,</p> \\[\\begin{equation*} \\begin{split} w_k &amp;= X \\alpha_k \\;\\;\\;\\;\\;\\;\\;\\;\\; \\forall k \\\\ \\\\ Cw_k &amp;= \\lambda_k w_k \\\\ \\left( \\frac{1}{n} XX^T \\right)(X \\alpha_k) &amp;= \\lambda_k X \\alpha_k \\\\ \\\\ \\text{Premultiplying by} X^T \\\\ \\\\ X^T((XX^T) X \\alpha_k) &amp;= X^T(n \\lambda_k X \\alpha_k) \\\\ (X^TX)(X^TX)\\alpha_k &amp;= n \\lambda_k (X^TX) \\alpha_k \\\\ \\\\ \\text{Let} X^TX = K \\\\  \\\\ K^2 \\alpha_k &amp;= n \\lambda_k K \\alpha_k \\\\  \\boxed{K \\alpha_k = (n \\lambda_k) \\alpha_k} \\\\ \\end{split} \\end{equation*}\\] <p>It is observed that for any \\(\\alpha_k\\) lets say \\(u\\) which satisfies  this equation , there exists a scaled version of \\(u\\) (Example \\(4u\\)) which  also satisfies this equation.</p> <p>To prevent the possibilities of scaled values of \\(\\alpha_k\\) , we will  narrow down the possible values using the idea that length of \\(w_k\\) is 1 i.e. \\(||w_k|| = 1\\).</p> <p>We know,</p> \\[\\begin{equation*} \\begin{split} w_k &amp;= X \\alpha_k \\\\  w_k^Tw_k &amp;= (X\\alpha_k)^T(X\\alpha_k) = \\alpha_k^T (X^TX) \\alpha_k \\\\ &amp;\\boxed{1 = \\alpha_k^T K \\alpha_k} \\\\ \\end{split} \\end{equation*}\\] <p>Now we have 2 equations , which \\(\\alpha_k\\) must satisfy.</p> <p>Up until now , we wanted the eigenvectors of \\(XX^T\\) which is \\(d \\times d\\)  matrix , but now we are saying we can solve the eigenequation of \\(K\\) , where \\(K = X^TX\\) which is a \\(n \\times n\\) matrix.</p> <p>But now the issue is , to get the value of \\(K\\) in the  equation </p> \\[K \\alpha_k = (n \\lambda_k) \\alpha_k\\] <p>the value of \\(\\lambda_k\\) is required  , which we can only get when we  solve for \\(XX^T\\) matrix. Back to square one \ud83d\ude2d.</p> <p>Now to find \\(\\lambda_k\\) we will find a relation between eigenvalues of  \\(XX^T\\) and \\(X^TX\\).</p> <p>Linear Algebra Fact :The non zero eigenvalues of \\(XX^T\\) and \\(X^TX\\) are exactly the same.</p> \\[\\begin{equation*} \\begin{split} \\text{For } C, \\\\ C &amp;= \\frac{1}{n} XX^T \\hspace{1cm} &amp; \\text{Eigenvectors} = \\{w_1 , w_2 .... , w_n \\} \\hspace{1cm} &amp; \\forall k , ||w_k||^2 = 1 \\\\  &amp;&amp; \\text{Eigenvalues} = \\{ \\lambda_1 \\geq \\lambda_2 \\geq .... \\geq \\lambda_n \\}  \\\\  \\\\ \\\\ \\text{For  } XX^T, \\\\ XX^T &amp;= n \\times C &amp; \\text{Eigenvectors} = \\{ w_1 , w_2 .... , w_l \\}  \\\\ &amp;&amp; \\text{Eigenvalues} = \\{ n\\lambda_1 \\geq n\\lambda_2 \\geq .... \\geq n\\lambda_l \\}  \\\\  \\\\ \\\\ \\text{For } X^TX \\\\ &amp;X^TX &amp; \\text{Eigenvectors} = \\{\\beta_1 , \\beta_2 , ..... \\beta_l  \\} \\hspace{1cm} &amp;  \\forall k, ||\\beta_k||^2 = 1 \\\\ &amp;&amp; \\text{Eigenvalues} = \\{ n\\lambda_1 \\geq n\\lambda_2 \\geq .... \\geq n\\lambda_l \\}  \\\\  \\end{split} \\end{equation*}\\] <p>Note that the eigenvalues of \\(XX^T\\) are the same \\(X^TX\\) from the  linear algebra fact.</p> <p>This gives us the final result as,</p> \\[\\boxed{K \\beta_k = (n \\lambda_k)\\beta_k}\\] <p>Now we need to check if \\(\\beta_k = \\alpha_k\\)?</p> \\[\\begin{equation*} \\beta_k^T K \\beta_k = \\beta_k^T(n \\lambda_k \\beta_k) = n \\lambda_k \\beta_k^T\\beta_k = \\boxed{n \\lambda_k} \\end{equation*}\\] <p>Therefore,</p> \\[\\alpha_k = \\frac{\\beta_k}{\\sqrt{n\\lambda_k}} , \\;\\;\\;\\; \\forall k \\] <p>The gist of this solution is that , when  \\(d &gt;&gt; n\\)  we use the eigenvectors of  \\(X^TX \\in \\mathbb{R}^{n \\times n}\\) instead of \\(XX^T \\in \\mathbb{R}^{d \\times d}\\) which reduces the computation time required to get the eigenvectors.</p> <p>New Algorithm when \\(d &gt;&gt; n\\)</p> <ol> <li>Compute \\(K = X^TX\\) , where  \\(K \\in \\mathbb{R}^{n \\times n}\\)</li> <li>Compute the eigendecomposition of \\(K\\) to get the eigenvectors and the  eigenvalues.</li> <li>Calculate for \\(\\alpha_k\\) , \\(\\alpha_k = \\frac{\\beta_k}{\\sqrt{n \\lambda_k}} \\;\\;\\;\\;\\; \\forall k\\)</li> <li>\\(\\boxed{w_k = X\\alpha_k} \\;\\;\\;\\;\\;\\; \\forall k\\)</li> </ol>"},{"location":"MLT/WEEK%202/Kernel%20PCA/#non-linear-relationship-of-datapoints","title":"Non-Linear Relationship of Datapoints","text":"<p>The issue of non-linear relationship arises when the datapoints  are related to each other in a \"non-linear\" way , it might be quadratic , cubic or  even biquadratic.</p> <p></p> <p>Now if the points of the dataset lie in a circle , determining the \"best fit line\" is pointless , almost all of the lines will be the best fit lines for this circle with a marginal difference of \"reconstruction error\" between them.</p> <p>The relation features of in this dataset can be represented using equation of a circle,</p> \\[(f_1 - a)^2 + (f_2 - b)^2 = r^2\\] <p>We can see that this equation has quadratic terms which cannot be  represented linearly. To solve this problem , we will map it to function with more features in order to represent it linearly.</p> \\[\\begin{equation*} \\begin{split} \\underset{\\mathbb{R}^2}{[f_1 , f_2]} \\xrightarrow{\\phi} \\overset{\\phi(x)}{\\underset{\\mathbb{R}^6}{[1 , f_1^2 , f_2^2 , f_1 f_2 , f_1 , f_2]}} \\\\  \\\\ \\text{Let } u \\in \\mathbb{R}^6  \\hspace{1cm} [a^2 + b^2 - r^2 , 1 , 1, 0 , -2a , -2b] \\\\ \\end{split} \\end{equation*}\\] <p>The function to map \\([f_1 , f_2]\\) to \\(\\mathbb{R}^6\\) is called \\(\\phi\\) and \\(u\\) is a point such that each datapoint of the original circular dataset satisfies,</p> \\[\\boxed{\\phi(x)^Tw = 0}\\] <p>The equation above shows that the datapoints after mapping to \\(\\mathbb{R}^6\\) lie in a linear subspace.</p> <p>Note</p> <p>Mapping \\(d\\) features to a polynomial of power \\(p\\) results in \\(^{d+p} C_d\\) new features.</p> <p>In the above equation of circle , it can be see in that mapping 2 features (\\(d\\))  to a polynomial of degree 2 (\\(p\\)), results in (\\(^{2+2} C_2\\)) 6 features.</p> <p>How does this solve our problem of non linear datapoints?</p> <p>For a dataset \\(S\\) , whose datapoints have a non-linear relationship (\\(x_i \\in \\mathbb{R}^d\\)), we can map this dataset to a higher dimension (linear subspace),  such that after mapping , \\(x_i \\in \\mathbb{R}^D\\).</p> <p>Note that \\(D &gt; d\\)</p> <p>As the points (after mapping to higher dimension) are in a linear subspace , our PCA algorithm  will work much better than before.</p> <p>Also note that , we already have a solution for the case when dimension of the datapoints is much  much larger than the number of datapoints (\\(d &gt;&gt; n\\)). </p>"},{"location":"MLT/WEEK%202/Kernel%20PCA/#kernel-functions","title":"Kernel Functions","text":"<p>Issues with Calculating \\(\\phi(x)\\)</p> <ul> <li>To run PCA on non-linear features , we came up with the solution of mapping (\\(\\phi(x)\\)) the  features to a higher dimension and then instead of calculating eigenvectors for a \\(d \\times d\\)  (Covariance) matrix , we calculated eigenvectors for \\(n \\times n\\) (\\(X^TX\\)) if \\(d &gt;&gt; n\\).</li> <li>The issue with current implementation of PCA is that calculating \\(\\phi(x)\\) is nearly  the same number of calculations as \\(O(d^p)\\). <ul> <li>This means that as the power of the polynomial increases , the calculation of individual  features in the mapping \\(\\phi(x)\\) rises exponentially.</li> <li>Example: If 2 features are mapped to a 20 power polynomial , the resulting number of  features will be nearly \\(2^{20}\\) , which is simply too many calculations.</li> </ul> </li> <li>To solve this problem we will now take a look at Kernel Functions.</li> </ul> <p>The eigendirections we compute (when mapping datapoints to a higher dimension) in PCA is of \\(\\phi(x)^T \\phi(x)\\).</p> <p></p> <p>To get to \\(K_{ij}\\) we first need to calculate \\(\\phi(x_i)^T \\phi(x_j)\\) , but is there a way to directly go from  \\(x_i \\quad x_j\\) to \\(K_{ij}\\) without computing \\(\\phi(x)\\) ?</p> <p>The function \\((x^T x^{'} + 1)^2\\) is one such function through which we can directly get to  \\(\\phi(x)^T \\phi(x^{'})\\),  without having to compute \\(\\phi(x)\\) and \\(\\phi(x^{'})\\).</p> <p>Lets say, \\(x = [f_1 , f_2] \\quad x^{'} = [g_1 , g_2]\\)</p> \\[\\begin{equation*} \\begin{split} (x^T x^{'} + 1)^2 &amp;= \\left( \\begin{bmatrix}f_1 &amp; f_2 \\end{bmatrix} \\begin{bmatrix} g_1 \\\\ g_2 \\end{bmatrix} + 1 \\right)^2 \\\\ &amp;= (f_1 g_1 + f_2 g_2 + 1)^2 \\\\  &amp;= f_1^2 g_1^2 + f_2^2 g_2^2 + 1 + 2f_1 g_1 f_2 g_2 + 2f_1 g_1 + 2f_2 g_2 \\\\ \\end{split} \\end{equation*}\\] <p>This can also be written as ,</p> \\[\\begin{equation*} \\begin{split} (x^T x^{'} + 1)^2 &amp;= \\begin{bmatrix}f_1^2 &amp; f_2^2 &amp; 1 &amp; \\sqrt{2}f_1 f_2 &amp; \\sqrt{2}f_1 &amp; \\sqrt{2}f_2 \\end{bmatrix}  \\begin{bmatrix}g_1^2 \\\\ g_2^2 \\\\ 1 \\\\ \\sqrt{2}g_1 g_2 \\\\ \\sqrt{2}g_1 \\\\ \\sqrt{2}g_2 \\end{bmatrix} \\\\ &amp;= \\phi(x)^T \\phi(x^{'}) \\\\ \\\\ \\text{where,}\\\\ \\\\ \\phi(x) &amp;= \\phi \\left( \\begin{bmatrix} a \\\\ b \\end{bmatrix}\\right) = \\begin{bmatrix}a^2 \\\\ b^2 \\\\ 1 \\\\ \\sqrt{2}a b \\\\ \\sqrt{2}a \\\\ \\sqrt{2}b \\end{bmatrix} \\\\\\end{split} \\end{equation*}\\] <p>We can see that , to calculate \\(\\phi(x)^T \\phi(x^{'})\\) we can instead solve for \\((x^T x^{'} + 1)^2\\) and  skip the step for calculating \\(\\phi(x)\\) and \\(\\phi(x^{'})\\).</p>"},{"location":"MLT/WEEK%202/Kernel%20PCA/#valid-kernel-functions","title":"Valid Kernel Functions","text":"<p>There are 2 ways to check if a function is a valid kernel function,</p> <ol> <li>There exists a mapping from \\(\\mathbb{R}^d\\) to \\(\\mathbb{R}\\) such that \\(k(x , x^{'}) = \\phi(x)^T \\phi(x^{'})\\).</li> <li>A kernel function is considered valid if ,<ul> <li>\\(k\\) is symmetric , i.e. , \\(k(x , x^{'}) = k(x^{'} , x)\\)</li> <li>The kernel matrix \\(K\\) , where \\(K_{ij} = k(x_i , x_j)\\) , is positive semi-definite.</li> </ul> </li> </ol> <p>Common Kernel Functions</p> <ol> <li>Polynomial Kernel: \\(k(x , x^{'}) = (x^Tx^{'} + 1)^p\\)</li> <li>Gaussian Kernel: \\(k(x , x^{'}) = \\exp \\left( - \\frac{|| x - x^{'}||^2}{2 \\sigma^2} \\right)\\) , for some \\(\\sigma &gt; 0\\).<ul> <li>\\(\\phi(x)\\) in this case is mapped to infinite dimension.</li> </ul> </li> </ol>"},{"location":"MLT/WEEK%202/Kernel%20PCA/#kenrel-pca","title":"Kenrel PCA","text":"<p>Now we need everything that is required to perform Kernel PCA on a non-linear dataset , lets put down an  algorithm for Kernel PCA.</p> <ul> <li>Input \\(\\{x_1 , x_2 , \\cdots , x_n \\}\\) \\(x_i \\in \\mathbb{R}^d\\) , kernel \\(k : \\mathbb{R}^d \\times \\mathbb{R}^d \\to \\mathbb{R}\\)</li> <li>Compute \\(K \\in \\mathbb{R}^{n \\times n}\\) where \\(K_{ij} = k(x_i,x_j) \\quad \\forall i,j\\)</li> <li>Center the kernel using,</li> </ul> \\[K^C = K - IK - KI + IKI\\] <p>where \\(K^C\\) is the centered kernel and \\(I \\in \\mathbb{R}^{n \\times n}\\) is a matrix with all elements equal to \\(\\frac{1}{n}\\)</p> <ul> <li>Compute \\(\\beta_1 , \\beta_2 , \\cdots , \\beta_l\\) eigenvectors and \\(n\\lambda_1 , n\\lambda_2 , \\cdots , n\\lambda_l\\) eigenvectors of K and normalize to get \\(\\alpha_k = \\frac{\\beta_k}{\\sqrt{n \\lambda_k}}\\)</li> <li>Compute the compressed representation using,</li> </ul> \\[\\begin{equation*} \\begin{split} \\phi(x_i)^T w_k &amp;= \\phi(x_j)^T \\left( \\sum_{j=1}^n \\phi(x_i) \\alpha_{kj} \\right) \\\\ &amp;= \\sum_{j=1}^n \\alpha_{kj} \\phi(x_i)^T \\phi(x_j) \\\\ &amp;= \\sum_{j=1}^n \\alpha_{kj} K_{ij} \\\\ \\end{split} \\end{equation*}\\] <ul> <li>Compute \\(\\sum_{j=1}^n \\alpha_{kj} K_{ij} \\quad \\forall k\\)</li> </ul> \\[\\phi(\\mathbf{x}_i)^T\\mathbf{w} \\in \\mathbb{R}^{d} \\to \\left [ \\begin{array}{cccc} \\displaystyle \\sum_{j=1}^{n} \\alpha_{1j} \\mathbf{K}^C_{ij} &amp; \\displaystyle \\sum_{j=1}^{n} \\alpha_{2j} \\mathbf{K}^C_{ij} &amp; \\ldots &amp; \\displaystyle \\sum_{j=1}^{n} \\alpha_{nj} \\mathbf{K}^C_{ij} \\end{array} \\right ]\\]"},{"location":"MLT/WEEK%203/Clustering/","title":"Clustering","text":""},{"location":"MLT/WEEK%203/Clustering/#introduction-to-clustering","title":"Introduction To Clustering","text":"<p>Clustering is a technique in unsupervised machine learning that involves  grouping similar data points together into clusters or groups based  on some similarity or distance measure. The goal of clustering is  to discover hidden patterns, structures,  or natural groupings within a dataset without  any prior knowledge of the groups or categories.</p>"},{"location":"MLT/WEEK%203/Clustering/#problems-with-clustering","title":"Problems with Clustering","text":"<p>The goal of this weak is to understand the information about datapoints which are clustered together.</p> <p>If we were to cluster datapoints into \\(k\\) different clusters  the total number of ways \\(n\\) datapoints can be clustered is  \\(k^n\\) (this includes empty clusters).</p> <p>For a set of datapoints from \\(\\{x_1 , x_2  , x_3 .... x_n \\}\\)  and the cluster indicators from \\(\\{z_1 , z_2 , z_3 , .... z_n \\}\\) , we need to develop a metric to get an idea of how good the  clusters are.</p> <p>2 clusters for a set of 5 datapoints</p> \\[\\stackrel{z_1 = 1 }{X_1} , \\stackrel{z_2 = 2}{X_2} , \\stackrel{z_3 = 1}{X_3} , \\stackrel{z_4 = 1}{X_4} , \\stackrel{z_5 = 2}{X_5}\\] <p>A common algorithm which can be used for this purpose is to  measure the distance of the datapoints from the mean of their  respective clusters and summing those values for each cluster  individually , a lower value indicates that the points are closely packed within a cluster , while a higher value indicates that the  points are spread apart.</p> <p>This algorithm can be formalized into a function as follows </p> \\[ F(z_1 , z_2 , z_3 , .... z_n ) = \\sum_{i=1}^{n} ||x_i - u_{z_i}||_2^2 \\] <p>where \\(\\mu_{z_i}\\) is mean of each \\(z_i^{th}\\) cluster.</p> <p>This way of clustering is considered an NP-Hard problem and  its computationally intensive as there are total of \\(k^n\\) possible combinations of datapoints.</p>"},{"location":"MLT/WEEK%203/Clustering/#k-means-clustering-lloyds-algorithm","title":"K-Means Clustering (Lloyd's Algorithm)","text":"<p>To solve the above problem of clustering we will take a look  at K-Means Algorithm.</p> <ul> <li> <p>The first step is Initialization , where each cluster  indicator is assigned a cluster between \\(1\\) to \\(k\\) for the  \\(0^{th}\\) iteration. $$ z_1^0 , z_2^0 , z_3^0 , .... z_n^0  \\;\\;\\;\\; \\in {1,2,3, .... k }$$</p> </li> <li> <p>We then compute the mean of each cluster for the \\(t^{th}\\) iteration. $$ \\mu_k^t = \\frac{\\sum_{i=1}^{n}x_i \\mathbb{1}(z_i^t = k)}{\\sum_{i=1}^{n}\\mathbb{1}(z_i^t = k)} \\;\\;\\;\\;\\;\\; \\forall k $$</p> </li> <li> <p>The next step is reassignment of the datapoints, $$ Z_i^{t+1} = \\underset{k}{\\text{arg } \\min} ||x_i  - \\mu_t^k ||_2^2 $$</p> <p>This step compares every point's distance to the mean of every other cluster , if the distance of the point to any cluster besides the \"current cluster\" is strictly less than the distance to the \"current cluster\" , then the point is assigned to the  cluster with least distance</p> </li> <li> <p>Then until convergence , loop between the second and third step until no new cluster assignments  are made.</p> </li> </ul> <p>Note</p> <p>K-Means Algorithm does not always produce the optimal solution but  usally produces reasonable clusters.</p> <p>Animation</p> <p></p> <p>This video was made by Jacob Bumgarner</p> <p>But what if the algorithm never actually converges?</p> <p>The short answer is Yes , the algorithm does converge. But how?</p>"},{"location":"MLT/WEEK%203/Clustering/#convergence-of-k-means-algorithm","title":"Convergence of K-Means Algorithm","text":"<p>FACT 1</p> <p>Let \\(X_1 , X_2 , X_3 ..... X_l \\in \\mathbb{R}^d\\) $$ v^* = \\underset{v \\in \\mathbb{R}^d}{\\text{arg min }} \\sum_{i=1}^{l} {|| x_i - v ||}^2$$</p> <p>For a bunch of datapoints we want a \\(v\\) such that it minimizes the average of sum of  squared distances.</p> <p>Using differentitation to solve this problem $$ v^* = \\frac{1}{l}\\sum_{i=1}^{n}X_i $$</p> <p>It can be seen that the answer to our problem will be the mean of all the datapoints. We will use the \"FACT\" (stated above) later in our proof of convergence of K-Means  Algorithm.</p> <p>Lets assume that we are at iteration \\(t\\) of Lloyd's/K-Means Algorithm. Then our current assignment of cluster indicators would look like $$ Z_1^t , Z_2^t , Z_3^t .... Z_n^t \\;\\;\\;\\;\\; \\in { 1, 2, 3 .... k}$$</p> <p>Here \\(t\\) corresponds to the iteration number and \\(n\\) corresponds to  the data point. Also , \\(\\mu_k^t\\) is the mean for cluster \\(k\\) in the \\(t^{\\text{th}}\\) (current) iteration.</p> <p>Now lets assume the algorithm does not converge and see what happens. If it doesnt converge , then the cluster indicators would be reassigned.</p> \\[ Z_1^{t+1} , Z_2^{t+1} , Z_3^{t+1} , ...... Z_n^{t+1} \\;\\;\\;\\;\\;\\;\\; \\in \\{1,2,3....k\\} \\] <p>After this reassignment we dont know for sure that this assignment of  cluster indicators is better than the previous one , to solve this problem  we will take a look at the \"objective function\".</p> <p>$$ \\begin{equation} \\sum_{i=1}^n {|| x_i - \\mu_{Z_i^t}^t ||}^2 \\tag{1} \\label{1} \\end{equation} $$  Here we can see that we are in the \\(t^{th}\\) iteration in which every point in  this experession , is being measured to the mean of the box/cluster its assigned to.</p> <p>Basically , this experession captures the distances of each point to its own box/cluster  in the \\(t^{\\text{th}}\\) iteration.</p> \\[ \\begin{equation} \\sum_{i=1}^{n} {||x_i - \\mu_{Z_i^{t+1}}^t ||}^2 \\tag{2} \\label{2} \\end{equation} \\] <p> Here the distance of every point is measured to the mean of the box/cluster it wants to switch to.</p> <p>If the algorithm hasnt converged, Some points might have lesser distance to their current cluster than the new cluster mean, they want to switch to , in that case \\(Z_i^{t+1}\\) is the same as \\(Z_i^t\\). While the other points might have distance closer to the new cluster mean  than their current mean , in that case they jump to the new cluster and thats when  the actual reassignment happens.</p> <p>As our assumption above , if the algorithm does not converge then there must be some points  who want to jump/switch to a new cluster mean which is closer to them.</p> <p>This means that the sum of \\(\\eqref{2}\\) will be less than the sum of \\(\\eqref{1}\\).</p> Why Does K-Means algorithm have finite number of iterations? <p>The total number of possible clusters is always \\(k^n\\) , which is a finite number.</p> <p>Basically , after each iteration the objective function (distance of points to the cluster mean) strictly decreases , which shows that after finite number of iterations , the algorithm will converge.</p>"},{"location":"MLT/WEEK%203/Clustering/#nature-of-clusters","title":"Nature of Clusters","text":"<p>Now that we know that the algorithm converges ,  what can we say about the clusters formed using this algorithm </p> <p>Lets understand this with an example where there are only 2 clusters. The means of the 2 clusters are \\(\\mu_1\\) and \\(\\mu_2\\).</p> <p>By the algorithm's construction we know that every point is happy with their own mean , this also can be thought of as that every point that is assigned to cluster  1 is closer to \\(\\mu_1\\) than it is to \\(\\mu_2\\).</p> <p>This can be expressed as,</p> \\[ {||x - \\mu_1||}^2 \\leq {||x - \\mu_2||}^2 \\] <p>This equation can further be changed into </p> \\[ \\begin{equation*} \\begin{split} {||x||}^2  + {||\\mu_1||}^2 - 2x^T\\mu_1 \\leq {||x||}^2 + {||\\mu_2||}^2 - 2x^T\\mu_2 \\\\ x^T(\\mu_2 - \\mu_1) \\leq \\frac{{||\\mu_2||}^2 - {||\\mu_1||}^2}{2} \\end{split} \\end{equation*}\\] <p>Note that the above equation is very much similar to a linear equation like \\(x^T w \\leq b\\)</p> <p>Now how do we visualize this ? , what does this  actually represent?</p> <p></p> <p> Here the black line is the difference between \\(\\mu_1\\) and \\(\\mu_2\\) and the green  line is the set of all points such that \\(x^T(\\mu_2 - \\mu_1) = 0\\) , also this green line is  perpendicular to the black line.</p> <p>From this figure a rough estimate would be that length of \\(\\mu_2\\) is greater than  length of \\(\\mu_1\\) , i.e. ,  \\(||\\mu_2|| &gt; ||\\mu_1||\\). Also \\(x^T(\\mu_2 - \\mu_1)\\) is at most  \\(\\frac{{||\\mu_2||}^2 - {||\\mu_1||}^2}{2}\\). As length of \\(\\mu_2 &gt; \\mu_1\\) , this means that the line corresponding to \\(x^T(\\mu_2 - \\mu_1) = \\frac{{||\\mu_2||}^2 - {||\\mu_1||}^2}{2}\\) will lie on the right hand side of the \"green\" line.</p> <p></p> <p> The yellow line is drawn from the middle point of \\(\\mu_2 - \\mu_1\\) parallel to  the green line , this is the line that divides the plane into 2 regions for cluster 1  and cluster 2.</p> <p>We are classifying all the points as a part of Cluster 1, which lie on the left of  \\(\\frac{{||\\mu_2||}^2 - {||\\mu_1||}^2}{2}\\) (orange line).</p> Cluster Means Representation (k=3) <p></p> <p>Essentially, We divide the entire space into \\(k\\) regions according the lines formed by the perpendicular bisectors  of, the line joining the means of \\(k\\) different clusters. Such regions are also known as Voronoi Regions.</p>"},{"location":"MLT/WEEK%203/Clustering/#initialization-of-centroids-k-means","title":"Initialization of Centroids, K-Means++","text":"<p>Initially we assigned the points to random boxes , but this is not the best way to assign the points. If the means are carefully picked , that will most likely decrease the time taken to get to the solution  produced by K-Means Algorithm. The idea behind K-Means++ is to give the algorithm a slight push/headstart when initializing cluster means.</p> <p>In K-Means++ Algorithm we pick means of points which are as far apart as they can be.</p> <ul> <li>It chooses first mean \\(\\mu_1^0\\) uniformly at random from  \\(\\{x_1 , x_2 , x_3 , .... , x_n \\}\\) </li> <li>For \\(l = 2 , 3 , .... k\\) , (where \\(l\\) represents the \\(l^{\\text{th}}\\) mean that we are going to pick) choose \\(\\mu_l^0\\) probabilistically proportional  to score. Here score is a positive number.</li> </ul> \\[ S(x) = \\underset{j=1,2,.... l-1}{\\min} {||x - \\mu_j^0||}^2 \\] <ul> <li> <p>The scores generated this way wont lie in the range of 0 to 1, to use these scores probabilistically we will normalize them by dividing the scores with the sum of all the distances from that cluster.</p> </li> <li> <p>After selecting the \\(k\\) means , we continue with K-Means Algorithm.</p> </li> </ul> <p>Animation</p> <p></p> <p>This video was made by Jacob Bumgarner</p>"},{"location":"MLT/WEEK%203/Clustering/#choice-of-k","title":"Choice of K","text":"<p>According to our original objective function, $$ F(z_1 , z_2 , z_3 , .... z_n ) = \\sum_{i=1}^{n} ||x_i - u_{z_i}||_2^2 $$</p> <p>If \\(k=n\\) , i.e. , number of clusters is the same as number of datapoints then , our objective function will output 0.</p> <p>However , such large values of \\(k\\) arent helpful for drawing insights from a  clustered data.</p>"},{"location":"MLT/WEEK%203/Clustering/#modified-objective-function","title":"Modified Objective Function","text":"<p>What is the solution for the problem of large \\(k\\)? What changes should we  make to our objective function?</p> <p>Our goal is to,</p> <ul> <li>Make \\(k\\) as small as possible while also having the smallest objective function value.  </li> <li>To counter the problem of large \\(k\\) , we will penalize large values of \\(k\\).</li> </ul> <p>Our modified objective function will be,</p> \\[\\text{Objective Function} + \\text{Penalty}(k)\\] <p>As \\(k\\) (number of clusters) increases the value of objective function will lesser and lesser ,  but , at the same time large values of \\(k\\) will suffer a penalty.</p>"},{"location":"MLT/WEEK%204/Estimation/","title":"Estimation","text":""},{"location":"MLT/WEEK%204/Estimation/#introduction-to-estimation","title":"Introduction to Estimation","text":"<p>There is some probabilistic mechanism that generates  the data for which, we dont know all the parameters.</p> <p>The goal of estimation is to find the parameters  we dont know about.</p> <p>Is there a principaled way to get estimators  from data?</p> <p>The way one can do this is by using the likelihood function.</p>"},{"location":"MLT/WEEK%204/Estimation/#maximum-likelihood-estimation-mle","title":"Maximum Likelihood Estimation (MLE)","text":"<p>Lets say there is a button, when pressed , gives the output as either 0 or 1. The button generates the following distribution , when pressed 4 times \\(x \\in \\{1,0,1,1\\}\\). </p> <p>If we were to estimate the probability of \\(P(X_1 =1 , X_2 = 0 , X_3 = 1 , X_4 = 1)\\), our  assumption would be that the above distribution was originally generated from some  probabilistic model/mechanism.</p> <p>The \\(P(X_1 =1 , X_2 = 0 , X_3 = 1 , X_4 = 1)\\) will be </p> <p></p> <p>If we were to guess the probability that \\(X\\) takes a certain  value , \\(\\frac{3}{4}\\) would be what most people agree on. This guess is also justified with the plot above, but how do  we actually end up with this guess? Is there a certain mathematical way/formula to get here?</p>"},{"location":"MLT/WEEK%204/Estimation/#fishers-principle-of-mle","title":"Fisher's Principle of MLE","text":"<p>Assumptions About The Distribution</p> <ol> <li>It is always assumed that the distribution for which we are  estimating unknown parameters , is always independent.<ul> <li>This means that the probability of 2 events dont affect each other.</li> <li>\\(P(x_i | x_j) = P(x_i) \\quad \\forall i \\neq j\\)</li> </ul> </li> <li>It is always assumed that the distribution for which we are  estimating unknown parameters , is always identically distributed.<ul> <li>This means that 2 different events from the same distribution , always follow the same \"assumed probabilistic model/mechanism\".</li> </ul> </li> </ol>"},{"location":"MLT/WEEK%204/Estimation/#maximum-likelihood-of-bernoulli-distribution","title":"Maximum Likelihood of Bernoulli Distribution","text":"\\[\\begin{equation*} \\begin{split} \\mathcal{L}(p , \\{\\mathbf{x}_1 , \\mathbf{x}_2 , .... \\mathbf{x}_n \\}) &amp;= P(\\mathbf{x}_1 , \\mathbf{x}_2 , \\mathbf{x}_3 , ... \\mathbf{x}_n ; p) \\\\ &amp;= P(\\mathbf{x}_1 ;p) \\cdot P(\\mathbf{x}_2;p)  .... P(\\mathbf{x}_n;p) \\\\ &amp;= \\prod_{i=1}^{n} p^{x_i} (1-p)^{1- x_i} \\end{split} \\end{equation*}\\] <p>From the above likelihood function we can see that  the following function is to be maximized </p> \\[\\begin{equation*} \\begin{split} \\hat{P}_{\\text{ML}} &amp;= \\underset{p}{\\arg \\max} \\prod_{i=1}^n p^{x_i} (1-p)^{1 - x_i} \\\\ \\\\ \\text{As log is monotonous increasing function,} \\\\ \\text{the point where } \\hat{P}_{\\text{ML}} \\text{ and } \\log (\\hat{P}_{\\text{ML}}) \\\\ \\text{ take the maximum value is the same}\\\\ &amp;= \\underset{p}{\\arg \\max} \\log \\left(\\prod_{i=1}^n p^{x_i} (1-p)^{1 - x_i} \\right) \\\\ &amp;= \\underset{p}{\\arg \\max} \\left(\\sum_{i=1}^n \\log p * \\mathbf{x}_i * \\log (1-p)*(1 - x_i) \\right) \\\\ \\\\ \\text{Taking derivative of }\\log (\\hat{P}_{\\text{ML}}) \\\\ \\hat{P}_{\\text{ML}} &amp;= \\frac{1}{n}\\sum_{i=1}^n \\mathbf{x_i} \\\\ \\end{split} \\end{equation*}\\] <p>We can now see where our guess previously originates from.</p> <p>Issues with Maximum Likelihood Estimation</p> <p>Lets say for a data of random numbers which depicts the  height of different people , we want to estimate the parameters from the data.</p> <p>Here we cannot use the same \"button\" which we used earlier as it only outputs 0 or 1.</p> <p>Gaussian Distribution is assumed to be the probabilistic model  behind data of people's heights. The parameters for a gaussian distribution are \\(\\mu\\) (mean)  and \\(\\sigma^2\\) (variance).</p> <p>For the sake of simplicity we will assume that \\(\\sigma^2\\) (variance) is  known. The likelihood function for the assumed gasussian distribution will be, </p> \\[\\begin{equation*} \\begin{split} \\mathcal{L}(\\boldsymbol{\\mu} , \\boldsymbol{\\sigma^2} , {x_1 , x_2 , \\cdots , x_n}) &amp;= P(x_1 , x_2 , \\cdots , x_n , \\boldsymbol{\\mu} , \\boldsymbol{\\sigma^2}) \\\\ &amp;= \\prod_{i=1}^n P(x_i ; \\boldsymbol{\\mu} , \\boldsymbol{\\sigma^2}) \\\\ \\end{split} \\end{equation*}\\] <p>We know that Gaussian Distribution is a Continuous Distribution, which means that  probability of \\(x\\) taking a specific value is always 0. Hence, \\(P(x_i ; \\mu , \\sigma^2) = 0 \\quad \\forall i\\)</p> <p>Success</p> <p>To counter the above problem , instead of taking probabilities in maximum likelihood estimation, we use Probability Density Functions.</p> <p>Therefore our new Likelihood Function will be,</p> \\[\\begin{equation*} \\begin{split} L(\\mu , \\sigma^2 , {x_1 , x_2 , \\cdots , x_n}) &amp;= \\mathcal{f}_{x_1 , x_2 , \\cdots , x_n}(x_1 , x_2 , \\cdots , x_n ; \\mu , \\sigma^2) \\\\ &amp;= \\prod_{i=1}^n \\mathcal{f}_{x_i}(x_i ; \\mu , \\sigma^2) \\end{split} \\end{equation*}\\]"},{"location":"MLT/WEEK%204/Estimation/#maximum-likelihood-estimation-of-gaussian-distribution","title":"Maximum Likelihood Estimation of Gaussian Distribution","text":"\\[\\begin{align*} \\mathcal{L}(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2;\\{\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n\\}) &amp;= f_{\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n}(\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n;\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2) \\\\ &amp;=\\prod _{i=1} ^n  f_{\\mathbf{x}_i}(\\mathbf{x}_i;\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2) \\\\ &amp;=\\prod _{i=1} ^n \\left [ \\frac{1}{\\sqrt{2\\pi}\\boldsymbol{\\sigma}} e^{\\frac{-(\\mathbf{x}_i-\\boldsymbol{\\mu})^2}{2\\boldsymbol{\\sigma}^2}} \\right ] \\\\ \\therefore \\log(\\mathcal{L}(p;\\{\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n\\})) &amp;= \\sum _{i=1} ^n \\left[ \\log \\left (\\frac{1}{\\sqrt{2\\pi}\\boldsymbol{\\sigma}}  \\right ) - \\frac{(\\mathbf{x}_i-\\boldsymbol{\\mu})^2}{2\\boldsymbol{\\sigma}^2} \\right] \\\\ \\end{align*}\\] <p>By differentiating with respect to \\(\\boldsymbol{\\mu}\\) and \\(\\boldsymbol{\\sigma}\\) we get,</p> \\[\\begin{align*} \\hat{\\boldsymbol{\\mu}}_{\\text{ML}} &amp;= \\frac{1}{n}\\sum _{i=1} ^n \\mathbf{x}_i \\\\ \\hat{\\boldsymbol{\\sigma}^2}_{\\text{ML}} &amp;= \\frac{1}{n}\\sum _{i=1} ^n (\\mathbf{x}_i-\\boldsymbol{\\mu})^T(\\mathbf{x}_i-\\boldsymbol{\\mu}) \\end{align*}\\]"},{"location":"MLT/WEEK%204/Estimation/#bayesian-estimator","title":"Bayesian Estimator","text":"<p>Sometimes when estimating the unknown parameters of some data , we might have a \"hunch\" about the parameters of the data. To incorporate this \"hunch\" about parameters of interest  into the estimation procedure, we will take  look at Bayesian Estimation.</p> <p>Our approach for Bayesian Estimation would be to think of  the parameter to estimate as a random variable. Earlier to estimate a parameter (lets say) \\(p\\) , we used to  find out the \"most likely\" value of \\(p\\) using MLE. Now, if we are given a coin and asked to estimate the probability  of Heads , our \"hunch\" before even seeing the data of coin  toss would be that the coin is unbiased. In reality , the coin may be biased or it may also be unbiased but according to  our \"hunch\" about the probability of coin landing on Heads , the \"most likely\" value should be \\(\\frac{1}{2}\\).</p> <p>We will incorporate our \"hunch\" into MLE  by thinking of our \"hunch\" as a probability distribution over  some random variable \\(\\theta\\).</p> <ul> <li> <p>The Probability Density Function of \\(P(\\theta)\\) represents      our \"hunch/belief\" about the parameter of interest ,      before seeing the data.  </p> </li> <li> <p>This distribution of \\(P(\\theta)\\) is called the Prior Distribution.</p> </li> <li> <p>Encoded Hunch for a Coin</p> <p></p> <p>Note: The coin may be biased or it also may be unbiased but our  \"hunch\" will say that coins in general tend to be unbiased , hence the  \"most likely\" probability is 0.5</p> </li> </ul> <p>After seeing the data , we have to update our belief/hunch. There are 2 cases which occur after seeing the data.  </p> <ol> <li> <p>Our assumption/belief is against the actual data.</p> <ul> <li>In the case of a Coin , if the coin is biased , then our hunch (that the probability is 0.5) is against the data.</li> </ul> </li> <li> <p>Our assumption/belief is closer to the actual data.</p> <ul> <li>In the case of a Coin , if the coin is biased ,  but the Probability of Coin landing on Heads , is near \\(0.5\\). Then our assumption/belief about the parameter \\(p\\) is closer  to the actual data.</li> </ul> </li> </ol> <p>In both the cases above , we need to update our \"hunch/belief\"  in order to get a better estimate.  </p> <ul> <li>This estimate is given by \\(P(\\theta | \\text{Data})\\).  </li> <li>This distribution of \\(P(\\theta|\\text{Data})\\) is called the Posterior Distribution.</li> </ul> <p></p> Bayes Theorem \\[ P(A|B)  = \\frac{P(B|A) \\times P(A)}{P(B)}\\] <p>For a given dataset \\(\\{ x_1 , x_2 , \\cdots , x_n \\}\\) and a parameter \\(\\theta\\), according to bayes theorem,</p> \\[\\begin{equation*} \\begin{split} P(\\theta | \\{ x_1 , x_2 , \\cdots , x_n \\} ) = \\frac{P(\\{ x_1 , x_2 , \\cdots , x_n \\}|\\theta) \\times P(\\theta)}{P(\\{ x_1 , x_2 , \\cdots , x_n \\})} \\\\ \\end{split} \\end{equation*}\\]"},{"location":"MLT/WEEK%204/Estimation/#bayesian-estimate-of-bernoulli-distribution","title":"Bayesian Estimate of Bernoulli Distribution","text":"<p>For a dataset \\(\\{ x_1 , x_2 , \\cdots , x_n \\}\\) where \\(x_i \\in \\{ 0,1 \\} \\quad \\forall i\\) with parameter \\(\\theta\\).</p> <p>A suitable distribution for incorporating our \"hunch/belief/prior\" is Beta Distribution. </p> \\[\\begin{equation*} \\begin{split} f(p;\\alpha,\\beta) = \\frac{p^{\\alpha-1}(1-p)^{\\beta-1}}{z} \\quad \\forall p \\in [0,1] \\\\ \\text{where z is the normalizing factor} \\end{split} \\end{equation*}\\] <p>Using the above Beta Distribution as a Prior we get,</p> \\[\\begin{equation*} \\begin{split} P(\\theta|\\{x_1, x_2, \\ldots, x_n\\}) &amp;\\propto P(\\theta|\\{x_1, x_2, \\ldots, x_n\\})*P(\\theta) \\\\ f_{\\theta|\\{x_1, x_2, \\ldots, x_n\\}}(p) &amp;\\propto \\left [ \\prod _{i=1} ^n {p^{x_i}(1-p)^{1-x_i}} \\right ]*\\left [ p^{\\alpha-1}(1-p)^{\\beta-1} \\right ] \\\\ f_{\\theta|\\{x_1, x_2, \\ldots, x_n\\}}(p) &amp;\\propto p^{\\sum _{i=1} ^n x_i + \\alpha - 1}(1-p)^{\\sum _{i=1} ^n(1-x_i) + \\beta - 1} \\end{split} \\end{equation*}\\] \\[  \\text{BETA PRIOR }(\\alpha, \\beta) \\xrightarrow[Bernoulli]{\\{x_1, x_2, \\ldots, x_n\\}} \\text{BETA POSTERIOR }(\\alpha + n_h, \\beta + n_t) \\] \\[ \\therefore \\hat{p_{\\text{ML}}} = \\mathbb{E}[\\text{Posterior}]=\\mathbb{E}[\\text{Beta}(\\alpha +n_h, \\beta + n_t)]= \\frac{\\alpha + n_h}{\\alpha + n_h + \\beta + n_t} \\] <p>Types of Beta Distribution</p> <p></p>"},{"location":"MLT/WEEK%204/Estimation/#gaussian-mixture-models-gmm","title":"Gaussian Mixture Models (GMM)","text":"<p>A Gaussian Mixture Model (GMM) is a probabilistic model that represents a mixture of multiple Gaussian (normal) distributions. In simpler terms, it's a way of describing a dataset as a combination of several Gaussian-shaped clusters.</p> What is the need of Gaussian Mixture Models? (GMM) <p>To answer this question lets take a look at a simple example  where maximum likelihood fails.  </p> <p>Lets say there are points lying on whole number line , which  represents the datapoints of a dataset \\(D\\). To represent these points in a probabilistic manner we would  have to \"assume\" that these points are generated from some  distribution. To find this distribution , we will use the method of maximum likelihood for a gaussian distribution.</p> <p></p> <p>It can be seen that the Gaussian Distribution derived from  maximum likelihood is centered somewhere around 10.</p> <p>The issue with this approach is that the orange cluster of points  dont have the same density as the green cluster of points. In other words , according to the derived gaussian distribution , the chance of generating points around orange clusters is very less when compared to that of green clusters.  </p> <p></p> <p>Hence , the above gaussian distribution (derived using maximum likelihood)  does not represent the \"true/actual\" distribution of datapoints.</p> <p>What is the solution for this problem then? What would be an appropriate  density estimation?  </p> <p>Answer : Combine several gaussian distributions together</p> <p></p> <p>The above density distribution is a much better representation of the  \"assumed\" probabilistic model for all the datapoints.</p>"},{"location":"MLT/WEEK%204/Estimation/#procedure-of-generating-gmm","title":"Procedure of Generating GMM","text":"<ul> <li> <p>Generate a mixture componenet among \\(\\{ 1,2,\\cdots K \\}\\) where \\(z_i \\in \\{ 1,2,\\cdots K \\}\\). We obtain, $$ P(z_i=k) = \\pi_k \\hspace{2em} \\left [ \\sum _{i=1} ^K \\pi_i = 1 \\hspace{1em} 0 \\le \\pi_i \\le 1 \\hspace{1em} \\forall i \\right ] $$</p> <ul> <li>\\(z_i\\) is the mixture indicator.</li> <li>This step selects a mixture from which the datapoint originates.</li> </ul> </li> <li> <p>Generate \\(x_i \\sim \\mathcal{N}(\\mu_{z_i} , \\sigma^2_{z_i})\\)</p> <ul> <li>Every mixture has its own mean and variance. Lets say the 3rd mixture is selected among the \\(K\\) mixtures. We will generate a datapoint from \\(\\mathcal{N}(\\mu_{z_3} , \\sigma^2_{z_3})\\).</li> <li>This step generates a datapoint from the selected mixture.</li> </ul> </li> </ul> <p>How many parameters do we have to find using parameter estimation?</p> <p>Each mixture has:  </p> <ul> <li>A \\(\\pi_k\\) probability , such that \\(\\sum_{i=1}^K \\pi_i = 1\\) (all the probabilities  sum upto 1)</li> <li>2 variables , mean (\\(\\mu\\)) and variance (\\(\\sigma^2\\)). Both of these parameters  are unknown to us.</li> </ul> <p>Therefore , for \\(K\\) mixtures , the number of parameters which need to estimated are \\((K-1) + 2K = 3K -1\\).</p> <p>Where does \"-1\" in \\(K -1\\) come from? All the probabilities sum upto 1 , if we know all the probabilities except the last one ,  we can find out the last probability by summing the rest and subtracting from 1.</p>"},{"location":"MLT/WEEK%204/Estimation/#likelihood-of-gmm","title":"Likelihood of GMM","text":""},{"location":"MLT/WEEK%205/Supervised%20Learning/","title":"Supervised Learning","text":"<p>For a bunch of datapoints \\(\\{x_1 , x_2 , .... x_n \\} \\;\\;\\;\\; x_i \\in \\mathbb{R}^d\\)  are called features/attributes and \\(\\{y_1 , y_2 , .... y_n  \\}\\) corresponding to the  datapoints are called the labels. These labels provide \"supervision\" for our  algorithms.</p> <p>These labels can take different types of values</p> <ul> <li>Binary Classification: Where the labels take only two values and they  come from \\(\\{+1 , -1 \\}\\).</li> <li>Multiclass Classification : Where the labels take multiples values/classes from a set  like \\(\\{0,1,2,.....9 \\}\\).</li> </ul>"},{"location":"MLT/WEEK%205/Supervised%20Learning/#linear-regression","title":"Linear Regression","text":"<p>For input/training data \\(\\{x_1 , x_2 , .... x_n \\} \\;\\;\\;\\; x_i \\in \\mathbb{R}^d\\)  our goal is to learn a function \\(h : \\mathbb{R}^d \\to \\mathbb{R}\\) which converts a feature to a label.</p> <p>There are many functions which map \\(\\mathbb{R}^d \\to \\mathbb{R}\\) , so  how do we measure the \"goodness\" of a function?</p> <p>To measure the error of a function </p> \\[\\text{error}(h) = \\sum_{i=1}^n (h(x_i) - y_i)^2 \\] <p>In the best case scenario , how small can this error be?</p> <p>0 is the least value the error function can take and it only happens  when \\(h(x_i) = y_i \\forall i\\)</p> <p>However this \\(h(x)\\) may not always be the best function for the mapping</p> <p>Some of the problems with \\(h(x)\\) are </p> <ul> <li>To achieve 0 error , we always output the same label for each feature , this \\(h(x)\\) \"memorizes\" the mapping from \\(\\mathbb{R}^d\\) to \\(\\mathbb{R}\\) and this  function may not always be useful. Functions like this tend to overfit the training data and produce considerable  errors on testing data.</li> </ul> <p>How to prevent overfitting of training data?</p> <p>Our goal now is to use the same squared error function ,  but impose a certain structure to reduce our search space.</p> <p>One of the simplest structures we could impose is a linear  structure.</p> <p></p> <p>Now our modified goal is </p> \\[\\underset{h_w \\in H_{\\text{linear}}}{\\min} \\sum_{i=1}^{n} (h_w(x_i) - y_i)^2\\] <p>or equivalently </p> \\[\\underset{w \\in \\mathbb{R}^d}{\\min} \\sum_{i=1}^{n} (w^Tx_i - y_i)^2\\]"},{"location":"MLT/WEEK%205/Supervised%20Learning/#optimizing-the-error-function","title":"Optimizing the Error Function","text":"<p>Now that we have identified a function for our  algorithm , we should think of a way to optimize this function </p> <p>The above function can be rewritten as follows </p> \\[\\begin{equation*} \\begin{split} \\underset{w \\in \\mathbb{R}^d}{\\min} &amp; {||X^Tw - y||}^2 \\\\ \\underset{w \\in \\mathbb{R}^d}{\\min} &amp; (X^Tw - y)^T(X^Tw - y) \\\\ \\end{split} \\end{equation*}\\] <p>The above equation is an unconstrained optimization problem , to minimize the equation we will now take the derivative and  equate it to zero.</p> \\[\\begin{equation*} \\begin{split} f(w) &amp;= (X^Tw - y)^T(X^Tw - y) \\\\ \\nabla f(w) &amp;= 2 (XX^T)w - 2(Xy) \\\\ (XX^T)w^* &amp;= Xy \\\\ w^* &amp;= (XX^T)^\\dagger(Xy) \\end{split} \\end{equation*}\\]"},{"location":"MLT/WEEK%205/Supervised%20Learning/#geometric-interpretation-of-linear-regression","title":"Geometric Interpretation of Linear Regression","text":"<p>Lets say for a dataset with number of features to be 2  (\\(d=2\\)) and number of points be 3 (\\(n=3\\)).</p> <p>How can we interpret \\(w^* = (XX^T)^\\dagger(Xy)\\) geometrically?</p> <p>Now if we draw an \\(n\\) dimensional space , in our case its \\(n =3\\), the first vector that we will have will be in \\(\\mathbb{R}^3\\) and the other  vector also in \\(\\mathbb{R}^3\\).</p> <p></p> <p>Note that we are not plotting the the datapoints but the features themselves.</p> <p>Now we plot the label in the same \\(\\mathbb{R}^3\\) subspace. </p> <p>We can see that the linear combinations of the features (green vectors) will lie in the same plane as the features themselves.</p> <p>Now if we also plot the label vector (\\(y\\)) onto the same \\(\\mathbb{R}^3\\) subspace , it may or may not lie in the same plane as of the features themselves.</p> <p>In the case it does not lie in the plane spanned by the features , we will find the closest projection of \\(y\\) onto the plane.</p> <p></p> <p>We also know that the red point will also be a linear combination of the features  as it lies in the same plane as of the features themselves.</p> <p>So for some real numbers like \\(\\alpha^*_1 , \\alpha^*_2\\) , the red point can be  expressed as the linear combination of features (\\(\\alpha^*_1f_1 + \\alpha^*_2f_2\\))</p> \\[\\implies \\alpha^*_1f_1 + \\alpha^*_2f_2 = X^T \\alpha^*\\] <p></p> <p>We also know that \\(X^T\\alpha^*\\) and \\(y - X^T \\alpha^*\\) are orthogonal to each other.</p> <p></p> \\[\\begin{equation*} \\begin{split} \\implies (X^T \\alpha^*)^T(y - X^T \\alpha^*) &amp;= 0 \\\\ y^TX^T \\alpha^* - {\\alpha^*}^T(XX^T) \\alpha^* \\\\ \\end{split} \\end{equation*}\\] <p>Now what happens if we put \\(w^* = \\alpha^*\\) , where  \\(w^* = {(XX^T)}^\\dagger Xy\\)</p> <p>The new equation will be,</p> \\[y^T X^T ((XX^T)^\\dagger Xy) - ((XX^T)^\\dagger Xy)^T (XX^T) (XX^T)^\\dagger Xy = 0\\] <p>With this equation we basically prove that the solution \\(\\alpha^*\\) we were looking for  is the same as \\(w^*\\)</p>"},{"location":"MLT/WEEK%205/Supervised%20Learning/#gradient-descent","title":"Gradient Descent","text":"<p>We know that \\(w^*\\) has a closed form solution which is \\(w^* = (XX^T)^\\dagger Xy\\), but it is computationally expensive to compute \\(w^*\\) as it takes \\(O(d^3)\\) iterations. Also, solving for \\(w^*\\) is an unconstrained optimization problem , which can be solved using the method of Gradient Descent.</p> <p>Gradient Descent is an iterative way to find minimizers of functions using just first order information , which is gradient of the function (vector of partial  derivatives).</p> \\[ w^{t+1} = w^t - \\eta_t \\nabla f(w^t) \\] <p>The gradient tells you the direction where function will increase , instead , when doing gradient descent we move opposite to the direction of the gradient  along the function , where it gradually decreases.</p> <ul> <li>\\(\\eta_t\\) is a scalar value and it is the step-size we take to move along the function.</li> <li>\\(f(w^t)\\) gives us the direction of the gradient.</li> </ul> <p>After some iterations , we eventually reach the global minima of the function.</p> <p>Our original Mean Squared Error function was,</p> \\[\\begin{equation*} \\begin{split} f(w) &amp;= ||Xw - y||^2 = \\sum_{i=1}^{n} (w^T x_i - y_i)^2 \\\\ \\nabla f(w) &amp;= 2 (XX^T)w - 2Xy \\\\ \\end{split} \\end{equation*}\\] <p>Now we can use this gradient of \\(f(w)\\) in the gradient descent equation,</p> \\[ w^{t+1} = w^t - \\eta_t [2(XX^T)w - 2Xy] \\] <p>This solves the problem of not having to compute the inverse of \\(XX^T\\) , which takes \\(O(d^3)\\) iterations. Using gradient descent to calculate \\(w^*\\) makes it less computationally expensive.</p> <p>Now what to do if \\(n\\) is too large, we know that \\(XX^T\\) is a \\(d \\times n * n * \\times d\\) matrix , just to calculate \\(XX^T\\) there is an inner dependency of \\(n\\), hence it becomes  computationally expensive to solve for \\(XX^T\\).</p> <p>Is there any way we can avoid computing \\(XX^T\\)?</p>"},{"location":"MLT/WEEK%205/Supervised%20Learning/#stochastic-gradient-descent","title":"Stochastic Gradient Descent","text":"<p>for \\(t = 1,2,3 ...... T\\) </p> <ul> <li>At each step sample a bunch (\\(k\\)) of datapoints uniformly at random from the set of  all datapoints.</li> <li>Pretend as if this sample (\\(k\\) datapoints) is the entire dataset and take a gradient  step with respect to it, </li> </ul> \\[2(\\tilde{X}\\tilde{X}^T w^t - \\tilde{X} \\tilde{y})\\] <p>where \\(\\tilde{X}\\) is the sampled (\\(k\\)) datapoints and \\(\\tilde{y}\\) are the labels corresponding  to the datapoints.</p> <p>This makes calculating \\(XX^T\\) managable as we only take \\(k\\) points at a time.</p> <p>After \\(t\\) rounds , use </p> \\[ w^T_{\\text{SGD}} = \\frac{1}{T} \\sum_{i=1}^{t} w^t \\] <p>At the end we basically take the average of the \\(w^t\\) obtained after several iterations , though the direction of descent may be noisy at first but in a typical case the average usually gives out the \\(w^*\\) with least possible noise.</p> <p>Stochastic Gradient Descent is always guaranteed to converge to optima with high probability.</p>"},{"location":"MLT/WEEK%205/Supervised%20Learning/#kernel-regression","title":"Kernel Regression","text":"<p>Our goal here is to map the data points to a higher dimensional space and  then learn a linear model in higher dimension (regressor) without explicitly computing the higher dimensional mappings.</p> <p>The solution for \\(w^*\\) in \\(w^* = (XX^T)^ \\dagger Xy\\) lies in the subspace spanned by the datapoints.</p> <p>It can also be seen as \\(w^*\\) lying in a \\(\\mathbb{R}^3\\) subspace spanned by the datapoints.</p> <p>How?</p> <p></p> <p>Lets say that there are some data points in \\(\\mathbb{R}^3\\) , even though they are 3-dimensional  vectors , lets assume that they all line in some 2-d plane (in our case its the green area above)</p> <p></p> <p>For arguments sake , lets assume that our \\(w^*\\) lies outside the (green) plane. To minimize  the error we will now take a point which is closest to \\(w^*\\) which lies on the same (green) plane.</p> <p>Here , \\(\\tilde{w}\\) is the projection of \\(w^*\\)/ closest point to \\(w^*\\) which lies in the  same (2-d) space spanned by the datapoints.</p> <p>Now , lets see what's the difference between error functions of \\(w^*\\) and \\(\\tilde{w}\\) </p> \\[\\sum_{i=1}^n ({w^*}^Tx_i - y_i) \\;\\;\\;\\;\\; \\text{and} \\;\\;\\;\\;\\; \\sum_{i=1}^n ({\\tilde{w}}^Tx_i - y_i)\\] <p>\\(w^*\\) can be written as the sum of \\(\\tilde{w}\\) and the vector perpendicular to \\(\\tilde{w}\\) , which is  \\(\\tilde{w}_{\\perp}\\)</p> <p>Note that \\(\\tilde{w}_{\\perp}\\) is perpendicular to the (2-d) plane itself , which means it  is perpendicular / orthogonal to all the points which lie in the plane (datapoints).</p> \\[\\begin{equation*} \\begin{split} w^* &amp;= \\tilde{w} + \\tilde{w}_{\\perp} \\\\ {w^*}^Tx_i &amp;= {(\\tilde{w} + \\tilde{w}_{\\perp} )}^T x_i \\\\ &amp;= \\tilde{w} x_i + \\tilde{w}_{\\perp}^T x_i  \\\\ &amp;= \\tilde{w} x_i \\;\\;\\;\\;\\;\\; \\forall i \\\\ \\end{split} \\end{equation*}\\] <p>\\(\\tilde{w}_{\\perp}^T x_i\\) will become 0 as explained above. </p> <p>Now we see that the error for both \\(w^*\\) and \\(\\tilde{w}\\) is exactly  the same.</p> <p>It can also be seen that \\(w^*\\) is some combination of the datapoints, which can be written as </p> \\[w^* = X \\alpha^*\\] <p>for some \\(\\alpha^* \\in \\mathbb{R}^n\\) </p> <p>We also know that ,</p> \\[\\begin{equation*} \\begin{split} w^* &amp;= (XX^T)^\\dagger Xy \\\\ X \\alpha^* &amp;= (XX^T)^\\dagger Xy \\\\ (XX^T) X \\alpha^* &amp;= (XX^T)(XX^T)^\\dagger Xy \\\\ (XX^T) X \\alpha^* &amp;=  Xy \\\\ X^T(XX^T) X \\alpha^* &amp;= X^TXy \\\\ (X^T X)^2 \\alpha^* &amp;= X^TXy \\\\ K^2 \\alpha^* &amp;= Ky \\\\  \\alpha^* &amp;= K^{-1}y \\\\ \\end{split} \\end{equation*}\\] <p>\\(K = X^T X\\) , is the kernel matrix.</p>"},{"location":"MLT/WEEK%205/Supervised%20Learning/#prediction","title":"Prediction","text":"<p>We know that,</p> \\[ w = \\sum_{i=1}^n \\alpha_i x_i \\] <p>Also Prediction \\(= w^T x_{\\text{test}}\\) ,</p> \\[\\begin{equation*} \\begin{split} w^T x_\\text{test} &amp;= (\\sum_{i=1}^n \\alpha_i x_i )^T x_\\text{test} \\\\ &amp;= \\sum_{i=1}^n \\alpha_i (x_i^T x_\\text{test}) \\\\ &amp;= \\sum_{i=1}^n ( \\phi(x_i)^T \\phi(x_\\text{test}) ) \\\\ &amp;= \\sum_{i=1}^n \\alpha_i K (x_i , x_\\text{test}) \\\\ \\end{split} \\end{equation*}\\] <p>where \\(\\alpha_i\\) shows how important is \\(i^\\text{th}\\) point  towards \\(w^*\\) and \\(K(x_i , x_\\text{test})\\) shows how similar is \\(x_\\text{test}\\) to \\(x_i\\).</p>"},{"location":"MLT/WEEK%205/Supervised%20Learning/#probabilistic-view-of-linear-regression","title":"Probabilistic view of Linear Regression","text":"<p>In a linear regression problem we know that , \\(x \\in \\mathbb{R}^d\\) , \\(y \\in \\mathbb{R}\\)  for a set of datapoints \\(\\{ (x_1 , y_1) , (x_2 , y_2) , ..... (x_n , y_n) \\}\\).</p> <p>The probabilistic we are going to assume is as follows,</p> \\[ y|x \\sim w^T x + \\epsilon \\] <p>For a given feature theres is an unknown but fixed \\(w \\in \\mathbb{R}^d\\) and  \\(\\epsilon\\) is a zero-mean gaussian (\\(\\mathcal{N}(0 , \\sigma^2)\\))noise.</p> <p>Now we can view this as an estimation problem and solve it using the  maximum likelihood approach.</p> <p>The likelihood function will be ,</p> \\[\\begin{equation*} \\begin{split} \\mathcal{L}(w ; \\substack{x_1 , x_2 , ... x_n \\\\ y_1 , y_2 , ... y_n} ) &amp;= \\prod_{i=1}^n e^{- \\frac{(w^Tx_i - y_i)^2}{2 \\sigma^2}} \\times \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\\\ \\log \\mathcal{L}(w ; \\substack{x_1 , x_2 , ... x_n \\\\ y_1 , y_2 , ... y_n} ) &amp;= \\sum_{i=1}^n  \\frac{-(w^Tx_i - y_i)^2}{2 \\sigma^2} \\times \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\\\ \\\\ \\text{equivalently} \\\\ \\\\ &amp;= \\underset{w}{\\max} \\sum_{i=1}^{n} - (w^T x_i - y_i)^2 \\\\ &amp;= \\underset{w}{\\min} \\sum_{i=1}^n (w^Tx_i - y_i)^2 \\\\ \\end{split} \\end{equation*}\\] <p>Note that the mean of the distribution becomes \\(w^Tx + 0\\) as \\(\\epsilon\\) is a  zero-mean gaussian distribution , which makes the final distribution to be  \\(\\mathcal{N}(w^Tx , \\sigma^2)\\)</p> <p>Also, we ignored the constants in the later half of the derivation because they are, you guessed it , constants. :p</p> <p>Finally from this we can conclude that \\(w^* = w_\\text{ML} = (XX^T)^\\dagger Xy\\)</p>"},{"location":"MLT/WEEK%206/Regression/","title":"Regression","text":""},{"location":"MLT/WEEK%206/Regression/#goodness-of-maximum-likelihood-estimator-for-linear-regression","title":"Goodness of Maximum Likelihood Estimator for linear Regression","text":"<p>In the previous week we observed that \\(w^*\\) which comes from the  squared error equation is the same as \\(\\hat{w}_{\\text{ML}}\\) which  came from the maximal Likelihood equation.</p> <p>Now we are going to look at \\(\\hat{w}_{\\text{ML}}\\) and its properties , which will gives us a better idea of \\(w\\). For \\(\\hat{w}_{\\text{ML}}\\) our assumption was that,</p> \\[y|x = w^T x + \\epsilon \\] <p>where \\(\\epsilon\\) (gaussian noise) belongs to a gaussian distribution with mean 0 and variance \\(\\sigma^2\\)  (\\(\\epsilon \\sim \\mathcal{N}(0 , \\sigma^2)\\)). For every \\(x\\) in our data \\(y\\) was generated using some \\(w^T x\\) , using some unknown  but fixed \\(w\\) and then adding 0 mean gasussian noise to it.</p> <p>Hence , \\(y\\) given \\(x\\) can be thought of as gaussian distribution with mean \\(w^T x\\) and  variance \\(\\sigma^2\\) (\\(y|x \\sim \\mathcal{N}(w^T x , \\sigma^2)\\))</p> <p>For \\(\\hat{w}_{\\text{ML}}\\) we should now look for a way to test that , how good the function is as a guess from true \\(w\\).</p> <p>A good function to compare \\(\\hat{w}_{\\text{ML}}\\)  to \\(w\\) is</p> \\[{||\\hat{w}_{\\text{ML}} - w ||}^2\\] <p>and to see what happens to this value on an average we will  look at its expected value over the randomness in \\(y\\), which can be written as </p> \\[E[{||\\hat{w}_{\\text{ML}} - w ||}^2]\\] <p>If we solve for the expected value further , we get</p> \\[E[{||\\hat{w}_{\\text{ML}} - w ||}^2] = \\sigma^2 \\text{trace}((XX^T)^ \\dagger)\\] <p>where \\(\\sigma^2\\) is the variance from the gaussian noise</p> <p>\\(\\sigma^2\\) in the expected value of the above function cant be reduced ,  it is the variance / loss which will always happen. Only thing we can reduce is the trace of the inverse of covariance matrix</p>"},{"location":"MLT/WEEK%206/Regression/#cross-validation-for-minimizing-mse","title":"Cross-validation for minimizing MSE","text":"<p>We know that trace of a matrix is the sum of the diagonal entries of matrix , but in previous courses we have also seen that trace of a matrix is also equal to  the sum of the eigenvalues of that matrix.</p> \\[\\text{tr}(A) = \\sum_{i=1}^{d} \\lambda_i\\] <p>where \\(A\\) is any matrix , \\(d\\) is the dimension of the matrix and  \\(\\lambda_i\\) is the \\(i^{\\text{th}}\\) eigenvalue.</p> <ul> <li>Let the eigenvalues of \\((XX^T)\\) be \\(\\{\\lambda_1 , \\lambda_2 , .... \\lambda_d \\}\\).</li> <li>The eigenvalues of \\((XX^T)^{-1}\\) are \\(\\{ \\frac{1}{\\lambda_1} , \\frac{1}{\\lambda_2} , .... \\frac{1}{\\lambda_d} \\}\\)</li> </ul> <p>The mean squared error equation \\((\\hat{w}_{\\text{ML}})\\),</p> \\[E(|| \\hat{w}_{\\text{ML}} - w ||^2) = \\sigma^2 \\left( \\sum_{i=1}^d \\frac{1}{\\lambda_i} \\right)\\] <p>Consider the following estimator:</p> \\[\\hat{w}_{\\text{new}} = (XX^T + \\lambda I )^{-1} XY \\] <ul> <li>For some matrix \\(A\\) , let the eigenvalues be \\(\\{ \\lambda_1 , \\lambda_2 , ..... \\lambda_d \\}\\)</li> <li>Now what will be the eigenvalues of \\(A + \\lambda I\\)?</li> </ul> \\[\\begin{equation*} \\begin{split} A v_1 &amp;= \\lambda_1 v_1 \\\\  (A + \\lambda I)v_1 &amp;= A v_1 + \\lambda v_1 \\\\ &amp;= \\lambda_1 v_1 + \\lambda v_1 \\\\  &amp;= (\\lambda_1 + \\lambda) v_1 \\\\ \\end{split} \\end{equation*}\\] <p>\\(\\implies\\) eigenvalues will be \\(\\{ \\lambda_1 + \\lambda , \\lambda_2 + \\lambda , ... \\lambda_d + \\lambda \\}\\)</p> <ul> <li>Similarly eigenvalues of \\({(XX^T + \\lambda I)}^{-1}\\) will be \\(\\{ \\frac{1}{\\lambda_1 + \\lambda} , \\frac{1}{\\lambda_2 + \\lambda} , ... \\frac{1}{\\lambda_d + \\lambda} \\}\\)</li> </ul> \\[\\therefore \\text{trace}((XX^T + \\lambda I)^{-1}) = \\left( \\sum_{i=1}^d \\frac{1}{\\lambda_i + \\lambda} \\right)\\] <p>If the MSE is really large one of the reasons for  it might because the trace of the matrix was really large ,  which means the eigenvalues were really small  (smaller eigenvalues give large trace as they are inversely proportional). To counter this we artifically introduced \\(\\lambda\\)  which increases the overall eigenvalues and hence  reducing the trace of the matrix , which in turn decreases MSE.</p>"},{"location":"MLT/WEEK%206/Regression/#types-of-cross-validation","title":"Types of Cross Validation","text":"<p>Three commonly used techniques for cross-validation are as follows:</p> <ul> <li>Training-Validation Split: The training set is randomly divided into a training set and a validation set, typically in an 80:20 ratio. Among various \\(\\lambda\\) values, the one that yields the lowest error is selected.</li> <li>K-Fold Cross Validation: The training set is partitioned into K equallysized parts. The model is trained K times, each time using K-1 parts as the training set and the remaining part as the validation set. The \\(\\lambda\\) value that leads to the lowest average error is chosen.</li> <li>Leave-One-Out Cross Validation: The model is trained using all but one sample in the training set, and the left-out sample is used for validation. This process is repeated for each sample in the dataset. The optimal \\(\\lambda\\) is determined based on the average error across all iterations.</li> </ul>"},{"location":"MLT/WEEK%206/Regression/#bayesian-modeling-for-linear-regression","title":"Bayesian Modeling for Linear Regression","text":"What are conjugate priors? <p>The key property of a conjugate prior is that,  when combined with a likelihood function,  the resulting posterior distribution belongs to the same  family of distributions as the prior.  This property simplifies the computation of the posterior distribution.</p> <p>Note: The conjugate prior for a gaussian distribution is gaussian distribution itself.</p> <p>We know that our original likelihood function was, </p> \\[ y|x  \\sim \\mathcal{N}(w^Tx , 1) \\] <p>where we are taking \\(\\sigma^2 = 1\\) for convenience , the following derivation will  still be valid when variance is just \\(\\sigma^2\\).</p> <p>Now our prior will be,</p> \\[ w \\sim \\mathcal{N}(0 , \\gamma^2 I) \\] <p>where \\(\\mu \\in \\mathbb{R}^d\\) and \\(\\gamma^2 I \\in \\mathbb{R}^{d \\times d}\\)</p> <p>Now,</p> \\[\\begin{equation*} \\begin{split} P(w| \\{ (x_1 , y_1) , (x_2 , y_2) , .... (x_n , y_n) \\}) &amp;\\propto P(\\{(x_1 , y_1) , (x_2 , y_2) , .... (x_n , y_n) \\}|w) \\times P(w) \\\\  &amp;\\propto \\left(\\prod_{i=1}^{n} e^{-\\frac{(y_i - w^Tx)^2}{2}} \\right) \\times \\left(\\prod_{i=1}^{n} e^{-\\frac{(w_i - 0)^2}{2 \\gamma^2}} \\right) \\\\ &amp;\\propto \\left(\\prod_{i=1}^{n} e^{-\\frac{(y_i - w^Tx)^2}{2}} \\right) \\times e^{- \\frac{||w||^2}{2 \\gamma^2}} \\\\ \\end{split} \\end{equation*}\\] <p>Now how will maximum aposterior (MAP) estimate look like? (Here we are taking log of the above function)</p> \\[\\begin{equation*} \\begin{split} \\hat{W}_{\\text{MAP}} &amp;= \\overset{\\arg}{\\underset{w}{\\max}} \\sum_{i=1}^{n}- \\frac{(y_i - w^Tx_i)^2}{2} - \\frac{||w||^2}{2 \\gamma^2} \\\\  \\hat{W}_{\\text{MAP}} &amp;= \\overset{\\arg}{\\underset{w}{\\min}} \\sum_{i=1}^{n} \\frac{(y_i - w^Tx_i)^2}{2} + \\frac{||w||^2}{2 \\gamma^2} \\\\  \\end{split} \\end{equation*}\\] <p>Taking gradient of this function,</p> \\[\\begin{equation*} \\begin{split} \\nabla f(w) &amp;= (XX^T)w - Xy + \\frac{w}{\\gamma^2} \\\\  \\hat{W}_{\\text{MAP}} &amp;= (XX^T + \\frac{1}{\\gamma^2}I )^{-1}Xy \\end{split} \\end{equation*}\\] <p>We can see that the same estimator can be derived when  find out MAP for a gaussian distribution prior.</p>"},{"location":"MLT/WEEK%206/Regression/#ridge-regression","title":"Ridge Regression","text":"<p>Previously our linear regression equation was, </p> \\[ \\hat{w}_{\\text{ML}} = \\underset{w}{\\arg \\min} \\sum_{i=1}^{n} (w^T x_i - y_i)^2 \\] <p>The Ridge Regression equation is given as,</p> \\[ \\hat{w}_{\\text{R}} = \\underset{w}{\\arg \\min} \\sum_{i=1}^{n} (w^T x_i - y_i)^2 + \\lambda ||w||^2 \\] <p>where \\(\\sum_{i=1}^{n} (w^T x_i - y_i)^2\\) is the loss and \\(\\lambda ||w||^2\\) is the regularizer.</p> <ul> <li>The regularizer has bayesian viewpoint to it as shown in the above derivation, also it can be thought of as adding a penalty on the overall function for  prefering a certain type of \\(w\\).</li> <li>The higher the weights of the \\(w\\) the larger the penalty , it can also  be thought of as prefering \\(w\\) which have their features reduced to zero or almost zero.</li> </ul> <p>Note</p> <ul> <li>Ridge Regression has more error than linear regression.</li> <li>Ridge Regresison increases the training error so that the model does not overfit.</li> </ul>"},{"location":"MLT/WEEK%206/Regression/#relation-between-solution-of-linear-regression-and-ridge-regression","title":"Relation Between Solution of Linear Regression and Ridge Regression","text":"<p>Lets say for a dataset we solved the linear regression problem and got \\(\\hat{w}_{\\text{ML}}\\) on  a 2-d subspace</p> <p></p> <p>Now is there any way to find the ridge regression solution for the same dataset?</p> <p>We know that equation of ridge regression is, </p> \\[ \\hat{w}_{\\text{R}} = \\underset{w}{\\arg \\min} \\sum_{i=1}^{n} (w^T x_i - y_i)^2 + \\lambda ||w||^2 \\] <p>It can be argued that this problem/equation is the same as  constrained optimization problem,</p> \\[\\begin{equation*} \\begin{split} \\underset{w \\in \\mathbb{R}^d}{\\min} &amp; \\sum_{i=1}^n (w^T x_i - y_i)^2 \\\\ \\\\ \\text{such that}\\\\ &amp; ||w||^2 \\leq \\theta \\\\ \\end{split} \\end{equation*}\\] <p>For every choice of \\(\\lambda &gt; 0\\) , there exists a \\(\\theta\\) such that the optimal solutions of Ridge Regression and Constrained Ridge Regression coincide.</p> <p>In a 2-d space , when \\(||w||^2 \\leq \\theta\\) , it can be written as,</p> \\[\\begin{equation*} \\begin{split} ||w||^2 \\leq \\theta \\\\ \\implies w_1^2 + w_2^2 \\leq \\theta \\\\ \\end{split} \\end{equation*}\\] <p>This is very similar to the equation of a circle whose radius (here) is \\(\\theta\\) and it is centered at origin.</p> <p></p> <p>From the above image we can see that we have found out a constrained  area for \\(\\hat{w}_{\\text{Ridge}}\\) , but where it is exactly?</p> <p>What is the loss/error value of linear regression at  \\(\\hat{w}_{\\text{ML}}\\)?</p> <p>Note</p> <p>The loss calculated at \\(\\hat{w}_{\\text{ML}}\\) is the least when  compared to any other \\(w\\).</p> \\[\\begin{equation*} \\begin{split} \\sum_{i=1}^n (\\hat{w}_{\\text{ML}} x_i - y_i)^2 &amp;= f(\\hat{w}_{\\text{ML}}) \\\\  \\end{split} \\end{equation*}\\] <p>Consider the set of \\(w\\) such that </p> \\[\\begin{equation*} \\begin{split} f(w) &amp;= f( \\hat{w}_{\\text{ML}} ) + c \\;\\;\\;\\;\\;\\; c&gt;0 \\\\ S_c &amp;= \\{ w : f(w) = f( \\hat{w}_{\\text{ML}}) + c \\} \\\\ \\end{split} \\end{equation*}\\] <p>Every vector in \\(S_c\\) satisfies,</p> \\[\\begin{equation*} \\begin{split} \\underset{f(w)}{||X^Tw - y||^2} &amp;= \\underset{f(\\hat{w}_{\\text{ML}})}{|| X^T \\hat{w}_{\\text{ML}} - y ||^2 } + c \\\\  \\\\ \\text{on simplification,}\\\\ (w - \\hat{w}_{\\text{ML}})^T (XX^T) (w - \\hat{w}_{\\text{ML}}) &amp;= c' \\\\ \\end{split} \\end{equation*}\\] <p>If we have \\(\\hat{w}_{\\text{ML}}\\) , \\(XX^T\\) and \\(c'\\) we can get a set  of all the \\(w\\) which satisfy the above equation such that they  are \\(c'\\) distance away in terms of error when compared to \\(\\hat{w}_{\\text{ML}}\\).</p> <p>If \\(XX^T = I\\) (\\(I\\) = Identity Matrix),</p> \\[\\begin{equation*} \\begin{split} (w - \\hat{w}_{\\text{ML}})^T I (w - \\hat{w}_{\\text{ML}}) &amp;= c' \\\\ || w - \\hat{w}_{\\text{ML}} ||^2 = c' \\\\ \\end{split} \\end{equation*}\\] <p>This again corresponds to the equation of a circle (with c' radius) in a 2-d space ,  but thats only the case when \\(XX^T = I\\). If \\(XX^T \\neq I\\) then instead of a circle ,  an ellipse is formed around \\(\\hat{w}_{\\text{ML}}\\) . </p> <p> </p> <p>If we keep increasing the \\(c'\\) while using the same values for \\(\\hat{w}_{\\text{ML}}\\) and \\(XX^T\\) , ellipses with increasing size are formed around \\(\\hat{w}_{\\text{ML}}\\)  which eventually touch the circle formed by the constrained ridge regression equation.</p> <p></p> <p>The point where it touches (yellow dot) is the ridge regression solution with the  least loss possible when compared to any other \\(\\hat{w}_{\\text{Ridge}}\\) in the  green circle. In other words that point (yellow dot) is closest to \\(\\hat{w}_{\\text{ML}}\\) and yet  satisfy the constrained ridge regression equation.</p> <p>Conclusion</p> <p>We can see that Ridge Regression pushes the values in the wieght vector (\\(w\\)) to 0 , but does not necessarily make them 0.</p>"},{"location":"MLT/WEEK%206/Regression/#relation-betwen-solution-of-linear-regression-and-lasso-regression","title":"Relation betwen solution of Linear Regression and Lasso Regression","text":"<p>Our goal here is to change the regularizer in ridge regression  equation in such a way that the elliptical contours around \\(\\hat{w}_{\\text{ML}}\\)  hit at a point where some of the features become zero.</p> <p>We know that ridge regression pushes feature values towards 0. But does not  necessarily make it 0.</p> <p>An alternate way to regularize would be to use \\(||\\cdot||_1\\) norm instead  of \\(||\\cdot||^2_2\\) norm.</p> \\[ ||w||_1 = \\sum_{i=1}^d | w_i | \\] <p>For L1 Regularization , </p> \\[\\begin{equation*} \\begin{split} &amp; \\underset{w \\in \\mathbb{R}^d}{\\min} \\sum_{i=1}^{n} (w^T x_i - y_i)^2 + \\lambda ||w||_1\\\\ \\\\ &amp; \\text{which is similar to} \\\\  \\\\  &amp; \\underset{w \\in \\mathbb{R}^d}{\\min} \\sum_{i=1}^{n} (w^T x_i - y_i)^2 \\\\ &amp; \\text{such that}\\\\ \\\\ ||w||_1 \\leq \\theta \\\\ \\end{split} \\end{equation*}\\] <p>When compared to L2 Constraint on the regularizer ,  this is how L1 constraint would look like </p> <p></p> <p>Now when we keep increasing the size of the elliptical contours  around \\(\\hat{w}_{\\text{ML}}\\) our hope is that it touches the point  where some of the features of weight vector become zero.</p> <p></p> <p>When looking at this , one can argue that the elliptical contours  will not always touch red area in such a way that one of the weight vectors becomes 0; Which is true when looking at it in a 2d subspace , but in higher dimensions the typical case is when some of weight vectors  become 0.</p> <p>This way of using L1 Regularizer is called LASSO (Least Absolute Shrinkage and Selection Operator)</p>"},{"location":"MLT/WEEK%206/Regression/#characteristics-of-lasso-regression","title":"Characteristics of Lasso regression","text":"<p>We know now that lasso regression makes certain weight vectors zero ,  so why not always use lasso?</p> <p>Advantages of using Ridge Regression vs Lasso Regression,</p> <ul> <li>Lasso Regression does not have a closed form solution.</li> <li>Sub-gradient methods are usually used to solve for Lasso Regression.</li> </ul>"},{"location":"MLT/WEEK%206/Regression/#what-are-sub-gradients","title":"What are Sub-Gradients?","text":"<p>For a piecewise linear function at the point \\(x\\) (purple) point the function  is not differentiable , sub-gradient provide a lower bound for this function at  \\(x\\) (purple point).</p> <p>At the blue point the function is differentiable and hence only 1 sub-gradient exists which is the gradient/slope itself. </p> <p>Now , what is the use of sub-gradients in lasso regression? We know that the regularizer in lasso regression takes the absolute values of  weight vectors, </p> <p>At the origin (green point) finding the differential is not  possible , hence we bound the function using sub-gradients.</p> <p></p> <p>Any sub-gradient between \\([-1,1]\\) lower bounds the function (\\(|x|\\)).</p> <p>Definition of Sub-Gradients</p> <p>A vector \\(g \\in \\mathbb{R}^d\\) is a sub-gradient of \\(f:\\mathbb{R}^D \\to \\mathbb{R}\\) at  a point \\(x \\in \\mathbb{R}^d\\) , if </p> \\[\\forall z \\;\\;\\;\\;\\;\\;\\;\\;\\; f(z) \\geq f(x) + g^T(z - x)\\] <p> </p> <p>Whats the use of Sub-Gradients?</p> <p>If function \\(f\\) to minimize is a convex function , then  sub-gradient descent converges.</p>"},{"location":"MLT/WEEK%207/Classification/","title":"Classification","text":"<p>Note</p> <p>Throughout the diagrams I have used red color to indicate a +1 or  positive label and blue color for -1 or a negative label </p>"},{"location":"MLT/WEEK%207/Classification/#classification","title":"Classification","text":""},{"location":"MLT/WEEK%207/Classification/#introduction-to-binary-classification","title":"Introduction to Binary Classification","text":"<p>For a set of datapoints \\(\\{ x_1 , x_2 , x_3 ... x_n \\}\\) where  \\(x \\in \\mathbb{R}^d\\) and labels \\(\\{ y_1 , y_2 , y_3 ... y_n \\}\\)  where \\(y \\in \\{ 0,1 \\} / \\{ -1,1 \\}\\). Our goal is to get a function \\(h\\) which maps the datapoints  to the classes (\\(h:\\mathbb{R}^d \\to \\{ 0,1 \\}\\)).</p>"},{"location":"MLT/WEEK%207/Classification/#loss-function","title":"Loss Function","text":"\\[\\text{Loss}(h) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{1}(h(x_i) \\neq y_i) \\quad \\quad \\quad \\mathbb{1}(z) = \\begin{cases} 1 &amp; \\text{if true} \\\\ 0 &amp; \\text{otherwise} \\end{cases}\\] <p>Like in the case of linear regression , where we restricted the  space for the loss function , to a linear space ; We can do something  similar to that here too</p> \\[\\begin{equation*} \\begin{split} \\underset{h \\in \\mathcal{H}_\\text{linear}}{\\min} \\sum_{i=1}^n \\mathbb{1}(h(x_i) \\neq y_i) \\\\ \\\\ \\text{where,}\\\\ \\\\ \\mathcal{H}_\\text{linear} = \\{ h_w : h_w(x) = \\text{sign}(w^T x) \\} \\\\ \\text{sign}(z) = \\begin{cases} 1 &amp; \\text{if z&gt;0} \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\end{split} \\end{equation*}\\] <p></p> <p>The above problem is an NP-Hard Problem in general. In regression we used to take the gradient , set it to zero and find  the \\(w\\), that doesnt apply here because the loss here can only take 2  discrete values (0 or 1) which makes this loss function non - differentiable an non - continuous.</p> <p>Can we somehow use linear regression to solve for this classification problem?</p> <p>For a dataset \\(\\{(x_1 , y_1) , (x_2,y_2) , ... (x_n , y_n) \\}\\) , then we input this dataset to a linear regression model which gives out a \\(w \\in \\mathbb{R}^d\\). At the end we use this \\(w\\) to get \\(h_w\\) by solving for \\(w^Tx =0\\) (\\(h_w : \\mathbb{R}^d \\to \\{ 0,1 \\}\\)).</p> <p>Is this a good idea? Does this help us?</p> <p></p> <p>Now if we add more positive label datapoints , </p> <p>We can see that the \\(w\\) gets skewed which in turn changes \\(h_w\\). The above algorithm depends on a linear regression model which solves for \\(w\\) by taking into account all the datapoints.</p> <p>From a linear classification point of view , the classifying line \\(h_w\\) shouldnt  be changed when new datapoints are introduced on either side but from a regression point of view these datapoints which are far apart from the classifying line  ,we are trying to minimize over all the datapoints , because of which  our \\(w\\) gets  tilted back and forth. </p> <p>This will give us lines which dont actually classify the datapoints properly.</p> <p>Conclusion</p> <p>Regression is sensitive to location of the datapoints and not just the  \"side\" on which the data lies with respect to the separator. </p>"},{"location":"MLT/WEEK%207/Classification/#k-nearest-neighbours-knn","title":"K-Nearest Neighbours (KNN)","text":"<p>For some set of datapoints with corresponding labels , if a new datapoint's (for which we predict the label) belongs to the training dataset , then we already have an answer for its (new datapoint's) label, but what to do when it doesnt belong to the training dataset?</p> <ul> <li> <p>Given a test points \\(x_\\text{test} \\in \\mathbb{R}^d\\) , find the closest  point \\(x^*\\) to \\(x_\\text{test}\\) in the training set.</p> </li> <li> <p>Predict \\(y_\\text{test} = y^*\\)</p> </li> </ul> <p>Is this a good algorithm? </p> <p>Issues with this algorithm</p> <ul> <li>This algorithm can get affected by outliers. </li> <li>Lets say our nearest point to \\(x_\\text{test}\\) happens to be an outlier, then our algorithm will predict the same value as \\(y^*\\) , which may label the point wrongly.</li> </ul> <p>Simple Fix for Issue Above</p> <ul> <li>Given \\(x_\\text{test}\\) , find the \\(k\\) closest points in the training dataset  \\((x_1^* , x_2^* , ... x_k^*)\\).</li> <li>Predict \\(y_\\text{test} = \\text{Majority}(y_1^* , y_2^* , ... y_k^*)\\)</li> </ul> <p>We have to supply the parameter \\(k\\) for the above fix , which the data does  not tell us, so how many neighbours we should look for?</p>"},{"location":"MLT/WEEK%207/Classification/#decision-boundry","title":"Decision Boundry","text":""},{"location":"MLT/WEEK%207/Classification/#case-1-k-1","title":"Case 1 (k = 1)","text":"<p>Lets look at the case when \\(k=1\\),</p> <p></p> <p>Note that these datapoints already have specified labels which comes from the dataset.</p> <p>Because \\(k=1\\) we get \"holes\" in certain regions for the decision boundry, looking at it objectively the blue point in the red region and vis a vis are  certainly outliers and should be ignored , but our classification algorithm is  sensitive to outliers.</p> <p>Also on the extreme right end we can see that there are some red points , which makes  the whole area on the right region as red , ideally that should have been blue ,  as those extreme right red points are outliers.</p> <p>Now we know that taking \\(k=1\\) is a bad idea. ;C</p> <p>Animation</p> <p> </p> <p>The nearest datapoint to \\(x_\\text{test}\\) (White Dot) is  the Positively Labelled (Red) Dot.</p>"},{"location":"MLT/WEEK%207/Classification/#case-2-kn","title":"Case 2 (k=n)","text":"<p>Now lets look at the case when \\(k=n\\)</p> <p>Note that these datapoints already have specified labels which comes from the dataset.</p> <p></p> <p>Our algorithm here considers all the datapoints as closest , because \\(k=n\\) ,  hence we take the majority of the labels and make the decision boundry. In our case the majority of the labels are blue (negative) and hence the whole  region is considered to be blue (negative).</p> <p>In other words if we do a prediciton for a label of some point , our answer will always be negative (blue) label.</p> <p>Problems Encountered</p> <ul> <li>Asking too few (\\(k=1\\)) neighbours gives us an outlier issue.</li> <li>Asking too many (\\(k=n\\)) neighbours gives us the \"majority label\".</li> </ul> <p>Animation</p> <p> </p> <p>The Majority Label in the dataset is +1 (Red Dot) hence, \\(x_\\text{test}\\) (White Dot) is Positively Labelled.</p> <p>What to do then?</p> <p>We must find such a \\(k^*\\) that it ignores the outliers and yet it maintains  a resonable decision boundry.</p> <p></p> <p>Animation</p> <p> </p> <ul> <li>Here we took k=25.</li> <li>It can be seen that \\(x_\\text{test}\\) (White Dot) lies  near a cluster of Positively Labelled (Red) Dots. </li> </ul> <p>How do find the right number of neighbours (\\(k^*\\))?</p>"},{"location":"MLT/WEEK%207/Classification/#chossing-k","title":"Chossing k*","text":"<p>We know that we can treat \\(k\\) as an hyperparameter , because its not a part of  the algorithm but rather the input which goes into the algorithm.</p> <ul> <li>We also know that , smaller the \\(k\\) the more complicated the decision boundry is.</li> <li>To solve this , we choose different values of \\(k\\) and cross validate for them  respectively.</li> </ul> <p>Issues with KNN Algorithm</p> <ul> <li>Choosing distance function (to identify the closest \\(k\\) neighbours) might  become an issue.</li> <li>When predicting a new datapoint \\(x_\\text{test}\\) we measure the distance of  \\(x_\\text{test}\\) from all the datapoints and then identify the \\(k\\) nearest neighbours. Now if we want to predict the label for another datapoint , we have to repeat the whole  procedure again. This shows that we dont actually learn a \"model\" and our algorithm  solely relies on the datapoints. We cannot throw away the datapoints after learning a  \"model\" , because in the first place , there is no model for KNN. This is the biggest issue with KNN Algorithm.</li> </ul>"},{"location":"MLT/WEEK%207/Classification/#introduction-to-decision-trees","title":"Introduction to Decision Trees","text":"<p>The input for decision tree algorithm is the usual dataset  \\(\\{ (x_1,y_1) , (x_2,y_2) , ... (x_n,y_n) \\}\\) where for all \\(i\\) ,  \\(x_i \\in \\mathbb{R}^d\\) and \\(y \\in \\{ +1,-1 \\}\\).</p> <p>The output of this algorithm is a \"Decision Tree\".</p> <p>What is a Decision Tree?</p> <p>It is a tree-like structure where each internal node represents a  decision based on the value of a specific feature, each branch  represents the outcome of that decision, and each leaf node  represents the final predicted outcome or class label.</p> <p></p> <p>How do we get a prediction for a point?</p> <p>To get the prediction of a datapoint \\(x_\\text{test}\\) , we simply  traverese through the decision tree , asking questions until we  reach the leaf nodes. At the end we assign the value of the leaf node to \\(y_\\text{test}\\).</p> <p>The model here (which wasnt in there in KNN) is the decision tree , after training our dataset on the decision tree , we can get rid of  the dataset and predict new \"test points\" by solely relying on the  decision tree.</p> <p>Whats a question in a decision tree?</p> <p>In a decision tree , a question is a feature-value  pair.</p> <p>Where the \"feature\" is the feature in the datapoint and the \"value\" is the number with which we compare  the \"feature\".</p> <p>How to measure goodness of a question?</p> <p>For a dataset \\(D = \\{ (x_1 , y_1), (x_2 , y_2), ... (x_n , y_n) \\}\\) , for  a particular feature , we want to ask such a question that (ideally) it  matches each datapoint to its label , in other words our predicition  should be the same as the labels assigned to a datapoint in the dataset  \\(D\\).</p> <p>In reality , such questions may not exist , this means we have to somehow capture the notion of \"impurity\" for these questions.</p>"},{"location":"MLT/WEEK%207/Classification/#measure-of-impurity-for-a-set-of-datapoints","title":"Measure of impurity for a set of datapoints","text":"<p>For a dataset \\(D = \\{ (x_1 , y_1), (x_2 , y_2), ... (x_n , y_n) \\}\\) , an \"impurity\" function for a question can be given as </p> \\[\\begin{equation*} \\begin{split} \\text{Entropy}(y_1 , y_2 , ... y_n) &amp;= \\text{Entropy}(p) \\\\ &amp;= - (p \\log_2 p + (1-p) \\log_2 (1-p) ) \\;\\;\\;\\;\\;\\;\\;\\; [\\text{convention} \\;\\; \\log_2 0 = 0] \\end{split} \\end{equation*}\\] <p></p> <ul> <li>When \\(p=0\\) or \\(p=1\\) , it means that all of the datapoints  are classified to a single label.</li> <li>At \\(p=0.5\\) , entropy is the highest , hence its the worst case.</li> <li>Note that the entropy at \\(p\\) and \\(1-p\\) is always the same.</li> <li>By convention , \\(p = \\frac{\\text{Total Number of 1s}}{\\text{Total Number of DataPoints}}\\)</li> </ul> <p>We know that for a given question , we assign labels to datapoints  based on the question asked. A question always assigns datapoints to  2 labels , either a 1 or -1. We can measure the entropy of the dataset \\(D\\) and the points which belong to the assigned labels , but how do we combine these 3 values (entropy of D , entropy of points assigned to label 1 , entropy of points  assigned to label -1) into a singular value measure overall impurity?</p>"},{"location":"MLT/WEEK%207/Classification/#information-gain","title":"Information Gain","text":"<p>Information Gain for a feature,value pair is given as,</p> \\[\\begin{equation*} \\begin{split} \\text{Information Gain}(\\text{feature,value}) &amp;= \\text{Entropy}(D) - [\\gamma \\text{Entropy}(D_\\text{yes}) + (1- \\gamma)\\text{Entropy}(D_\\text{no})] \\\\ \\\\ \\text{where,}\\\\ \\\\ \\gamma &amp;= \\frac{|D_\\text{yes}|}{|D|} \\end{split} \\end{equation*}\\] <p>We use \\(\\gamma\\) to take into account the number of datapoints. A dataset \\(\\alpha\\) with 100 datapoints , from which 99 are classified as  label 1 and another dataset \\(\\beta\\) with 10000 datapoints , from which 9900 are classified as label 1 , will have the same entropy but the measure of information  gain will be higher for \\(\\beta\\) when compared to \\(\\alpha\\) , as the decision  tree trained on \\(\\beta\\) was able to classify more datapoints.</p>"},{"location":"MLT/WEEK%207/Classification/#decision-tree-algorithm","title":"Decision Tree Algorithm","text":"<ul> <li>Discretize each feature in the [min,max] range.</li> <li>Pick the question that has the highest information gain.</li> <li>Repeat the procedure for \\(D_\\text{yes}\\) and \\(D_\\text{no}\\).</li> </ul> <p>We can keep adding questions to the decision tree by using  the above procedure , but where do we stop?</p> <p>We stop adding new questions to the decision tree after we  reach a certain \"threshold of purity\" , this is generally  around 90% purity.</p>"},{"location":"MLT/WEEK%207/Classification/#example-of-decision-tree","title":"Example of Decision Tree","text":"<p>We classify the blue point on the right side as outlier when  we use cross validation method. If we were to keep adding more questions such that the outlier no longer  lies in an \"incorrect\" region , the purity of the decision tree may increase and so will the complexity.</p> <p>Our goal is to make small decision trees with a respectable measure of \"purity\".</p>"},{"location":"MLT/WEEK%207/Classification/#generative-and-discriminative-models","title":"Generative and Discriminative Models","text":"<p>In classical classification problems, two types of models are commonly employed: generative models and discriminative models.</p> <p>Generative models capture the joint distribution between features and labels and are represented as:</p> \\[P(x,y)\\] <p>These models focus on modeling the feature generation process.</p> <p>On the other hand, discriminative models directly model the conditional  probability of labels given the features and are represented as:</p> \\[P(y|x)\\] <p>Discriminative models generate labels solely based on the provided data.</p> <p>It is important to understand the differences between generative  and discriminative models when choosing an appropriate modeling approach for a given classification problem.</p>"},{"location":"MLT/WEEK%208/Models/","title":"Types of Models","text":""},{"location":"MLT/WEEK%208/Models/#generative-model-based-algorithm","title":"Generative Model-Based Algorithm","text":"<p>For a dataset \\(D= \\{ (x_1,y_1), (x_2,y_2), ... (x_n,y_n) \\}\\), let \\(x\\) and \\(y\\) both be binary features such that \\(x_i \\in \\{ 0,1 \\}^d\\) and \\(y_i \\in \\{ 0,1 \\}\\)</p> <p>Can features be binary? Does it even have an real life uses?</p> <p>The features can be binary and usually represent Yes/No type  question. One of the examples is of spam classification of mail  which we will be doing now.</p>"},{"location":"MLT/WEEK%208/Models/#spam-classifcication","title":"Spam Classifcication","text":"<p>For the spam classification of emails we will have to make \\(d\\)  length featuers for each email , even when the lengths and words  of emails are different.</p> <p>One of the ways we could do this is to make a very very long  vector/list which stores the poisition of each word in a  dictionary in ascending order.</p> <p>Example</p> <p>Lets say (for simplicity) our dictionary has 4 words, [\"Welcome\", \"to\" , \"earth\" , \"aliens\"]. Although, the  words arent ordered here, our feature vectors/lists will be  ordered.</p> <p>Now lets say that our mail has the following 2 words, \"Welcome Aliens\". We will encode it in such a way that each feature represents the poisition  and occurence of the word in dictionary.</p> <p>Feature vector of \\(d\\) length for \"Welcome Aliens\" will be, [1 , 0 , 0 , 1].</p> <p>To do Generative Modeling for our \\(d\\) length feature vectors, our next step would be assign probabilities to each word for  being in the spam and non-spam category.</p> <p>In other words each feature (\\(x\\)) has 2 possibilities of being  spam or non-spam (\\(y\\)). Our task at hand is to assign probabilities to all the features with all the possible combinations (2).</p> \\[P(x,y) = \\underbrace{P(x)}_{P (\\text{email})} \\times \\underbrace{ P(y|x)}_{ P( \\text{spam|email})} = \\underbrace{ P(y)}_{ P( \\text{spam})} \\times \\underbrace{ P(x|y)}_{ P( \\text{email|spam})}\\] <p>There are several advantages to writing \\(P(x,y)\\) in such a way, though we only care about at the end of the day is \\(P(y|x)\\) , that is , given a feature vector  what is probability it is spam or not spam.</p> <p>If we already know the structure of \\(P(y|x)\\) we can ignore the probability of \\(P(x)\\) ,  as it doesnt help us much with the predicition of a new test datapoint. So in some sense, we can just do a discriminative model for \\(P(y|x)\\) , instead of  modeling \\(P(y|x)\\) and \\(P(x)\\).</p> <p>In the second equation (\\(P(x|y) \\times P(y)\\)) , we arent assuming a specific  structure for \\(y\\) given \\(x\\) , instead we assume how labels are generated which  is \\(P(y)\\). Basically , we are assuming how to the structure/email will be given  that we know the email is spam or not spam.</p> <p>This is a more meaningful assumption as we have some way of understanding for how the email will look like given that it is spam or not spam. So now we will be modeling for \\(P(y)\\) and \\(P(x|y)\\).</p>"},{"location":"MLT/WEEK%208/Models/#generative-story-for-email-given-label","title":"Generative Story for Email Given Label","text":"<p>To make a generative model we will now make generative story  to train our model. Our generative story will have 2 steps,</p> <ul> <li>Step 1: Decide the label of the email by tossing a coin. \\(P(y_i = 1) = p\\)</li> <li> <p>Step 2: Decide the features of the email using the label in previous step.  \\(P(x_i | y_i)\\)</p> </li> <li> <p>In Step1 we are basically tossing a coin and if (lets say) comes out to be  heads , we say that this email is spam with some probability \\(P\\). The Step1  is deciding on which type of email (spam or non-spam) are we trying to generate.</p> </li> <li> <p>In Step2 we are basically generating the email itself for a set of words with  different probabilities (which sum upto 1) given we know which kind of email it is from Step1.</p> </li> </ul> <p></p> <p>We follow the Step1 and Step2 from our algorithm above, and generate an email of features with \\(d\\) length.</p> <p>Now lets say our dictionary only had \\(3\\) words, so the total number of possible feature vectors will be \\(2^{d=3} = 8\\), each  feature can take 2 values (0,1).</p> <p>For our spam category, the words like \"lottery\" , \"win\" will have a higher probability as features than the non-spam category.</p> <p>Note that the probability of each feature in a category represents  its chance of occurence within that specific category.</p> <p>Even if the feature vectors  on both the categories are the same ,  the sets of probabilities are different for both of them. Some of  the probabilities might even be zero for for some features in (lets say) spam category when compared to the non-spam category.</p> <p>Now if we want to learn a model from the above algorithm ,  we need to consider how many parameters are there for this coin  and 2 dice.</p> <ul> <li>The coin has probability \\(p\\) , so thats 1 of the parameters.</li> <li>The spam dice has \\(d\\) probabilities , each probability coressponding  to the combination of the features . Each feature has 2 possibilities (0,1), for \\(d\\) number of features we will have \\(2^d\\) parameters.  We know that all the probabilities sum upto 1 ,  which means we can always find out the \\(d^{\\text{th}}\\) probability  using \\(2^d-1\\) probabilities. Therefore at the end we are left with  \\(2^d -1\\) probabilities.</li> <li>The non-spam dice is the same as spam dice just the probabilities of the  features is different , hence we will also have \\(2^d-1\\) parameters for non-spam  dice.</li> </ul> <p>Our total number of parameters will be \\(1 + (2^d -1) + (2^d -1) = 2^{d+1} - 1\\).</p> <p>We can see that as we increase our number of features , the number of parameters  increase exponentially. This is simply too many parameters to handle/compute.</p> <p>If our dictionary had 10000 words , our parameters to compute would be  \\(2^10000\\) , to put that into perpective , this number is greater than the  number of atoms in the entire observable universe.</p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/","title":"Logistic Regression","text":""},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#introduction","title":"Introduction","text":"<p>Our goal in this week is to discover discriminative models which can be  used for classification.</p> <p>We want to create a discriminative model for \\(P(y=1|x)\\) and the simplest  model that one can think of is a linear classification model.</p> \\[\\begin{equation*} P(y=1|x) =  \\begin{cases} 1 &amp; \\text{for } w^Tx \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\end{equation*}\\] <p>In generative model we looked at how \\(x\\) was generated , but for a  discriminative model we only care about how \\(y|x\\) is generated.</p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#linear-separatability-assumption","title":"Linear Separatability Assumption","text":"<p>For our above linear model to be able to classify datapoints ,  the datapoints must have either label 1 or label -1.  This means there should be no  outliers in a dataset and all  the points should belong to either side of \\(w^Tx = 0\\) (Linear Separator).</p> <p> </p>  Here the data is linearly separable , there are no outliers in    this dataset. <p> </p> This dataset is not allowed because there are    outliers and hence the dataset is not linearly spearabale. <p>If the \"Not Allowed Dataset\" is given to us then our assumption would be that  the labeler used some \\(w\\) which correctly classified all the datapoints , but according to our current model such datasets are not possible. Hence we say that this dataset is not allowed under our model.</p> <p>When we make strong assumptions like linear separatability of the dataset, we hope to build fast and efficient algorithms, but do such algorithms really exist? The short answer is Yes.</p> <p>Our goal here was to get a discriminative model for classification which minimizes  the zero-one loss over a dataset.</p> \\[\\underset{h \\in \\mathcal{H}}{\\min} \\sum_{i=1}^n \\mathbb{1}( h(x_i) \\neq y_i )\\] <p>For a general dataset this is an NP-HARD problem even if \\(\\mathcal{H}\\) is considered  to be linear.</p> <p>Now if we get back to our \"Linear Separatability Assumption\" , then the loss for  our algorithm will be 0 (on the training dataset) as it will be able to correctly  classify all the datapoints because there are no outliers present.</p> \\[\\exists w \\in \\mathbb{R}^d \\text{  s.t.  } \\text{sign}(w^Tx) =y_i \\forall i \\in [n]\\] <p>There exists a \\(w\\) such that sign(\\(w^Tx\\)) = \\(y_i\\) (we make the correct prediction) for  all the \\(i\\) (datapoints) in \\([n]\\) (dataset)</p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#perceptron-algorithm","title":"Perceptron Algorithm","text":"<p>The Input for this algorithm is \\(\\{ (x_1,y_1) , (x_2,y_2) , ... (x_n,y_n) \\}\\) where  \\(x_i \\in \\mathbb{R}^d\\) and \\(y_i \\in \\{+1,-1 \\}\\).</p> <p>The algorithm is trying to find a \\(w\\) that correctly classifies all the datapoints, if such a \\(w\\) exists.</p> <p>This algorithm is an iterative algorithm and it starts with a \\(w^0\\) , where \\(0\\) indicates the iteration number and initially \\(w^0 = [0,0,0,...0]\\) i.e. \\(w^0\\) is a zero vector.</p> <p>Until Convergence</p> \\[\\begin{align} &amp; \\text{Pick } (x_i, y_i) \\text{ pair from the dataset}\\\\ &amp; \\text{If sign}(w^Tx_i) = y_i \\\\ \\\\ &amp; \\quad \\text{Do nothing} \\\\ \\\\ &amp; \\text{else}\\\\ \\\\ &amp; \\quad \\boxed{w^{t+1} = w^t + x_i y_i} \\\\ \\\\ &amp; \\text{end} \\\\ \\end{align}\\] <p>Basically , we check if our current \\(w\\) predicts the datapoint correctly , if it  doesnt predict the datapoint correctly then we multiply the datapoint with its label (+1 or -1) and add this product to our current \\(w\\) until convergence.</p> <p>Also note that the update rule here is the boxed equation,</p> \\[ \\boxed{w^{t+1} = w^t + x_i y_i} \\]"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#understanding-perceptron-update-rule","title":"Understanding Perceptron Update Rule","text":"<p>In our current perceptron algorithm , two types of mistakes can happen</p> <p>Mistake Type 1</p> <ul> <li>Predicted Label = +1 (sign \\((w^Tx_i) \\geq 0\\))</li> <li>Actual Label = -1 (\\(y_i\\) = -1)</li> </ul> <p>Mistake Type 2</p> <ul> <li>Predicted Label = -1 (sign \\((w^Tx_i) &lt; 0\\))</li> <li>Actual Label = +1 (\\(y_i\\) = +1)</li> </ul> <p>When we encounter a mistake , we either make a mistake in prediction  of Type 1 Category or Type 2 Category and then we update \\(w\\) accordingly. A general question to ask here would be , we have updated our \\(w\\) on some datapoint at \\(t^\\text{th}\\) iteration, but how does this \\(w^{t+1}\\)  (\\(w^t\\) after update) perform on the point where we made the mistake?</p> <p>We know that,</p> \\[\\begin{equation*} \\begin{split} w^{t+1} &amp;= w^t + x_i y_i \\\\ \\\\ \\text{Multiplying both sides by } x_i \\\\ \\\\ (w^{t+1})^T x_i &amp;= (w^t + x_i y_i)^T x_i \\\\ &amp;= w^{t^T} x_i + y_i ||x_i||^2 \\\\ \\end{split} \\end{equation*}\\] <p>Lets assume that a mistake of Type 1 occurs.</p> \\[ (w^{t+1})^T x_i = \\underbrace{w^{t^T} x_i}_{\\geq 0} + \\underbrace{\\underbrace{y_i}_{-1} \\underbrace{||x_i||^2}_{\\geq 0}}_{\\text{Negative}}\\] <p>Here \\(y_i = -1\\) represents the \"actual\" label of \\(x_i\\),</p> <ul> <li>\\(||x_i||^2\\) will always be positive because it is squared.</li> <li>The product of \\(y_i\\) and \\(||x_i||^2\\) will be less than zero (negative).</li> </ul> <p>Now what does all this mean?</p> <p>In a Type 1 Mistake , we predicted the label to be positive (+1) because our  \\(w^T x_i \\geq 0\\) , but it should have been negative (as the actual label is -1). We can see that the product of \\(y_i\\) and \\(||x_i||^2\\) will be negative and will  get subtracted from \\(w^{t^T} x_i\\) which will shift the \\(w\\) towards the negative  direction. </p> <p>This doesnt mean that \\(w\\) will immediately give a negative dot product just after this iteration (where we made the Type 1 Mistake) but it does moves/shifts  the \\(w\\) to the correct direction.</p> <p>Conclusion : Update rule pushes \\(w\\) in the right direction.</p> <p>The update of \\(w\\) we discussed fixes the prediction for the \"current\" datapoint, but does it affect the prediction of previous datapoints (which was predicted  correctly )? In on overall sense , does our current algorithm give use the best \\(w\\)?</p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#redifining-linear-separatability","title":"Redifining Linear Separatability","text":"<p>Case 1</p> <p></p> <p>Here we can see that updating \\(w\\) for a point \\(x\\) leads to misclassification of  some datapoints which were correctly classified before.</p> <p>Animation</p> <p> </p> <ul> <li>It can be seen that at the end when the new weight vector (yellow) is created , it misclassifies the circled points , which were correctly classified by the old weight vector (white).</li> </ul> <p>Case 2</p> <p></p> <p>Is this data linearly separable?</p> <p>At first glance this dataset might look linearly separable , but in according to  our current algorithm this dataset is not linearly separable.</p> <p>How? Why?</p> <p>One might say that \\(w\\) lying on x-axis (below diagram) separates the dataset.</p> <p></p> <p>Now lets see how the perceptron algorithm work on this dataset.</p> <p>Iteration 1</p> <p>Initially \\(w^0 = [0,0]\\) </p> <p>\\(\\large{\\substack{w^{0^T}x_1 = 0 \\\\ \\hat{y} = +1}, \\;\\; \\substack{w^{0^T}x_2 = 0 \\\\ \\hat{y} = +1}, \\;\\; \\boxed{\\substack{w^{0^T}x_3 = 0 \\\\ \\hat{y} = +1}}}\\)</p> <p>Iteration 2</p> <p>Our algorithm made a mistake in prediciton of the third (boxed) datapoint. Now we will update \\(w\\) as a mistake in prediciton occured,</p> <p>\\(w^1 = w^0 + x_3 y_3 = \\begin{bmatrix} 1 \\\\ -1/2 \\end{bmatrix}\\)</p> <p>After updating \\(w\\) we again run the algorithm,</p> <p>\\(\\large{\\boxed{\\substack{w^{1^T}x_1 = -0.5 \\\\ \\hat{y} = -1}}, \\;\\; \\substack{w^{1^T}x_2 = 0.5 \\\\ \\hat{y} = +1}, \\;\\; \\substack{w^{1^T}x_3 = -1.25 \\\\ \\hat{y} = -1}}\\)</p> <p>Iteration 3</p> <p>Our algorithm made a mistake in prediciton of the third (boxed) datapoint. Now we will update \\(w\\) as a mistake in prediciton occured,</p> <p>\\(w^2 = w^1 + x_1 y_1 = \\begin{bmatrix} 1 \\\\ 1/2 \\end{bmatrix}\\)</p> <p>\\(\\large{\\substack{w^{1^T}x_1 = 0.5 \\\\ \\hat{y} = +1}, \\;\\; \\boxed{\\substack{w^{1^T}x_2 = -0.5 \\\\ \\hat{y} = -1}}, \\;\\; \\substack{w^{1^T}x_3 = -0.75 \\\\ \\hat{y} = -1}}\\)</p> <p>Iteration 4</p> <p>Our algorithm made a mistake in prediciton of the second (boxed) datapoint. Now we will update \\(w\\) as a mistake in prediciton occured,</p> <p>\\(w^3 = w^0 + x_2 y_2 = \\begin{bmatrix} 1 \\\\ -1/2 \\end{bmatrix}\\)</p> <p>We can see that this \\(w^3\\) is the same as \\(w^1\\) , which means if we go ahead with this iteration we run into again predict the second datapoint wrong and hence the loop will keep on running without stopping. At the end , our perceptron  algorithm will never give us a \\(w\\) which classifies all the points correctly  and the algorithm will never converge.</p> <p>In such an edge case , there exists no \\(w\\) which will correctly classify all  the datapoints , even though , at first the dataset may look linearly separable</p> <p>Animation</p> <p> </p> <ul> <li>In each iteration the incorrectly predicted point is highlighted  in yellow color.</li> <li>Points on the right side of the Decision Boundry are predicted as +1 (positive), while points on the left side are predicted as -1 (negative)</li> <li>Even after several iterations it can be seen that the weight vector keeps going back and forth between <code>w=[1,0.5]</code> and <code>w=[1,-0.5]</code>.</li> <li>Hence we can see that the algorithm will never converge.</li> </ul> <p>Why does this happen?</p> <p>One of the reasons is , the given dataset is not strictly linearly separable  as some of the datapoints lie on the decision boundry itself and we chose to  label such datapoints as +1 , though they can also be labeled as -1.</p> <p>What to do to solve this issue?</p> <p>We can apply more stricter \"assumptions\" on our dataset to account for the  edge case described above.</p> <p></p> <p>A dataset is linearly separable with \\(\\gamma\\) margin if,</p> <p>\\(\\exists w^* \\in \\mathbb{R}^d \\quad \\text{s.t. } \\quad (w^{*^T}x_i)y_i \\geq \\gamma \\forall i \\quad \\text{for some } \\gamma &gt; 0\\)</p> <p>(There exists a \\(w^*\\) such that \\((w^{*^T}x_i) y_i \\geq \\gamma\\) for all the datapoints where \\(\\gamma &gt; 0\\))</p> <p>This assumption makes it so that there are no datapoints between the parallel  dotted lines , in other words , this also means that no points will lie on  \\(w^T x = 0\\)</p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#proof-of-convergence-of-perceptron-algorithm","title":"Proof of Convergence of Perceptron Algorithm","text":"<p>To prove the convergence of the algorithm we are going to make a few  assumptions about the dataset</p> <ol> <li>Linear Separatability with \\(\\gamma\\) margin.</li> <li> <p>Radius Assumption </p> <ul> <li>\\(\\forall i \\in D \\quad ||x_i||_2 \\leq R \\quad \\text{for some } R &gt; 0\\)</li> <li>This basically means that all the points in dataset \\(D\\) fall within a  circle of radius \\(R\\).</li> </ul> </li> <li> <p>Without loss of generality , assume \\(||w^*|| = 1\\)</p> <ul> <li>This basically means that we have normalized our \\(w\\) get \\(w^*\\).</li> </ul> </li> </ol> <p>We will now try to quantify the number of mistakes our aglorithm can make , if the number of mistakes is finite then it means the number of iterations  is also finite , therefore , our algorithm must converge.  </p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#analysis-of-mistakes-of-perceptron-algorithm","title":"Analysis of 'Mistakes' of Perceptron Algorithm","text":"<ul> <li> <p>Observe that an update in perceptron algorithm only happens when a  mistake occurs.</p> </li> <li> <p>Say \\(w^l\\) is the current guess and a mistake happens w.r.t (x,y).</p> </li> </ul>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#bound-1","title":"Bound 1","text":"<p>Now we will take look at what happens to the length of \\(w\\) after an update</p> \\[\\begin{equation*} \\begin{split} w^l &amp;= w^{l-1} + xy \\\\ ||w^l||^2 &amp;= ||w^{l-1} + xy||^2 \\\\ &amp;= (w^{l-1} + xy)^T (w^{l-1} + xy) \\\\  &amp;= \\underbrace{||w^{l-1}||^2}_{\\geq 0} + \\underbrace{2(w^{{l-1}^T} x)y}_{\\leq 0} + \\underbrace{||x||^2 \\underbrace{y^2}_{\\pm1}}_{\\leq R^2} \\\\ \\\\ \\therefore ||w^l||^2 &amp;\\leq ||w^{l-1}||^2 + R^2 \\\\ &amp;\\leq (||w^{l-2}||^2 +R^2 ) + R^2 \\\\  &amp;\\vdots \\\\ &amp;\\leq ||w^0||^2 + l R^2 \\\\ \\\\ \\boxed{\\therefore ||w^l||^2 \\leq l R^2} \\\\  \\end{split} \\end{equation*}\\] <p>Note</p> <ul> <li>The reason why \\(y^2\\) is always greater than zero because it is this label of  of the datapoints and can only take value of either +1 or -1.</li> <li>||w||^2 will also be always greater than or equal to zero as square of any real number is always a positive number (\\(w\\) is just a vector comprising of real numbers)</li> <li>Product of \\(||x||^2\\) and \\(y^2\\) will always be less than or equal to \\(R^2\\) because as per our assumption , all the points lie within a circl of radius \\(R\\).</li> <li>\\(2(w^{{l-1}^T} x) y\\) will always be less than one because an update only happens  when a mistake occurs,<ul> <li>If actual label is +1 and predicted label is -1 , this implies \\(w^T x &lt; 0\\) i.e. its a negative value and the (actual) label is a positive value , product of  negative and positive values is always negative.</li> <li>Similarly , if actual label is -1 and predicted label is +1, this implies \\(w^T x \\geq 0\\)  i.e its a positive value and the (actual) label is a negative value , product of  positive and negative values is always negative.</li> </ul> </li> </ul>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#bound-2","title":"Bound 2","text":"<p>We will now use \\(w^*\\) (the best \\(w\\) which exists) to obtain another bound for  number of mistakes.</p> \\[\\begin{equation*} \\begin{split} w^l &amp;= w^{l-1} + x y \\\\  (w^l)^T w^* &amp;= (w^{l-1} + xy)^T w^* \\\\ &amp;= w^{{l-1}^T} w^* + \\underbrace{(w^{*^T} x)y}_{\\geq \\gamma} \\\\  \\\\ \\therefore (w^l)^T w^* &amp;\\geq (w^{l-1})^T w^* + \\gamma \\\\ &amp; \\geq (w^{{l-2}^T} w^* + \\gamma) + \\gamma \\\\ &amp; \\vdots \\\\ &amp; \\geq \\underbrace{(w^0)^T w^*}_{0} + l \\gamma \\\\  \\\\ \\therefore (w^l)^T w^* &amp;\\geq l \\gamma \\\\ \\\\ ((w^l)^T w^*)^2 &amp;\\geq l^2 \\gamma^2 \\\\ \\\\  ||w^l||^2 \\underbrace{||w^*||^2}_{1} &amp;\\geq l^2 \\gamma^2 \\text{ Using Cauchy-Schwarz Inequality }  \\\\ \\boxed {\\therefore ||w^l||^2 \\geq l^2 \\gamma^2} \\end{split} \\end{equation*}\\] <p>Cauchy-Schwarz Inequaltiy</p> <p>We know that,</p> \\[ -1 \\leq \\cos(\\theta) \\leq 1 \\] <p>Multiplying the product of norm of some vectors \\(v\\) and \\(w\\) in the above equation,</p> \\[\\begin{equation*} \\begin{split} -||v|| \\times ||w|| \\leq ||v|| &amp;\\times ||w|| \\cos(\\theta) \\leq ||v|| \\times ||w|| \\\\ -||v|| \\times ||w|| \\leq v &amp;\\cdot w  \\leq ||v|| \\times ||w|| \\\\ |v \\cdot w| &amp;\\leq ||v|| \\times ||w|| \\end{split} \\end{equation*}\\] <p>Note : Dot product of any 2 vectors is given by \\(x \\cdot y = ||x|| \\times ||y|| \\cos(\\theta)\\)</p> <p>Note</p> <ul> <li>In the above assumptions we said that norm of \\(w^*\\) is 1.</li> </ul>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#radius-margin-bound","title":"Radius Margin Bound","text":"<p>Now that we have both upper and lower bound of \\(||w^l||\\),</p> \\[\\begin{equation*} \\begin{split} l^2 \\gamma^2 &amp;\\leq ||w^l||^2 \\leq l R^2 \\\\ l^2 \\gamma^2 &amp;\\leq l R^2 \\\\ \\therefore l &amp;\\leq \\frac{R^2}{\\gamma^2}\\\\ \\end{split} \\end{equation*}\\] <p>Conclusion: A dataset which follows all the assumptions above , its mistakes  are always less than or equal to Radius in which all the datapoints lie divided by  the margin gamma with respect to the optimal \\(w^*\\).</p> <p>As the number of mistakes now can be quantified , we can say that this perceptron  algorithm will converge.</p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#sigmoid-function-for-modeling-class-probabilities","title":"Sigmoid Function for Modeling Class Probabilities","text":"<p>We know that Perceptron Algorithm makes a linear separatability assumption ,  if we were to write that in probabilistic manner , then one way to do that  would be,</p> \\[\\begin{equation*} P(y=1|x) = \\begin{cases} 1 &amp; \\text{if } w^T x \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\end{equation*}\\] <p>As the probabilities of the are 1 and 0 for a given datapoint , the perceptron  algorithm only works on linearly separable datasets. </p> <p>If the dataset has points which are not linearly separable but appear to be outliers, our perceptron algorithm is unable to run on such a dataset.</p> <p>Can we somehow relax the probabilities for a given datapoint?  So that the perceptron algorithm also works on datasets which are not linearly  separable.</p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#simple-linear-probabilistic-model","title":"Simple Linear Probabilistic Model","text":"<p>We will now start building up to a reasonable algorithm which has realaxed probabilities. We will start with a simple linear model where the score (\\(z\\)) of a datapoint is  given by \\(z = w^T x\\). </p> <p></p> <p>We are going to allow any point to be labeled as +1 or -1 , but the deciding factor for which label will +1 or -1 will be based on the score (\\(z\\)) of the datapoint. The higher the score of a label is , the higher will be its probability of being  labeled as +1 , similarly the lower the score of the datapoint is , the higher will be its probability of being labeled as -1.</p> <p>An intuitive way to think about this would be that , \\(x_2\\) is farther away from the decision boundry/linear separator , hence we're more confident that \\(x_2\\) should be  labeled as +1 when compared to \\(x_1\\) which is much much closer to the decision boundry.</p> <p>Example</p> <p>In the above diagram , </p> <ul> <li> <p>\\(x_1\\) will have a lower score when compared to \\(x_2\\) (\\(w^T x_1 &lt; w^T x_2\\)), this means that probability of \\(x_1\\) being labeled as +1 is lower than  probability of \\(x_2\\) being labeled as +1 (\\(P(y = 1 | x_1) &lt; P(y = 1 | x_2)\\)).</p> </li> <li> <p>Similarly , \\(x_4\\) is farther away than \\(x_3\\) , which means that \\(x_4\\) has  higher probability of being labeled as -1 when compared to \\(x_3\\)  ( \\(P(y = -1 | x_3) &lt; P(y = -1 | x_4)\\)).</p> </li> </ul> <p>According to this simple linear model , every point has the probability to be  labeled as +1 or -1 , just the chance that it gets labeled (+1 or -1) depends on how far it is form the decision boundry. </p> <p>Problems With Current Linear Model</p> <p>We can calculate the score for any datapoint given a \\(w\\) but we dont have  function/method to convert this score to a probability.</p> <p>To convert the score to a probability will use the Sigmoid Function.</p> <p></p> <p>This function goes from \\(0 \\to 1\\) over the domain of \\((-\\infty , \\infty)\\) and  is given by \\(g(z) = \\frac{1}{1 + e^{-z}}\\). Here , \\(z = w^T x\\).</p> <p>Hence, with sigmoid function we define probabilities of a datapoint being  labeled as +1 or -1 which means datasets which were previously not allowed are now allowed for our  Probabilistic Perceptron Algorithm.</p>"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#logistic-regression_1","title":"Logistic Regression","text":"<p>We have developed Probabilistic Perceptron Algorithm , which labels datapoints  on certain score (z) , but the problem with our current approach is that there may  exist many \\(w\\) which correctly classify the datapoints. We dont have any method to  identify the best \\(w\\) among all the \\(w\\)'s which classify the datapoints.</p> <p></p> <p>Here \\(w_1\\) and \\(w_2\\) both will be able to classify the datapoints , but which amongst them is a better \\(w\\)?</p> <p>This seems to be problem of maximum liklihood which can be solved using using the traditional method of derivative of log-likelihood.</p> <p>For a dataset \\(D = \\{(x_1 , y_1) , (x_2 , y_2) , ... (x_n , y_n) \\}\\), where \\(x_i \\in \\mathbb{R}^d\\) and \\(y_i \\in \\{-1 , 1 \\}\\)</p> <p>We know that,</p> \\[ P(y=1|x) = g(w^T x_i) = \\frac{1}{1 + e^{- w^T x}} \\] <p>The maximum likelihood expression will be,</p> \\[\\begin{equation*} \\begin{split} \\mathcal{L}(w;D) &amp;= \\prod_{i=1}^n (g(w^T x_i))^{y_i} (1 - g(w^T x_i))^{1 - y_i} \\\\  \\log( \\mathcal{L}(w;D) ) &amp;= \\sum_{i=1}^{n} y_i \\log(g(w^T x_i)) + (1 - y_i) \\log(1 - g(w^T x_i)) \\\\ &amp;= \\sum_{i=1}^{n} y_i \\log (\\frac{1}{1 + e^{-w^T x_i}}) + (1 - y_i) \\log (\\frac{e^{-w^T x_i}}{1 + w^{-w^T x_i}}) \\\\ &amp;= \\sum_{i=1}^{n} [(1 - y_i)(-w^T x_i) -log(1 + e^{-w^T x_i})] \\\\ \\end{split} \\end{equation*}\\] Note <ul> <li>Our assumption here is the probabilities are generated independent of other labels.</li> <li>The above Maximum Likelihood is very similar to Maximal Likelihood of a bernoulli  random variable.</li> </ul> <p>Our goal now is maximize the above equation with respect to \\(w\\) , so that we get the  best possible \\(w\\),</p> \\[ \\underset{w}{\\max} \\sum_{i=1}^{n} [(1 - y_i)(- w^T x_i) - \\log(1 + e^{- w^T x_i})] \\] <p>However , the above equation doesnt have a closed-form solution when a derivative is taken to solve further. Therefore, we will use gradient descent to identify the best \\(w\\).</p> <p>The gradient descent of the above log-likelihood function will be,</p> \\[\\begin{equation*} \\begin{split} \\nabla \\log (\\mathcal{L}(w;D)) &amp;= \\sum_{i=1}^{n} \\left[(1 - y_i)(-x_i) - \\frac{e^{-w^T x_i}}{1 + e^{-w^Tx)i}} (-x_i)  \\right] \\\\ &amp;= \\sum_{i=1}^{n} \\left[ -x_i + x_i y_i + x_i \\left( \\frac{e^{-w^T x_i}}{1 + e^{-w^Tx_i}} \\right)  \\right] \\\\ &amp;= \\sum_{i=1}^{n} \\left[ x_iy_i - x_i \\left( \\frac{1}{1 + e^{-w^T x_i}} \\right) \\right] \\\\ \\nabla \\log(\\mathcal{L}(w;D)) &amp;= \\sum_{i=1}^{n} \\left[ x_i \\left(y_i - \\frac{1}{1 + e^{-w^T x_i}}  \\right)  \\right] \\end{split} \\end{equation*}\\] <p>Using the Gradient Descent formula we get,</p> \\[\\begin{equation*} \\begin{split} w_{t+1} &amp;= w_t + \\mathcal{n}_t \\nabla \\log ( \\mathcal{L}(w;D))\\\\ &amp;= w_t + \\mathcal{n}_t \\left( \\sum_{i=1}^n x_i \\left(\\overbrace{y_i - \\underbrace{\\frac{1}{1 + e^{-w^Tx_i}}}_{g(w^T x_i)}}^{\\theta_i}  \\right)  \\right) \\end{split} \\end{equation*}\\] <p>Note</p> <ul> <li>The term after \\(y_i\\) is the Sigmoid Function which outputs a probability for a certain  score of a datapoint.</li> <li>Lets say for a point the actual label is +1 and it is predicted correctly as +1 (\\(y_i = 1\\)) , this  means that the point has a higher probability (lets say \\(g(w^Tx_i) = 0.9\\)) when compared to the other  binary label, which was derived from the sigmoid function. This also means that \\(\\theta_i\\) will be a small value as \\(1 - 0.9 = 0.1\\). This also means that  this particular datapoint will not have much effect on the direction of the gradient descent algorithm.</li> <li>Prediction of a datapoint \\(x_\\text{test}\\) is given by ,</li> </ul> \\[ y_\\text{test} = \\text{sign}( \\hat{w}^T x_\\text{test} ) \\]"},{"location":"MLT/WEEK%209/Perceptron%20Learning%20Algorithm/#advantages-of-logistic-regression","title":"Advantages of Logistic Regression","text":"<ul> <li> <p>There is a kernel version for the above equation as it can be argued that  \\(w = \\sum_{i=1}^n \\alpha_i x_i\\)</p> </li> <li> <p>Regularized Version for the above equation is ,</p> </li> </ul> \\[\\underset{w}{\\min} \\sum_{i=1}^n \\left[ \\log(1 + e^{-w^T x_i}) + w^T x_i (1-y_i) \\right] + \\underbrace{\\frac{\\lambda}{2} ||w||^2}_{\\text{Regularizer}} \\] <p>Here \\(\\lambda\\) is Cross Validated Hyperparameter.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/","title":"Shell Variables","text":""},{"location":"SC/WEEK%202/Shell%20Variables/#shell-variables-part-1","title":"Shell Variables (Part 1)","text":""},{"location":"SC/WEEK%202/Shell%20Variables/#creating-shell-variables","title":"Creating Shell Variables","text":""},{"location":"SC/WEEK%202/Shell%20Variables/#exporting-shell-variables","title":"Exporting Shell Variables","text":"<p>Exporting a variable makes it available to the parent shell as well  as the children shell.</p> <p>If a variable is set in the parent shell then it wont be accessible in the child shell. To make the value of the variable available in the child shell , exporting is used.</p> <p>Note</p> <p>Any changes made in the child shell to an exported variable (from parent shell) will not be reflected in the parent shell.</p> <p><pre><code>export myvar=\"value string\"\n</code></pre> or </p> <pre><code>myvar=\"value string\"\nexport myvar\n</code></pre>"},{"location":"SC/WEEK%202/Shell%20Variables/#using-variable-values","title":"Using Variable Values","text":"<p>The value of the variable is displayed using the <code>echo</code> command.</p> <p><pre><code>echo $myvar \necho ${myvar}\necho \"${myvar}_something\"\n</code></pre> Using curly braces helps in manipulating the value of the variable  for the desired output.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#removing-a-variable","title":"Removing a variable","text":"<pre><code>unset myvar\n</code></pre> <p>The value of the variable can also be removed by doing <pre><code>myvar=\n</code></pre></p> <p>Note : There is nothing after the <code>=</code> sign in the above command.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#testing-if-a-variable-is-set","title":"Testing if a variable is set","text":"<p><pre><code>[[ -v myvar ]];\necho $?\n</code></pre> Return Codes 0 : success (variable is set) 1 : failure (variable is not set)</p> <p>Note</p> <p><code>echo $?</code> returns the exit code of the last executed command. A status code of 0 means that the command was executed successfully and a stuatus code of non-zero value means that the command resulted in  an error or failed to execute.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#testing-if-a-variable-is-not-set","title":"Testing if a variable is not set","text":"<pre><code>[[ -z ${myvar+x} ]];\necho $?\n</code></pre> <p>Here <code>x</code> can be any string.</p> <p>Return Codes 0 : success (variable is not set) 1 : failure (variable is set)</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#substitue-default-value","title":"Substitue default value","text":"<p>If the variable is not set, display \"bananas\"  as its default value</p> <pre><code>echo ${myvar:-\"bananas\"}\n</code></pre> <p>If the variable is not set, change its  value to \"bananas\" and display its value as \"bananas\".</p> <pre><code>echo ${myvar:=\"bananas\"}\n</code></pre>"},{"location":"SC/WEEK%202/Shell%20Variables/#reset-value-if-variable-is-set","title":"Reset value if variable is set","text":"<p>If the variable <code>myvar</code> is set, then set \"wutermellon\" as its value</p> <pre><code>echo ${myvar:+\"wutermellon\"}\n</code></pre>"},{"location":"SC/WEEK%202/Shell%20Variables/#list-of-variable-names","title":"List of variable names","text":"<p><pre><code>echo ${!H*}\n</code></pre> This will give a list of shell variables that start with <code>H</code>.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#length-of-string-value-of-variable","title":"Length of (string) value of variable","text":"<pre><code>echo ${#myvar}\n</code></pre> <p>If <code>myvar</code> is not set then it displays <code>0</code>.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#slice-of-string-value-of-variable","title":"Slice of (string) value of variable","text":"<pre><code>echo ${myvar:5:4}\n</code></pre> <p>This will display 4 characters of the value and  will also skip the first 5 characters of the value. Here <code>5</code> is the offset and <code>4</code> is the slice length.</p> <p>The offset can also be negative. All the characters to the left of the index -2 are ignored.</p> <pre><code>echo ${myvar: -2:9}\n</code></pre>"},{"location":"SC/WEEK%202/Shell%20Variables/#remove-matching-pattern","title":"Remove matching pattern","text":"<pre><code>echo ${myvar#pattern}\n</code></pre> <p>This will only remove the matched pattern once.</p> <pre><code>echo ${myvar##pattern}\n</code></pre> <p>This will match the pattern maximum number of times  and remove them.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#keep-matching-pattern","title":"Keep matching pattern","text":"<pre><code>echo ${myvar%pattern}\n</code></pre> <p>This will display the matched pattern only once.</p> <pre><code>echo ${myvar%%pattern}\n</code></pre> <p>This will display the matched pattern maximum  number of times.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#replace-matching-pattern","title":"Replace matching pattern","text":"<pre><code>echo ${myvar/pattern/string}\n</code></pre> <p>This will match once and replace it with the string.</p> <pre><code>echo ${myvar//pattern/string}\n</code></pre> <p>This will match maximum number of times with the pattern  and replace it with the string.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#replace-matching-pattern-by-location","title":"Replace matching pattern by location","text":"<p><pre><code>echo ${myvar/#pattern/string}\n</code></pre> This will match the pattern at beginning of the value and replace it with the string.</p> <pre><code>echo ${myvar/%pattern/string}\n</code></pre> <p>This will match the pattern at the end of the value and  replace it with the string</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#changing-case","title":"Changing Case","text":""},{"location":"SC/WEEK%202/Shell%20Variables/#changing-to-lowercase","title":"Changing to Lowercase","text":"<p><pre><code>echo ${myvar,}\n</code></pre> This will change the first character to lowercase</p> <pre><code>echo ${myvar,,}\n</code></pre> <p>This will change all the characters to lowercase.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#changing-to-uppercase","title":"Changing to Uppercase","text":"<pre><code>echo ${myvar^}\n</code></pre> <p>This will change the first character to uppercase.</p> <pre><code>echo ${myvar^^}\n</code></pre> <p>This will chane all the characters to uppercase.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#restricting-value-types-of-a-variable","title":"Restricting value types of a variable","text":"<p><pre><code>declare -i myvar\n</code></pre> This will make it so that only integers can be assigned to  <code>myvar</code>.</p> <p><pre><code>declare -l myvar\n</code></pre> This will make it so that only lowercase characters can be assigned to <code>myvar</code>.</p> <p><pre><code>declare -u myvar\n</code></pre> This will make it so that only uppercase characters can be assigned to <code>myvar</code>.</p> <pre><code>declare -r myvar\n</code></pre> <p>This will make it so that the variable is read only.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#removing-restrictions-on-types-of-a-variable","title":"Removing restrictions on types of a variable","text":"<p><pre><code>declare +i myvar\n</code></pre> <pre><code>declare +l myvar\n</code></pre> <pre><code>declare +u myvar\n</code></pre> This will remove the restrictions on <code>myvar</code>. In the case of read-only restriction , removing it is  not possible.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#indexed-arrays","title":"Indexed Arrays","text":"<p>The index of arrays in bash need not be in succession.</p>"},{"location":"SC/WEEK%202/Shell%20Variables/#associative-arrays","title":"Associative Arrays","text":""},{"location":"STATS2/Books%20%2B%20Link/LINKS/","title":"Links for Topics","text":"<ul> <li>Multiple Discrete Random Variables -  https://www.youtube.com/watch?v=CqYuEwwNUu8</li> <li>Multiple Random Variables: Discrete and Continuous- https://www.youtube.com/watch?v=XhXhI_NaoCc</li> <li>Multiple random variables  https://www.youtube.com/watch?v=1U537aiXJzM</li> <li>Multiple random variables with densities - https://www.youtube.com/watch?v=AR3SoXCvw8I</li> <li>Discrete random variables - part 1/5 (continuous vs discrete) - https://www.youtube.com/watch?v=ajLFqrPTAcY</li> </ul> <p>part 2: https://youtu.be/FrL4Dcoy9MI part 3: https://youtu.be/NXUkzZhrrcA part 4: https://youtu.be/cnJjKX5AHi4 part 5: https://youtu.be/NTWD-EyTkR0</p>"},{"location":"STATS2/WEEK%201/aq_solutions/","title":"Assignment Question Solutions","text":"<p>Warning</p> <ul> <li>Please try to solve the questions on your own first.</li> <li>Thinking that \"I have seen the solutions , I understand everything\" is WRONG. You actually don't understand anything unless you solve questions.</li> <li>For detailed explanations look for posts on discourse or scroll through live lectures.</li> </ul>"},{"location":"STATS2/WEEK%201/aq_solutions/#aq-11","title":"AQ 1.1","text":""},{"location":"STATS2/WEEK%201/aq_solutions/#aq12","title":"AQ1.2","text":""},{"location":"STATS2/WEEK%201/aq_solutions/#aq13","title":"AQ1.3","text":""},{"location":"STATS2/WEEK%201/aq_solutions/#aq14","title":"AQ1.4","text":""},{"location":"STATS2/WEEK%201/aq_solutions/#aq15","title":"AQ1.5","text":""},{"location":"STATS2/WEEK%201/aq_solutions/#aq16","title":"AQ1.6","text":""},{"location":"STATS2/WEEK%201/aq_solutions/#aq17","title":"AQ1.7","text":""},{"location":"STATS2/WEEK%201/Notes/Two%20Discrete%20Random%20Variables/","title":"Discrete Random Variables","text":"<p>Discrete random variables are variables that can take on a countable number of distinct values.  These values are typically integers or whole numbers and are often the result of counting or enumerating something. </p> <p>Example</p> <ul> <li>Coin Toss : Consider a random variable \\(X\\) which represents the number of heads when a coin is tossed \\(2\\) times. We can see that \\(X\\) can only take the values \\(0 , 1 , 2\\). Here \\(X\\) is a discrete random variable.</li> <li>Russian Roulette : Consider a random variable \\(Y\\). \\(Y = 0\\) when a bullet is not fired and \\(Y=1\\) when  a bullet is fired. \\(Y\\) takes the values of \\(0,1\\). Here \\(Y\\) is a discrete random variable.</li> <li>Dice Roll : Consider a random variable \\(Z\\). \\(Z\\) can only take values \\(0,1,2,3,4,5,6\\) and each of these  values has a corresponding probability. Here \\(Z\\) is a discrete random variable.</li> </ul>"},{"location":"STATS2/WEEK%201/Notes/Two%20Discrete%20Random%20Variables/#takeaways-from-this-week","title":"Takeaways from this Week","text":"<ul> <li>You should be able to understand how the joint distribution tables work.</li> <li>Marginal PMF and Conditional Distribution are the most important concept in this week and will be used in the future.</li> </ul>"},{"location":"STATS2/WEEK%201/Notes/Two%20Discrete%20Random%20Variables/#joint-pmf","title":"Joint PMF","text":"<p>A joint PMF (Probability Mass Function) distribution refers to the probability distribution of two or  more random variables occurring together. It gives the probabilities for all possible combinations of values of these variables.</p> <p>Suppose \\(X\\) and \\(Y\\) are discrete random variables defined in the same probability space. Let the range of \\(X\\) and \\(Y\\) be \\(T_X\\) and \\(T_Y\\) , respectively . The joint PMF of \\(X\\) and \\(Y\\) , denoted by \\(f_{XY}\\) , is a function from \\(T_X \\times T_Y\\) to [0,1] defined as</p> \\[f_{XY} = P(X = t_1 \\ and \\ Y=t_2) , t_1 \\in T_X , t_2 \\in T_Y\\] <p>It is usually written in a table or a matrix.</p> <p>Example</p> <p>Coin Toss</p> <p>Let \\(X_i = 1\\) if \\(i^{th}\\) toss is heads and \\(X_i = 0\\) if toss is tales.</p> \\(t_2\\) \\ \\(t_1\\) 0 1 0 1/4 1/4 1 1/4 1/4 <p>Then , \\(f_{XY}(0,0) = P(X_1=0,X_2=0) = \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4}\\) </p> <p>Picking Marbles</p> <p>Consider a bag containing three red marbles (R) and two blue marbles (B).  We randomly select two marbles from the bag without replacement and observe their colors.</p> <p>Joint PMF Distribution would provide all the possibilites of picking 2 marbles from the bag.</p> Marble 1 Marble 2 Probability (P) R R 3/10 R B 3/10 B R 3/10 B B 1/10 <p>Let \\(X,Y\\) represent the color of first and second marbles respectively. Then,</p> <ul> <li>\\(f_{XY}(R,R) = \\frac{3}{5} \\times \\frac{2}{4} = \\frac{3}{10}\\) (Both marbles are red)</li> <li>\\(f_{XY}(R,B) = \\frac{3}{5} \\times \\frac{2}{4} = \\frac{3}{10}\\) (\\(X\\) is red and \\(Y\\) is blue)</li> </ul> <p>Info</p> <p>The sum of all the Joint PMFs will always be 1</p>"},{"location":"STATS2/WEEK%201/Notes/Two%20Discrete%20Random%20Variables/#marginal-pmf-probability-mass-function","title":"Marginal PMF (Probability Mass Function)","text":"<p>The marginal PMF (Probability Mass Function) refers to the probabilities of a single random variable,  independently of the other variables in a joint probability distribution.</p> <p>Suppose \\(X\\) and \\(Y\\) are jointly distributed discrete random variables with joint PMF \\(f_{XY}\\). The PMF of the individual random variables \\(X\\) and \\(Y\\) are called as marginal PMFs. It can be shown that</p> \\[f_X(t)=P(X=t)=\\sum_{t'\\in T_Y} f_{XY}(t,t')\\] \\[f_Y(t)=P(Y=t)=\\sum_{t'\\in T_X} f_{XY}(t,t')\\] <p>where \\(T_X\\) and \\(T_Y\\) are the ranges of \\(X\\) and \\(Y\\) , respectively.</p> <p>Example</p> \\(t_2\\) \\ \\(t_1\\) 0 1 \\(f_{x_{2}}(t_2)\\) 0 1/4 1/4 1/2 1 1/4 1/4 1/2 \\(f_{x_{1}}(t_1)\\) 1/2 1/2 <ul> <li>Adding along the rows and adding along the columns gives us the Marginal PMF.</li> <li> <p>In our case the marignal PMF of \\(X_1\\) will be</p> <ul> <li>\\(f_{X_1}(0) = f_{X_{1}X_2}(0,0) + f_{X_{1}X_2}(0,1) = \\frac{1}{4} + \\frac{1}{4}\\)</li> <li>\\(f_{X_1}(1) = f_{X_{1}X_2}(1,0) + f_{X_{1}X_2}(1,1) = \\frac{1}{4} + \\frac{1}{4}\\)</li> </ul> </li> </ul>"},{"location":"STATS2/WEEK%201/Notes/Two%20Discrete%20Random%20Variables/#conditional-distribution-of-one-random-variable-given-another","title":"Conditional distribution of one random variable given another","text":"<p>Conditional distribution refers to the probability distribution of one random variable given the knowledge  or condition of another random variable. It provides the probabilities for the values of one variable,  taking into account specific conditions or values of another variable.</p> <p>In simpler terms, it allows us to understand how the distribution of one variable changes  or is affected when we consider a specific condition or value of another variable.</p> <p>Suppose \\(X\\) and \\(Y\\) are jointly distributed discrete random variables with joint PMF \\(f_{XY}\\). The conditional PMF of \\(Y\\) given \\(X=t\\) is defined as the PMF:</p> \\[Q(t')=P(Y=t'|X=t)=\\frac{P(Y=t' , X=t)}{P(X=t)} = \\frac{f_{XY}}{f_{X}(t)}\\] <p>Example</p> \\(t_2\\) \\ \\(t_1\\) 0 1 2 \\(f_Y(t_2)\\) 0 1/4 1/8 1/8 1/2 1 1/8 1/8 1/4 1/2 \\(f_X(t_1)\\) 3/8 1/4 3/8 <p>Where , \\(X \\in \\{0,1,2\\}\\) , \\(Y \\in \\{0,1\\}\\) and \\((Y|X=0) \\in \\{0,1\\}\\)</p> <ul> <li>\\(f_{Y|X = 0}(0) = \\frac{f_{XY}(0,0)}{f_X(0)} = \\frac{1/4}{3/8} = \\frac{2}{3}\\)</li> <li>\\(f_{Y|X = 0}(1) = \\frac{f_{XY}(0,1)}{f_X(0)} = \\frac{1/8}{3/8} = \\frac{1}{3}\\)</li> </ul>"},{"location":"STATS2/WEEK%201/Notes/Two%20Discrete%20Random%20Variables/#factoring","title":"Factoring","text":"<p>Factoring is used to convert Joint Probabilities into a product of  Condtional and Marginal Probabilities.</p> \\[\\begin{equation*} \\begin{split} P(Y=t'|X=t)&amp;=\\frac{P(Y=t' , X=t)}{P(X=t)} \\\\ \\text{Conditional} &amp;= \\frac{\\text{Joint}}{\\text{Marginal}} \\\\ \\\\ \\\\ P(Y=t' , X=t) &amp;= P(Y=t'|X=t) \\times P(X=t)\\\\ \\text{Joint} &amp;= \\text{Conditional} \\times \\text{Marginal} \\end{split} \\end{equation*}\\] <p>For a Joint Probability of 4 variables , </p> \\[\\begin{align*} f_{X_1X_2X_3X_4}(t_1,t_2,t_3,t_4) = P(X_4 = t_4 , X_3 = t_3 , X_2 = t_2 , X_1 = t_1) \\\\ \\implies f_{X_4 \\mid X_3 = t_3 , X_2 = t_2 , X_1=t_1}(t_4) \\times f_{X_3 \\mid X_2 = t_2 , X_1=t_1}(t_3) \\times f_{X_2 \\mid X_1=t_1}(t_2) \\times f_{X_1}(t_1) \\end{align*}\\]"},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/","title":"Parameter Estimation 2","text":""},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/#bayesian-estimation","title":"Bayesian Estimation","text":"<p>\\(\\(X_1 , X_2 .... X_n \\sim , \\text{parameter } \\Uptheta\\)\\) - Prior distribution of \\(\\Uptheta\\) : \\(\\Uptheta \\sim f(\\Uptheta)\\) - Bayes' rule : posterior \\(\\propto\\) likelihood \\(\\times\\) prior </p> <p>\\(\\(P(\\Uptheta = \\theta | S) = \\frac{P(S|\\Uptheta = \\theta) \\times f_{\\Uptheta}(\\theta)}{P(S)}\\)\\) ![[Pasted image 20230410153658.png]]</p>"},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/#choice-of-priors","title":"Choice of Priors","text":""},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/#types-of-priors","title":"Types of Priors","text":"<ul> <li> <p>Flat , uninformative: </p> <ul> <li>Nearly flat over the interval in which the parameter takes value </li> <li>This usually reduces to something close to maximum likelihood.</li> </ul> </li> <li> <p>Conjugate Priors: </p> <ul> <li>Pick a prior so that the posterior is in the same class as the prior.</li> </ul> </li> <li> <p>Informative Priors: </p> <ul> <li>This needs some justification from the domain of the problem.</li> <li>Parameterize the prior so that its flatness can be controlled.</li> </ul> </li> </ul>"},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/#examples","title":"Examples","text":""},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/#bernoulli-distribution","title":"Bernoulli Distribution","text":"<p>\\(\\(X_1 , X_2 .... X_n \\sim \\text{iid } \\text{Bernoulli}(\\mathbf{p})\\)\\) - Prior \\(\\mathbf{p} \\sim \\text{Uniform}[0,1]\\) , continuous distribution  - Samples: \\(x_1 , x_2 , x_3 ..... x_n\\) - \\(w = x_1 + x_2 + ... + x_n\\)  - Posterior density: \\(\\text{Beta}(w + 1 , n -w + 1)\\)     - Posterior Mean: \\(\\frac{w+ 1}{(w+1) + (n-w+1)} = \\frac{w+1}{n+2} =\\frac{x_1 + x_2 + ... +x_n + 1}{n+2}\\)</p>"},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/#bernoulli-distribution-with-beta-prior","title":"Bernoulli Distribution with beta prior","text":"<p>\\(\\(X_1 , X_2 .... X_n \\sim \\text{iid } \\text{Bernoulli}(\\mathbf{p})\\)\\) - Prior \\(\\mathbf{p} \\sim \\text{Beta}(\\alpha,\\beta)\\) , continuous distribution  - \\(w = x_1 + x_2 + ... + x_n\\)  - Posterior Density: \\(\\text{Beta}(w + \\alpha , n - w + \\beta)\\)     - Posterior Mean: \\(\\frac{w + \\alpha}{(w + \\alpha) + (n - w + \\beta)} = \\frac{w + \\alpha}{n + \\alpha + \\beta}\\)</p>"},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/#observations-for-beta-prior","title":"Observations for Beta Prior","text":"<ul> <li>Prior : \\(\\text{Beta}(\\alpha , \\beta)\\)<ul> <li>\\(\\alpha , \\beta \\geq 0\\)</li> <li>PDF \\(\\propto p^{\\alpha - 1}(1-p)^{\\beta -1} , 0 &lt; p &lt; 1\\)</li> </ul> </li> <li>\\(\\alpha = \\beta = 1\\)<ul> <li>Flat prior </li> <li>Estimate close to but not equal to maximum -likelihood </li> </ul> </li> <li>\\(\\alpha = \\beta = 0\\)<ul> <li>Estimate coincides with Maximum-likelihood.</li> </ul> </li> <li>\\(\\alpha = \\beta\\)<ul> <li>Symmetric Prior </li> </ul> </li> </ul>"},{"location":"STATS2/WEEK%2010/Parameter%20Estimation%202/#normal-sample-with-known-mean-and-known-variance","title":"Normal sample with known mean and known variance","text":"<p>\\(\\(X_1 , X_2 .... X_n \\text{iid Normal}(M ,\\sigma^2)\\)\\) Prior \\(M \\sim Normal(\\mu_{0} , \\sigma_{0}^{2})\\) , continuous distribution  \\(f_M(\\mu) = \\frac{1}{\\sqrt{2 \\pi}\\sigma_0} \\text{exp}(- \\frac{(\\mu - \\mu_0)^2}{2 \\sigma_{0}^{2}})\\)</p> <ul> <li>Posterior Density : Normal </li> <li>Posterior Mean = \\(\\overline{x}\\frac{n \\sigma_{0}^{2}}{n \\sigma_{0}^{2} + \\sigma^2} + \\mu_0 \\frac{\\sigma^2}{n \\sigma_{0}^{2} + \\sigma^2}\\)</li> </ul>"},{"location":"STATS2/WEEK%2011/Hypothesis%20Testing/","title":"Hypothesis Testing","text":"<p>Using samples , decide between a null hypothesis denoted \\(H_0\\) and an alternative hypothesis denoted \\(H_A\\) .</p>"},{"location":"STATS2/WEEK%2011/Hypothesis%20Testing/#acceptance-set-and-test","title":"Acceptance Set and Test","text":"<p>\\(X_1 , X_2 .... X_n \\sim X , H_0 : \\text{null hypothesis , }H_A : \\text{alternative hypothesis.}\\) - Suppose \\(X \\in \\symbfscr{X}\\). Then the samples \\(X_1 , X_2 ... X_n \\in \\symbfscr{X}^n\\) - Subset \\(A \\subseteq \\symbfscr{X}\\)  If \\(X_1 , X_2 ... X_n \\in A\\) we accept \\(H_0\\) otherwise we reject \\(H_0\\)</p>"},{"location":"STATS2/WEEK%2011/Hypothesis%20Testing/#size-and-power-of-test","title":"Size and Power of Test","text":"<p>Type I error: It is also known as the size of a test , denoted as \\(\\alpha\\) - Reject \\(H_0\\) when \\(H_0\\) is true  - \\(\\alpha = P(\\text{Type I error}) = P(\\text{Reject }H_0 | H_0 \\text{ is true})\\) Type II error: It is also known as the power of a test , denoted as \\(1 - \\beta\\)  - Accept \\(H_0\\) when \\(H_A\\) is true  - \\(\\beta = P(\\text{Type II Error}) = P(\\text{Accept } H_0|H_A \\text{ is true})\\)</p>"},{"location":"STATS2/WEEK%2011/Hypothesis%20Testing/#types-of-tests","title":"Types of Tests","text":"<pre><code>$c$ = critical value\n</code></pre>"},{"location":"STATS2/WEEK%2011/Hypothesis%20Testing/#right-tailed-test","title":"Right Tailed Test","text":"<p>\\(H_0 : \\mu = \\mu_0\\) \\(H_A : \\mu &gt; \\mu_0\\) \\(T = \\overline{X}\\) Rejection Region: \\(\\overline{X} &gt; c\\) \\(Z = \\frac{\\overline{X} - \\mu_0}{\\sigma / \\sqrt{n}}\\)</p>"},{"location":"STATS2/WEEK%2011/Hypothesis%20Testing/#left-tailed-test","title":"Left Tailed Test","text":"<p>\\(H_0 : \\mu = \\mu_0\\) \\(H_A : \\mu &lt; \\mu_0\\) \\(T = \\overline{X}\\) Rejection Region: \\(\\overline{X} &lt; c\\)</p>"},{"location":"STATS2/WEEK%2011/Hypothesis%20Testing/#two-tailed-test","title":"Two Tailed Test","text":"<p>\\(H_0 : \\mu = \\mu_0\\) \\(H_A : \\mu \\neq \\mu_0\\) \\(T = \\overline{X}\\) Rejection Region: \\(|\\overline{X} - \\mu| &gt; c\\)</p>"},{"location":"STATS2/WEEK%2012/Different%20Types%20of%20Tests/","title":"Different Types of Tests","text":""},{"location":"STATS2/WEEK%2012/Different%20Types%20of%20Tests/#normal-samples-and-statistics","title":"Normal Samples and Statistics","text":"\\[X_1 , X_2 , X_3 ..... X_n \\sim iid \\text{ Normal}(\\mu , \\sigma^2)$$ - Sample Mean $\\overline{X} = \\frac{1}{n}(X_1 + X_2 + X_3 .... + X_n)$ - Sample Variance $S^2 = \\frac{1}{n-1}((X_1 - \\overline{X})^2 + (X_2 - \\overline{X})^2 + ...... + (X_n - \\overline{X})^2)$ $$\\overline{X} \\sim \\text{ Normal}(\\mu , \\frac{\\sigma^2}{n})$$ $$\\frac{(n-1)}{\\sigma^2}S^2 \\sim \\chi^{2}_{n-1}$$ $$\\frac{\\overline{X} - \\mu}{S / \\sqrt{n}} \\sim t_{n-1}\\]"},{"location":"STATS2/WEEK%2012/Different%20Types%20of%20Tests/#t-test-for-mean-unknown-variance","title":"T-Test for Mean (unknown variance)","text":"<p>\\(\\(X_1 , X_2 ,  ...... ,X_n \\sim \\text{ Normal}(\\mu , \\sigma^2)\\)\\) - Null \\(H_0 : \\mu = \\mu_0, \\text{ Alternative } H_A : \\mu &gt; \\mu_0\\) - \\(T = \\overline{X}\\) , Test : Reject \\(H_0 \\text{ if } T &gt; c\\)</p> <p>Computing Significance Level - Sample Variance \\(S^2 = \\frac{1}{n-1}\\sum^{n}_{i=1}(X_i - \\overline{X})^2\\) - Given , \\(H_0 ,\\frac{T - \\mu_0}{S /  \\sqrt{n}} \\sim t_{n-1}\\) \\(\\(\\alpha = P(T &gt; c | \\mu = \\mu_0) = P(t_{n-1} &gt; \\frac{c - \\mu_0}{S / \\sqrt{n}}) = 1 - F_{t_{n-1}}(\\frac{c- \\mu_0}{S/ \\sqrt{n}})\\)\\)</p>"},{"location":"STATS2/WEEK%2012/Different%20Types%20of%20Tests/#mathbfchi2-test-for-variance","title":"\\(\\mathbf{\\chi^2}\\) test for variance","text":"<p>\\(\\(X_1 , X_2 , ..... iid \\text{ Normal}(\\mu , \\sigma^2)\\)\\) - Null \\(H_0 : \\sigma = \\sigma_0\\) , Alternative \\(H_A : \\sigma &gt; \\sigma_0\\) - \\(S^2 = \\frac{1}{n-1}\\sum^{n}_{i=1}(X - \\overline{X})^2\\) ,  Test: Reject \\(H_0\\) if \\(S &gt;c\\)</p> <p>Computing Significance Level - Given \\(H_0\\) , \\(\\frac{n-1}{\\sigma_0^2}S^2 \\sim \\chi^{2}_{n-1}\\) - \\(\\alpha = P(S &gt; c | H_0) = P(\\frac{n-1}{\\sigma_0^2})S^2 &gt; \\frac{n-1}{\\sigma_0^2})c^2 = 1 - F_{\\chi^{2} _{n-1}}(\\frac{n-1}{\\sigma_0^2}c^2)\\)</p>"},{"location":"STATS2/WEEK%2012/Different%20Types%20of%20Tests/#two-samples-from-normal-distribution","title":"Two Samples from Normal Distribution","text":"<p>\\(\\(X_1 , X_2 , X_3 , ...... X_n \\sim \\text{iid Normal}(\\mu_1 , \\sigma^2_1 )\\)\\) \\(\\(Y_1 , Y_2 , Y_3 , ...... Y_n \\sim \\text{iid Normal}(\\mu_2 , \\sigma^2_2 )\\)\\) - \\(\\overline{X} \\sim \\text{ Normal}(\\mu_1 , \\sigma_1^2 / n_1)\\) , \\(\\overline{Y} \\sim \\text{ Normal}(\\mu_2 , \\sigma_2^2 / n_2)\\) - \\((\\frac{n_1-1}{\\sigma^2_1})S^2_X \\sim \\chi^2_{n_1 - 1}\\) , \\((\\frac{n_2-1}{\\sigma^2_2})S^2_Y \\sim \\chi^2_{n_2 - 1}\\) - \\(\\overline{X} - \\overline{Y} \\sim \\text{Normal}(\\mu_1 - \\mu_2 , \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2})\\) - If \\(\\sigma_1 = \\sigma_2\\)     - \\(\\frac{S^2_X}{S^2_Y} \\sim F(n_1 -1 , n_2 - 1)\\)</p>"},{"location":"STATS2/WEEK%2012/Different%20Types%20of%20Tests/#two-samples-z-test","title":"Two Samples Z-test","text":"<p>\\(\\(X_1 , X_2 , X_3 , ...... X_n \\sim \\text{iid Normal}(\\mu_1 , \\sigma^2_1 )\\)\\) \\(\\(Y_1 , Y_2 , Y_3 , ...... Y_n \\sim \\text{iid Normal}(\\mu_2 , \\sigma^2_2 )\\)\\) - Null \\(H_0 : \\mu = \\mu_0, \\text{ Alternative } H_A : \\mu \\neq \\mu_0\\) - \\(T = \\overline{Y} - \\overline{X}\\) , Test : Reject \\(H_0 \\text{ if } |T| &gt; c\\)</p> <p>Computing Significance Level Given \\(H_0\\) , \\(T \\sim \\text{Normal}(0 , \\sigma_{T}^{2})\\) , where \\(\\sigma_T^2 = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma^2_2}{n_2}\\) \\(\\(\\alpha = P(|T| &gt; c | H_0) = P(|\\text{Normal}(0,1)| &gt; \\frac{c}{\\sigma_{T}})\\)\\)</p>"},{"location":"STATS2/WEEK%2012/Different%20Types%20of%20Tests/#two-sample-f-test","title":"Two Sample F-test","text":"<p>\\(\\(X_1 , X_2 , X_3 , ...... X_n \\sim \\text{iid Normal}(\\mu_1 , \\sigma^2_1 )\\)\\) \\(\\(Y_1 , Y_2 , Y_3 , ...... Y_n \\sim \\text{iid Normal}(\\mu_2 , \\sigma^2_2 )\\)\\) - Null \\(H_0 : \\sigma_1 = \\sigma_2\\) , Alternative \\(H_A : \\sigma_1 \\neq \\sigma_2\\) - T = \\(\\frac{S_X^2}{S_Y^2}\\) , Test : Reject \\(H_0\\) if \\(T &gt; 1 + c_R\\) or \\(T &lt; 1 - c_L\\) - Given \\(H_0\\) , \\(T \\sim F(n_1 -1 , n_2 -1)\\) - \\(\\alpha / 2 = P(T &lt; 1 - c_L | H_0) = P(T &gt; 1 + c_R | H_0)\\)</p>"},{"location":"STATS2/WEEK%202/AQ%20Solutions/","title":"Assignment Question Solutions","text":"<p>Warning</p> <ul> <li>Please try to solve the questions on your own first.</li> <li>Thinking that \"I have seen the solutions , I understand everything\" is WRONG. You actually don't understand anything unless you solve questions.</li> <li>For detailed explanations look for posts on discourse or scroll through live lectures.</li> </ul>"},{"location":"STATS2/WEEK%202/AQ%20Solutions/#aq-21","title":"AQ 2.1","text":""},{"location":"STATS2/WEEK%202/AQ%20Solutions/#aq-22","title":"AQ 2.2","text":""},{"location":"STATS2/WEEK%202/AQ%20Solutions/#aq-24","title":"AQ 2.4","text":""},{"location":"STATS2/WEEK%202/AQ%20Solutions/#aq-25","title":"AQ 2.5","text":""},{"location":"STATS2/WEEK%202/AQ%20Solutions/#aq-210","title":"AQ 2.10","text":""},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/","title":"Extra Content","text":""},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#visualizing-random-variables","title":"Visualizing Random Variables","text":"<p>Sometimes we dont want the usual representation of random variables, that is when we use functions. Functions change the horizontal axis of the graph. \\(f(x) = x- 10\\) is a function which shifts the x axis to the left by 10.</p> <p>Sometimes these functions can either be one to one , which means that each input has a unique output/ no two outputs are the same OR the functions can be many to one , which means outputs for different inputs can be the same/ two or more outputs are same.</p> <p>See This for what changes occurs on different types of functions.</p>"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#many-to-one-functions","title":"Many To One Functions","text":"<p>In the case of many to one functions we add the probabilities when the outputs are the same.</p> <p></p> <p>Info</p> <p>If two variables \\(X\\) and \\(Y\\) are independent then their functions \\(f(X)\\) and \\(g(Y)\\) will also be independent.</p>"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#formulas","title":"Formulas","text":"<p>You are probably better off mugging up these because its not gonna come in future weeks. Also you will be provided with a forumla sheet in the exam with all the formula required for STATS2.</p>"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#two-uniformly-distributed-iid-random-variables","title":"Two uniformly distributed iid random variables","text":""},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#sum","title":"Sum","text":"<p>Given that \\(X,Y \\sim Uniform \\{1,2,3,4.....n\\} , W=X+Y\\) \\(\\implies W \\in \\{2,3,4,5....2n\\}\\)</p> \\[P(W=w) =  \\begin{cases} \\frac{w-1}{n^2}, &amp; 2 \\leq w \\leq n+1 \\\\ \\frac{2n - w + 1}{n^2} &amp; n+2 \\leq w \\leq 2n \\end{cases}\\]"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#maximum","title":"Maximum","text":"<p>Given that \\(X,Y \\sim Uniform \\{1,2,3,4.....n\\} , Z=\\max(X,Y)\\)</p> <p>\\(\\implies Z \\in \\{1,2,3,....n\\}\\)</p> \\[P(Z=z) = \\frac{2z-1}{n^2}\\]"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#sum-of-n-independent-bernoulli-trials","title":"Sum of n independent bernoulli trials","text":"<p>Let \\(X_1 , X_2 , X_3 .... X_n\\) be the results of \\(n\\) i.i.d \\(Bernoulli(p)\\) trials. </p> <p>The sum of the n random variables \\(X_1 , X_2 , X_3 .... X_n\\) is \\(Binomial(n,p)\\)</p>"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#sum-of-2-random-variables-taking-integer-values","title":"Sum of 2 random variables taking integer values","text":"<p>Suppose \\(X\\) and \\(Y\\) take integer values and let their joint PMF be \\(f_{XY}\\). Let \\(Z = X+Y\\)</p> <p>Let \\(z\\) be some integer.</p> \\[\\begin{align}     P(Z=z) &amp;= P(X+Y=z) \\\\     &amp;= \\sum^{\\infty}_{x=- \\infty} P(X=x , Y=z-x) \\\\     &amp;= \\sum^{\\infty}_{x=- \\infty}f_{XY}(x , z-x) \\\\     &amp;= \\sum^{\\infty}_{x=- \\infty}f_{XY}(z-y , y) \\\\ \\end{align}\\]"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#convolution","title":"Convolution","text":"<p>If \\(X\\) and \\(Y\\) are independent,</p> \\[ f_{X+Y}(z) = \\sum^{\\infty}_{x = - \\infty}f_{X}f_{Y}(z-x) \\]"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#two-independent-poisson","title":"Two Independent Poisson","text":""},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#sum_1","title":"Sum","text":"<p>\\(Z = X+Y\\)</p> \\[f_Z(Z) = \\frac{e^{-(\\lambda_1 + \\lambda_2)} \\times (\\lambda_1 + \\lambda_2)^Z}{Z!} \\]"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#conditional-distribution-of-xz","title":"Conditional distribution of X|Z","text":"\\[P(X=k|Z=n) = \\frac{n!}{k!(n-k)!} \\times (\\frac{\\lambda_1}{\\lambda_1 + \\lambda_2})^k \\times (\\frac{\\lambda_2}{\\lambda_1 + \\lambda_2})^{n-k}\\] <p>which is also equals to </p> \\[P(X=k|Z=n) = Binomial(n, \\frac{\\lambda_1}{\\lambda_1 + \\lambda_2})\\] <p>given that \\(X|Z \\sim Binomial(n, \\frac{\\lambda_1}{\\lambda_1 + \\lambda_2})\\)</p>"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#max-of-cdf-of-2-independent-random-variables","title":"Max of CDF of 2 independent random variables","text":"<p>Definition (CDF of a random variable)</p> <p>Cumulative distribution function of a random variable \\(X\\) is a function \\(F_X : \\mathbb{R} \\to [0,1]\\) defined as</p> \\[ F_{X}(x) = P(X \\leq x)\\] <p>Suppose \\(X\\) and \\(Y\\) are independent and \\(Z = \\text{max}(X,Y)\\).</p> \\[\\begin{align}     F_Z(z) &amp;= P(\\text{max}(X,Y) \\leq z) \\\\     &amp;= P((X \\leq z) \\text{and} (Y \\leq z)) \\\\     &amp;= P(X \\leq z)P(Y \\leq z) \\\\     &amp;= F_X(z)F_Y(z) \\end{align}\\]"},{"location":"STATS2/WEEK%202/Notes/Extra%20Content/#min-of-2-independent-geometric-random-variables","title":"Min of 2 independent Geometric Random Variables","text":""},{"location":"STATS2/WEEK%202/Notes/Notes/","title":"Independent Random Variables","text":""},{"location":"STATS2/WEEK%202/Notes/Notes/#takeaways-from-this-week","title":"Takeaways from this week","text":"<ul> <li>Being able to check whether a given join distribution has indepenedent random variables or not.</li> <li>Memoryless Property </li> </ul>"},{"location":"STATS2/WEEK%202/Notes/Notes/#independence-of-random-variables","title":"Independence of Random Variables","text":"<p>Independent random variables are variables that have no influence or relationship with each other.  In other words, the occurrence or value of one random variable does not affect the occurrence  or value of the other random variable.</p> <p>Formally, two random variables \\(X\\) and \\(Y\\) are considered independent if the probability distribution of one variable is not affected by the other variable.</p> <p>Let \\(X\\) and \\(Y\\) be two random variables defined in a probability space with ranges \\(T_X\\) and \\(T_Y\\) respectively. \\(X\\) and \\(Y\\) are considered independent if :</p> \\[f_{XY}(t_1 , t_2) = f_X(t_1) \\times f_{Y|X=t_1}(t2)\\] <p>where,</p> \\[f_{Y|X=t_1}(t2) = f_Y(t_2)\\] \\[\\therefore f_{XY}(t_1 , t_2) = f_X(t_1) \\times f_Y(t_2)\\] <p>Properties of Independent Variables</p> <ul> <li>Joint PMF is the product of the marginal PMFs when the variables are independent.</li> <li>All the subsets of independent random variables are independent.</li> </ul>"},{"location":"STATS2/WEEK%202/Notes/Notes/#checking-independence-of-random-variables","title":"Checking Independence of Random Variables","text":"<p>For every element in the table of 2 or more random variables. Each entry must be the product of their respective marginal PMFs then only they are considered independent. </p> <p>If for any element \\(f_{XY}(t_1 , t_2) \\neq f_X(t_1)f_Y(t_2)\\) then the variables are considered dependent.</p> <p>Tips To Identify Independent Random Variables</p> <ul> <li>i.i.ds (independent and identically distributed) are one of the examples for independent random variables for any \\(f_{XY}(t_1 , t_2) \\neq 0\\)</li> <li>Finding dependent variables is easier when \\(f_{XY}(t_1)(t_2) =0\\). The logic behind it is for some \\(t_1\\) and \\(t_2\\) \\(f_X(t_1) \\times f_Y(t_2) \\neq 0\\) , if it is 0 then it would mean that either or both of the marginals are 0 which is generally not true.</li> </ul>"},{"location":"STATS2/WEEK%202/Notes/Notes/#geometric-iid","title":"Geometric iid","text":""},{"location":"STATS2/WEEK%202/Notes/Notes/#question-1","title":"Question 1","text":"<p>Let \\(X_1 , X_2 , X_3 ... , X_n\\) be an iid with a Geometric(p) distribution. What is the probability that all of these random variables are larger than some positive integer \\(j\\).</p> \\[X \\sim \\{1,2,3,....\\}\\] \\[P(X=k) = (1-p)^{k-1}p\\] <p>The probability that the random variables are greater than \\(j\\) is :</p> \\[(P(X &gt; j))^n = (1-p)^{jn}\\]"},{"location":"STATS2/WEEK%202/Notes/Notes/#question-2","title":"Question 2","text":"<p>Let \\(X \\sim \\{\\stackrel{\\frac{1}{2}}{0},\\stackrel{\\frac{1}{4}}{1} , \\stackrel{\\frac{1}{8}}{2} , \\stackrel{\\frac{1}{16}}{3} , \\stackrel{\\frac{1}{16}}{4}\\}\\) , and let \\(X_1 ..... X_n\\) be the iid samples with distribution \\(X\\).</p>"},{"location":"STATS2/WEEK%202/Notes/Notes/#what-is-the-probability-that-4-is-missing-in-some-samples","title":"What is the probability that 4 is missing in some samples.","text":"<ul> <li>\\(P(X_1 \\neq 4 , X_2 \\neq 4 , X_3 \\neq 4 , X_4 \\neq 4 .... X_n \\neq 4)\\)</li> <li>\\((P(X \\neq 4))^n\\) as all the probabilities are same for an iid.</li> <li>\\((P(X \\neq 4))^n = (1 - P(X = 4))^n\\)</li> <li>\\((P(X \\neq 4))^n = (1 - \\frac{1}{16})^n = (\\frac{15}{16})^n\\)</li> </ul>"},{"location":"STATS2/WEEK%202/Notes/Notes/#what-is-the-probability-that-4-appears-exactly-once","title":"What is the probability that 4 appears exactly once.","text":"<p>\\(\\implies P( \\text{4 Appears exactly once})=\\)</p> \\[\\begin{align} \\implies P(X_1 = 4 , X_2 \\neq 4 , X_3 \\neq 4 .... X_n \\neq 4) + \\\\  P(X_1 \\neq 4 , X_2 = 4 , X_3 \\neq 4 ... X_n \\neq 4) + ... \\\\ P(X_1 \\neq 4 , X_2 \\neq 4 , X_3 \\neq 4 .... X_{n-1} \\neq 4 , X_n =4) \\end{align}\\] <p>\\(\\implies n \\times P(X \\neq 4)^{n-1} \\times P(X=4)\\) \\(\\implies n \\times (\\frac{15}{16})^{n-1} \\times (\\frac{1}{16})\\)</p>"},{"location":"STATS2/WEEK%202/Notes/Notes/#memoryless-property-of-geometric-distribution","title":"Memoryless Property of Geometric Distribution","text":"<p>The memoryless property of geometric random variables states that the past history or  previous outcomes of the trials do not affect the future outcomes.  In other words, the probability of success in the next trial remains the same,  regardless of how many trials have already occurred.</p> <p>(Just mug up the formula for this one if you dont understand this \ud83d\udc80\ud83e\udd72)</p> \\[P(X \\geq s+t | X \\geq t  ) = P(X \\geq s)\\]"},{"location":"STATS2/WEEK%202/Notes/Notes/#proof","title":"Proof","text":"<p>The PMF of a random variable \\(X\\) is </p> \\[\\begin{align} f(x) &amp;= p(1-p)^x &amp; x &amp;= 0,1,2,.. \\end{align}\\] <p>The probability that \\(X\\) is greater than or equal to \\(x\\) is</p> \\[\\begin{align} P(X \\geq x) &amp;= (1-p)^x &amp; x = 0,1,2,... \\end{align}\\] <p>The conditional probability will be</p> \\[\\begin{align} P(X \\geq s +t | X \\geq t) &amp;= \\frac{P(X \\geq s + t , X \\geq t)}{P(X \\geq t)} \\\\ &amp;= \\frac{P(X \\geq s+t)}{P(X \\geq t)} \\\\ &amp;=  \\frac{(1-p)^{s+t}}{(1-p)^t} \\\\ &amp;= (1-p)^s \\\\ &amp;= P(X \\geq s) \\end{align}\\]"},{"location":"STATS2/WEEK%203/AQ%20Solutions/","title":"Assignment Question Solutions","text":"<p>Warning</p> <ul> <li>Please try to solve the questions on your own first.</li> <li>Thinking that \"I have seen the solutions , I understand everything\" is WRONG. You actually don't understand anything unless you solve questions.</li> <li>For detailed explanations look for posts on discourse or scroll through live lectures.</li> </ul>"},{"location":"STATS2/WEEK%203/AQ%20Solutions/#aq-31","title":"AQ 3.1","text":""},{"location":"STATS2/WEEK%203/AQ%20Solutions/#aq-32","title":"AQ 3.2","text":""},{"location":"STATS2/WEEK%203/AQ%20Solutions/#aq-34","title":"AQ 3.4","text":""},{"location":"STATS2/WEEK%203/AQ%20Solutions/#aq-35","title":"AQ 3.5","text":""},{"location":"STATS2/WEEK%203/AQ%20Solutions/#aq-36","title":"AQ 3.6","text":""},{"location":"STATS2/WEEK%203/AQ%20Solutions/#aq-37","title":"AQ 3.7","text":""},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/","title":"Expectation of Random Variables","text":""},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#takeaways-from-this-week","title":"Takeaways From This Week","text":"<ul> <li>Bounds on Probabibilites is an important concept and will be used in the future</li> <li>Rest of the content in this week is formula based so you have to figure out how and where to apply the formulas.</li> <li>The formulas will be given in the in-person exams so no need to remember them , just study the application.</li> </ul>"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#random-variables-expectations-and-variances","title":"Random Variables , Expectations and Variances","text":""},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#expectation-of-random-variables","title":"Expectation of Random Variables","text":"<p>The expectation of a random variable is like its average value or what you would typically expect it to be. It gives you an idea of the central tendency of the variable.</p> <p>Coin Toss</p> <p>The expected value for a fair coin toss should be 0.5 . </p> <p>Suppose \\(X\\) is a random variables defined in the range of \\(T_X\\) and PMF of \\(X\\) is \\(f_X\\) . The expected value of the random variables \\(X\\) will be</p> \\[E[X] = \\sum_{t \\in T_X} t \\times f_X(t) = \\sum_{t \\in T_X} t \\times P(X =t)\\] <p>Note</p> <ul> <li>\\(E[X]\\) has the same unit of \\(X\\)</li> <li>\\(E[X]\\) may or may not belong to range of \\(X\\)</li> </ul> <p>Expectation Properties</p> <ul> <li>\\(E[c \\times X] = c \\times E[X]\\) , where \\(c\\) is a constant and \\(X\\) is a random variable.</li> <li>\\(E[X + Y] = E[X] + E[Y]\\) , where \\(X\\) and \\(Y\\) are 2 random variables.</li> <li>\\(E[X - Y] = E[X] + E[Y]\\) </li> <li>If X and Y are independent :\\(E[XY] = E[X]E[Y]\\)</li> </ul>"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#variance-and-standard-deviation-properties","title":"Variance and Standard Deviation Properties","text":"<p>The variance of a random variable measures how spread out or how much the values of the variable differ from the expected value (or mean). In simpler terms, it tells you how much the individual values of the random variable tend to deviate from the average.</p> <p>Let \\(X\\) be a random variable. Let \\(a\\) be a constant real number.</p> \\[\\begin{align} Var(X) = E[X^2] - E[X]^2 \\\\  SD(X) = \\sqrt{Var(X)} \\end{align}\\] <p>Variance Properties</p> <ul> <li>\\(Var(aX) = a^2Var(X)\\)</li> <li>\\(SD(aX) = |a|SD(X)\\)</li> <li>\\(Var(X + a) = Var(X)\\)</li> <li>\\(SD(X + a) = SD(X)\\)</li> </ul> <p>Info</p> <ul> <li>If X and Y are independent : \\(Var(X+Y) = Var(X) + Var(Y)\\)</li> </ul>"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#types-of-random-variables","title":"Types of Random Variables","text":"Random Variables Expectation Variance Uniform Random Variable \\(\\frac{a+b}{2}\\) \\(\\frac{(b-a)^2}{12}\\) Geometric Random Variable \\(\\sum^{\\infty}_{t=1} t(1-p)^{t-1}p = \\frac{1}{p}\\) \\(\\frac{1-p}{p^2}\\) Poisson Random Variable \\(\\sum^{\\infty}_{t = 0} t \\times e^{- \\lambda} \\times \\frac{\\lambda ^ {t}}{t!} = \\lambda\\) \\(\\lambda\\) Binomial Random Variable \\(\\sum^{n}_{t=0} t \\times {n \\choose x} p^t (1-p)^{n-t} = np\\) \\(np(1-p)\\) Bernoulli Random Variable \\(0(1-p) + p = p\\) \\(p(1-p)\\)"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#bounds-in-probabilities","title":"Bounds In Probabilities","text":"<p>How do Probability bounds even work?</p> <p>The Central Limit Theorem (CLT) states that when independent random variables are added together, their sum tends to follow a normal distribution, regardless of the shape of the individual variables' distributions. This holds true as the number of variables increases. In simpler terms, the CLT explains why many real-world phenomena exhibit a bell-shaped or normal distribution when multiple random factors are involved.</p> Understanding CLT <p></p> <p>This video dives deep into the concept of CLT (Central Limit Theorem) , after watching this you will have a much better understanding of CLT and Probability Bounds.</p>"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#markovs-inequality","title":"Markov's Inequality","text":"Note <p>Markov's inequality provides a general upper bound, but it may not provide a tight bound in many cases.</p> <p>Markov's inequality states that the probability of a non-negative random variable exceeding a certain value is bounded by the ratio of its expected value to that value.</p> <p>Let \\(X\\) be a random variable.</p> \\[P(X \\geq a) \\leq \\frac{E(X)}{a}\\] <p>Example</p> <p>A shopkeeper sells mobile phones. The expected demand for mobile phones is\u00a04\u00a0per week. \\(X\\)\u00a0is denoting the number of phones sold in a week.</p> \\[ P(X \\geq 10) \\leq 0.4 \\] <p>Also, </p> \\[P(X &lt; 10) \\geq 0.6\\]"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#chebyshevs-inequality","title":"Chebyshev's Inequality","text":"<p>Chebyshev's inequality states that the probability of a random variable deviating from its mean by a certain number of standard deviations is bounded by the reciprocal of that number squared.</p> <p>Let \\(X\\) be a random variable with mean \\(\\mu\\) and finite variance \\(\\sigma^2\\) , then for any real number \\(k&gt;0\\)</p> \\[P(|X - \\mu| &lt; k \\sigma) \\geq 1 - \\frac{1}{k^2}\\] <p>Also,</p> \\[P(|X - \\mu| \\geq k \\sigma) \\leq \\frac{1}{k^2}\\] Why is it \\(\\frac{1}{k^2}?\\) <p>A general explanation would be to look at the graphs of \\(\\frac{1}{k}\\) and \\(\\frac{1}{k^2}\\).</p> <p>It can be seen that this graph does not look like a bell curve , also it goes in 3rd quadrant too. If we were to plot probability along the y-axis , it would become negative according to this graph.   Graph of \\(\\frac{1}{k}\\)</p> <p>This graph is much more similar to a bell curve and does not go in 3rd quadrant.   Graph of \\(\\frac{1}{k^2}\\)</p>"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#more-important-formulas","title":"More Important Formulas","text":""},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#standardized-random-variables","title":"Standardized Random Variables","text":"<p>Standardized random variables are used to transform data from different distributions into a common scale, allowing for meaningful comparisons and analysis.</p> <p>A random variable \\(X\\) is said to be standardized if \\(E[X] = 0 \\text{ and } Var(X) = 1\\)</p> <p>Also, If \\(X\\) is a random variable.  Then,</p> \\[\\frac{X - E[X]}{SD(X)}\\] <p>is a standardized random variable.</p> What is the use of Standardized Random Variables? <ul> <li>Statistical Analysis: Standardization allows for meaningful comparisons of variables with different scales and distributions.</li> <li>Hypothesis Testing: Standardized variables help meet assumptions of normality in tests and improve accuracy.</li> <li>Z-Scores: Provide a common reference point for comparing data points and identifying outliers.</li> <li>Data Visualization: Simplifies plotting variables with different scales together for easier analysis.</li> <li>Machine Learning: Standardization is a preprocessing step to ensure features are on a similar scale for better model performance.</li> </ul>"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#covariance-formula","title":"Covariance Formula","text":"What is Covariance? <p>Covariance is a statistical measure that quantifies the relationship between two random variables. It measures how changes in one variable are associated with changes in another variable. In other words, covariance indicates the degree to which two variables vary together.</p> \\[Cov(X,Y) = E[XY] - E[X] \\times E[Y]\\] <p>Properties of Covariance</p> <p>The formula calculates the average of the product of the deviations of X and Y from their respective means. </p> <ul> <li>If the covariance is positive, it indicates that as one variable increases, the other tends to increase as well. </li> <li>If the covariance is negative, it indicates an inverse relationship, meaning that as one variable increases, the other tends to decrease. </li> <li>A covariance of zero suggests no linear relationship between the variables.</li> </ul>"},{"location":"STATS2/WEEK%203/Expectation%20of%20Random%20Variables/#correlation-coefficient","title":"Correlation Coefficient","text":"What is Correlation Coefficient <p>The correlation coefficient is a statistical measure that quantifies the strength and direction of the linear relationship between two variables. It provides a numerical value between -1 and 1 that indicates the degree of association between the variables.</p> \\[Cor(X,Y) = \\frac{Cov(X,Y)}{SD(X) \\times SD(Y)}\\] <p>Properties of Correlation Coefficient</p> <p>Let correlation coefficient be denoted as r</p> <ul> <li>If r = 1, it indicates a perfect positive correlation, meaning that the variables have a strong linear relationship and move in the same direction.</li> <li>If r = -1, it indicates a perfect negative correlation, meaning that the variables have a strong linear relationship but move in opposite directions.</li> <li>If r = 0, it indicates no linear correlation, meaning that the variables have no linear relationship.</li> <li>A correlation coefficient closer to 1 or -1 indicates a stronger linear relationship, while a value closer to 0 indicates a weaker or no linear relationship.</li> </ul>"},{"location":"STATS2/WEEK%204/AQ%20Solutions/","title":"Assignment Question Solutions","text":"<p>Warning</p> <ul> <li>Please try to solve the questions on your own first.</li> <li>Thinking that \"I have seen the solutions , I understand everything\" is WRONG. You actually don't understand anything unless you solve questions.</li> <li>For detailed explanations look for posts on discourse or scroll through live lectures.</li> </ul>"},{"location":"STATS2/WEEK%204/AQ%20Solutions/#aq-42","title":"AQ 4.2","text":""},{"location":"STATS2/WEEK%204/AQ%20Solutions/#aq-43","title":"AQ 4.3","text":""},{"location":"STATS2/WEEK%204/AQ%20Solutions/#aq-45","title":"AQ 4.5","text":""},{"location":"STATS2/WEEK%204/AQ%20Solutions/#aq-46","title":"AQ 4.6","text":""},{"location":"STATS2/WEEK%204/Continuous%20Random%20Variables/","title":"Cumulative Distribution Function","text":"<p>It is a function that describes the probability distribution of a random variable by specifying the probability that the random variable takes on a value less than or equal to a given value.</p> <p>The CDF of a random variable \\(X\\) , denoted \\(F_X(X)\\) , is a function from \\(\\mathbb{R} \\to [0,1]\\) is defined as </p> \\[F_X(X) = P(X \\leq x)\\] <p>Properties</p> <ul> <li>\\(F(X)\\) is always a non-decreasing funciton taking values between 0 and 1.</li> <li>\\(P(a &lt; X \\leq b) = F_X(b) - F_X(a)\\)</li> <li>As \\(X \\to - \\infty\\) , \\(F_X\\) goes to 0.</li> <li>As \\(X \\to  \\infty\\) , \\(F_X\\) goes to 1.</li> <li>Probability of \\(X\\) taking a specific value is always 0.</li> </ul>"},{"location":"STATS2/WEEK%204/Continuous%20Random%20Variables/#cdf-of-standardised-variables","title":"CDF Of Standardised Variables","text":"<p>Let a discrete random variable \\(X\\) have a CDF \\(F_X\\). Assume that \\(Y = \\frac{X - \\mu}{\\sigma}\\) , where \\(\\mu\\) and \\(\\sigma\\) are the mean and standard deviation of \\(X\\)  respectively. If \\(F_Y\\) is the CDF of \\(Y\\) , then </p> \\[F_Y(y) = F_X(\\mu + Y \\sigma)\\]"},{"location":"STATS2/WEEK%204/Continuous%20Random%20Variables/#continuous-random-variable","title":"Continuous Random Variable","text":"<p>Example</p> <p>Height , Weight , Time , Temperature , Price , etc.</p> <p>A continuous random variable is a type of random variable that can take on any value within a specified range or interval. Unlike discrete random variables, which can only assume a countable set of distinct values, continuous random variables have an infinite number of possible values within a given range.</p> <p>A random variable \\(X\\) with CDF \\(F_X(x)\\) is said to be continuous random variable if \\(F_X(x)\\) is continuous at every \\(x\\).</p> <p>Properties</p> <ul> <li>\\(P(X =x) = 0\\) for all \\(x\\)</li> <li>\\(\\therefore P(a \\leq X \\leq b) = P(a &lt; X \\leq b) = P(a \\leq X &lt; b) = P(a &lt; X &lt; b)\\)</li> <li>Graphs of continuous random variables never breaks at any point and does not jump from one value to another.</li> <li>Probability of \\(X\\) falling in an interval will be nonzero </li> </ul>"},{"location":"STATS2/WEEK%204/Continuous%20Random%20Variables/#probability-density-functions","title":"Probability Density Functions","text":"<p>Probability Density Function (PDF) is a function that describes the probability distribution of a continuous random variable. </p> <p>The PDF represents the relative likelihood of different outcomes or values occurring within that range. It is typically denoted as \\(f(x)\\), where \\(x\\) is the variable, and the integral of the PDF over a specific interval gives the probability of the random variable falling within that interval.</p> \\[\\int^{b}_{a}f(x) dx = F(b) - F(a) = P(a &lt; X &lt; b)\\] <p>Properties</p> <ul> <li>The PDF must be non-negative for all values of x.</li> <li> <p>The total area under the PDF curve must be equal to 1.</p> <p>\\(\\implies \\int^{\\infty}_{ - \\infty} f(x) dx = 1\\)</p> </li> </ul>"},{"location":"STATS2/WEEK%204/Continuous%20Random%20Variables/#common-distribution-functions","title":"Common Distribution Functions","text":"Distribution PDF CDF Uniform \\(X \\sim Uniform[a,b]\\) \\(f_X(x) = \\begin{cases} \\frac{1}{b-a} &amp; a &lt; x &lt; b\\\\ 0 &amp; \\text{otherwise} \\end{cases}\\) \\(F_X(x) = \\begin{cases} 0 &amp; x \\leq a \\\\ \\frac{x-a}{b-a} &amp; a &lt; x &lt; b \\\\ 1 &amp; x \\geq b \\end{cases}\\) Exponential \\(X \\sim Exp(\\lambda)\\) \\(f_X(x) = \\begin{cases} \\lambda \\exp(-\\lambda x) &amp; x&gt;0 \\\\ 0 &amp; otherwise \\end{cases}\\) \\(F_X(x) = \\begin{cases} 0 &amp; x \\leq 0 \\\\ 1 - \\exp(-\\lambda x) &amp; x &gt;0 \\end{cases}\\) Normal \\(X \\sim Normal(\\mu , \\sigma^2)\\) \\(F_X(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp(- \\frac{(x - \\mu)^2}{2 \\sigma^2})\\) \\(F_X(x) = \\int^{x}_{- \\infty} f_X(u)du\\)"},{"location":"STATS2/WEEK%205/AQ%20Solutions/","title":"Assignment Question Solutions","text":"<p>Warning</p> <ul> <li>Please try to solve the questions on your own first.</li> <li>Thinking that \"I have seen the solutions , I understand everything\" is WRONG. You actually don't understand anything unless you solve questions.</li> <li>For detailed explanations look for posts on discourse or scroll through live lectures.</li> </ul>"},{"location":"STATS2/WEEK%205/AQ%20Solutions/#aq-51","title":"AQ 5.1","text":""},{"location":"STATS2/WEEK%205/AQ%20Solutions/#aq-52","title":"AQ 5.2","text":""},{"location":"STATS2/WEEK%205/AQ%20Solutions/#aq-54","title":"AQ 5.4","text":""},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/","title":"Functions of Continuous Random Variables","text":""},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#_1","title":"Functions of Continuous Random Variables","text":""},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#functions-of-continuous-random-variables","title":"Functions of Continuous Random Variables","text":"<p>Why do we need functions of continuous random variables?</p> <p>We may model one quantity as a random variable \\(X\\). We may have to work with  another closely related quantity.</p> <p>Example</p> <p>Length of a square = \\(X\\)</p> <p>Area of a square = \\(Y = g(X) = X^2\\)</p>"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#cumulative-distribution-function-of-gx","title":"Cumulative Distribution Function of g(X)","text":"<p>If \\(X\\) is a continuous random variable and \\(Y=g(X)\\) is a function of \\(X\\) , then \\(Y\\) itself is  a random variable. Thus we should be able to find the CDF and PDF of \\(Y\\).</p> Relationship between PDF and CDF of a Random Variable <p>CDF \\(\\overset{\\text{differentiation}}{\\underset{\\text{integration}}{\\rightleftarrows}}\\) PDF</p> <ul> <li>Suppose \\(X\\) is a continuous random variable with CDF \\(F_X\\) and PDF \\(f_X\\)</li> <li>Suppose \\(g : \\mathbb{R} \\to \\mathbb{R}\\) is a function.</li> <li>Then , \\(Y = g(X)\\) is a random variable with CDF \\(F_Y\\) determined as follows.</li> </ul> \\[ F_Y(y) = P(Y \\leq y) = P(g(X) \\leq y) = P(X \\in \\{x:g(x) \\leq y\\}) \\]"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#monotonic-differentiable-functions","title":"Monotonic , differentiable functions","text":"<p>Suppose \\(X\\) is continuous random variable with PDF \\(f_X\\). Let g(x) be monotonic for \\(x \\in supp(x)\\) with derivative \\(g'(x) = \\frac{dg(x)}{dx}\\). </p> <p>Then, the PDF of \\(Y = g(X)\\) is </p> \\[ f_Y(y) = \\frac{1}{|g'(g^{-1}(y))|}f_X(g^{-1}(y)) \\]"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#translation","title":"Translation","text":"<p>\\(Y = X + a\\)</p> \\[ f_Y(y) = f_X(y-a) \\]"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#scaling","title":"Scaling","text":"<p>\\(Y = aX\\)</p> \\[ f_Y(y) = \\frac{1}{|a|}f_X(\\frac{y}{a}) \\]"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#affine","title":"Affine","text":"<p>\\(Y = aX + b\\)</p> \\[ f_Y(y) = \\frac{1}{|a|}f_X(\\frac{y-b}{a}) \\]"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#affine-transformation-of-normal-distributions","title":"Affine transformation of normal distributions","text":"<ul> <li>Given \\(X \\sim Normal(0,1)\\)</li> </ul> \\[ f_X(x) = \\frac{1}{\\sqrt{2 \\pi}}\\exp(\\frac{-x^2}{2}) \\] <ul> <li>If \\(Y = \\sigma X + \\mu\\)</li> </ul> \\[ f_Y(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}\\exp(\\frac{-(y - \\mu)^2}{2 \\sigma^2}) \\] \\[\\implies Y \\sim Normal(\\mu , \\sigma^2)\\] <ul> <li>\\(X \\sim Normal(\\mu , \\sigma^2)\\)</li> </ul> \\[ Y = \\frac{X - \\mu}{\\sigma} \\sim Normal(0,1) \\]"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#expectation","title":"Expectation","text":"<p>Let \\(X\\) be a continuous random variable with density \\(f(x)\\). </p> \\[E[X] = \\int^{\\infty}_{- \\infty} x \\times f_X(x)dx\\] <p>Also ,</p> \\[E[X^2] = \\int^{\\infty}_{- \\infty} x^2 \\times f_X(x)dx\\] <p>Let \\(g : \\mathbb{R} \\to \\mathbb{R}\\) be a function. The expected value of \\(g(X)\\), denoted \\(E[g(X)]\\) is given by </p> \\[ E[g(X)] = \\int^{\\infty}_{ - \\infty} g(X)f_X(x)dx \\] <p>whenever the above integrals exists.</p> <p>What is the formula for Variance?</p> <p>The formula for variance remains the same</p> \\[\\text{Var}(X) = E[X^2] - (E[X])^2\\]"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#formulas","title":"Formulas","text":"Distribution PDF CDF Expectation Variance Uniform \\(X \\sim Uniform[a,b]\\) \\(f_X(x) = \\begin{cases} \\frac{1}{b-a} &amp; a &lt; x &lt; b\\\\ 0 &amp; \\text{otherwise} \\end{cases}\\) \\(F_X(x) = \\begin{cases} 0 &amp; x \\leq a \\\\ \\frac{x-a}{b-a} &amp; a &lt; x &lt; b \\\\ 1 &amp; x \\geq b \\end{cases}\\) \\(E[X] = \\frac{a+b}{2}\\) \\(\\sigma^2 = \\frac{(b-a)^2}{2}\\) Exponential \\(X \\sim Exp(\\lambda)\\) \\(f_X(x) = \\begin{cases} \\lambda \\exp(-\\lambda x) &amp; x&gt;0 \\\\ 0 &amp; otherwise \\end{cases}\\) \\(F_X(x) = \\begin{cases} 0 &amp; x \\leq 0 \\\\ 1 - \\exp(-\\lambda x) &amp; x &gt;0 \\end{cases}\\) \\(E[X] = \\frac{1}{\\lambda}\\) \\(\\sigma^2 = \\frac{1}{\\lambda^2}\\) Normal \\(X \\sim Normal(\\mu , \\sigma^2)\\) \\(F_X(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp(- \\frac{(x - \\mu)^2}{2 \\sigma^2})\\) \\(F_X(x) = \\int^{x}_{- \\infty} f_X(u)du\\) \\(E[X] = \\mu\\) \\(\\sigma^2\\)"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#joint-distributions-of-discrete-and-continuous-random-variables","title":"Joint Distributions of Discrete and Continuous Random Variables","text":"<p>Joint distributions involve the simultaneous analysis of two or more random variables.  When one of these random variables is discrete, and the other is continuous,  we have a joint distribution of a discrete and continuous random variable.</p> <p>Example</p> <p>Suppose \\(X\\) represents the number of defective items in a batch (a discrete random variable),  and \\(Y\\) represents the time it takes to produce the batch (a continuous random variable).  The joint distribution would provide the probability of different combinations, such as P(X = 2, 1 \u2264 Y \u2264 2), which is the probability of having exactly 2 defective items when the production time is between 1 and 2 hours.</p>"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#joint-probability-of-continuous-given-discrete","title":"Joint Probability of Continuous Given Discrete","text":"<p>Let \\(X\\) and \\(Y\\) be two random variables with \\(X\\) being a discrete random variable and \\(Y\\) being a continous random variable.</p> <ul> <li>\\(X\\) has the range \\(T_X\\) and PMF \\(p_X(x)\\)</li> <li>For each \\(X \\in T_X\\) , we have continous random variable \\(Y_X\\) with density \\(f_{Y_X}(y)\\) where, \\(Y_X\\) is \\(Y\\) given \\(X=x\\) , denoted as \\((Y|X=x)\\).</li> <li>\\(f_{Y_X}(y)\\) conditional density of \\(Y\\) given \\(X=x\\) can be denoted as \\(f_{Y|X=x}(y)\\)</li> </ul> <p>\\(\\therefore\\) Marginal density of \\(Y\\) will be,</p> \\[ f_Y(y) = \\sum_{x \\in T_X} p_X(x)f_{Y|X=x}(y) \\]"},{"location":"STATS2/WEEK%205/Functions%20of%20Continuous%20Random%20Variables/#joint-probability-of-discrete-given-continuous","title":"Joint Probability of Discrete Given Continuous","text":"<p>Suppose \\(X\\) and \\(Y\\) are jointly distributed with \\(X \\in T_X\\) being discrete with PMF  \\(p_X(x)\\) and conditional densities \\(f_{Y|X=x}(y)\\) for \\(x \\in T_X\\). The conditional  probability of \\(X\\) given \\(Y =y_0 \\in \\text{supp}(Y)\\)  is defined as </p> \\[ P(X=x|Y=y_0) = \\frac{p_X(x)f_{Y|X=x}(y_0)}{f_Y(y_0)} \\] <p>where \\(f_Y\\) is the marginal density of \\(Y\\).</p>"},{"location":"STATS2/WEEK%206/AQ%20Solutions/","title":"Assignment Question Solutions","text":"<p>Warning</p> <ul> <li>Please try to solve the questions on your own first.</li> <li>Thinking that \"I have seen the solutions , I understand everything\" is WRONG. You actually don't understand anything unless you solve questions.</li> <li>For detailed explanations look for posts on discourse or scroll through live lectures.</li> </ul>"},{"location":"STATS2/WEEK%206/AQ%20Solutions/#aq-61","title":"AQ 6.1","text":""},{"location":"STATS2/WEEK%206/AQ%20Solutions/#aq-62","title":"AQ 6.2","text":""},{"location":"STATS2/WEEK%206/AQ%20Solutions/#aq-63","title":"AQ 6.3","text":""},{"location":"STATS2/WEEK%206/AQ%20Solutions/#aq-64","title":"AQ 6.4","text":""},{"location":"STATS2/WEEK%206/Joint%20Continuous%20Random%20Variables/","title":"Joint Continuous Random Variables","text":"<p>A continuous random variable can take on an uncountable number of values within a certain range.</p> <p>Example</p> <p>Examples include height, weight, time, temperature,  and any measurement that can take on a wide range of real numbers.</p> <p>Joint Continuous random variables deal with the simultaneous behavior of two or more continuous random variables.</p> <p>Example</p> <p>Consider two continuous random variables, \\(X\\) and \\(Y\\).  \\(X\\) represents the time it takes for a customer to arrive at a store, and \\(Y\\) represents the amount of money the customer spends during their visit.  Both \\(X\\) and \\(Y\\) can take on a wide range of real-number values.</p>"},{"location":"STATS2/WEEK%206/Joint%20Continuous%20Random%20Variables/#joint-probability-density-function-pdf","title":"Joint Probability Density Function (PDF)","text":"<ul> <li> <p>When dealing with two continuous random variables, \\(X\\) and \\(Y\\), the joint PDF \\(f_{XY}(x,y)\\)  defines the probability density for every pair of values \\((x,y)\\) that \\(X\\) and \\(Y\\) can take  simultaneously.</p> </li> <li> <p>This function represents how likely it is for \\(X\\) and \\(Y\\) to jointly fall within a  specific region in their respective value spaces.</p> </li> <li> <p>The integral of this joint PDF over a region of the XY plane gives the probability that (X, Y) falls within that region.</p> </li> </ul> <p>Properties of PDF</p> <p>A function \\(f(x,y)\\) is said to be a joint density function if </p> <ul> <li>\\(f(x,y) \\geq 0\\) , i.e. \\(f\\) is non-negative</li> <li>\\(\\int \\int^{\\infty}_{ - \\infty} f(x,y)dxdy = 1\\)</li> <li>\\(f(x,y)\\) is piecewise continuous in each random variable.</li> </ul> What does Piecewise Continuous mean? <p>\"Piecewise continuous\" is a term used to describe a function that is continuous except for a finite number of isolated points or intervals where it may have discontinuities. In other words, a piecewise continuous function can be thought of as a function that is continuous over certain subintervals of its domain but may have jumps or discontinuities at specific points or subintervals.</p> <p>Example</p> <p>Let \\(X\\) and \\(Y\\) have joint density </p> \\[ f_{XY} = \\begin{cases} 1 &amp; 0 &lt; x &lt; 1 , 0 &lt; y &lt; 1 \\\\ 0 &amp; otherwise \\end{cases} \\] <p>This specific example is also known as uniform unit square.</p> <p>In the context of the arrival time and spending example, the joint PDF  \\(f_{XY}(x,y)\\) might represent the probability density of a customer arriving at time  \\(x\\) and spending \\(y\\) dollars. It provides the likelihood of simultaneous occurrences of these two events.</p>"},{"location":"STATS2/WEEK%206/Joint%20Continuous%20Random%20Variables/#2d-uniform-distribution","title":"2D Uniform Distribution","text":"<p>For some (reasonable) region \\(D\\) in \\(\\mathbb{R}^2\\) with total area \\(|D|\\). </p> <p>We say that \\((X,Y) \\sim D\\) if they have the joint density</p> \\[ f_{XY} = \\begin{cases} \\frac{1}{|D|} &amp; (x,y) \\in D \\\\ 0 &amp; otherwise \\end{cases} \\] <p>For any sub region \\(A\\) of \\(D\\) , \\(P((X,Y) \\in A) = \\frac{|A|}{|D|} = \\frac{\\text{Area of A}}{\\text{Area of D}}\\)</p>"},{"location":"STATS2/WEEK%206/Joint%20Continuous%20Random%20Variables/#marginal-density","title":"Marginal Density","text":"<ul> <li> <p>Just as with single random variables, you can find the marginal PDFs for X and Y from the joint PDF.</p> </li> <li> <p>The marginal PDF for \\(X\\) , denoted as \\(f_X(x)\\) , is obtained by integrating  the joint PDF \\(f_{XY}(x,y)\\) with respect to \\(Y\\) over the entire range of \\(Y\\) values.</p> </li> <li> <p>Similarly , the marginal PDF for \\(Y\\) , denoted as \\(f_Y(y)\\) , is obtained by integrating  the joint PDF \\(f_{XY}(x,y)\\) with respect to \\(X\\) over the entire range of \\(X\\) values.</p> </li> </ul> <p>Suppose \\((X,Y)\\) have joint density \\(f_{XY}(x,y).\\) Then,</p> <ul> <li>\\(X\\) has the marginal density \\(f_X(x)\\) = \\(\\int^{\\infty}_{y = - \\infty} f_{XY}(x,y)dy\\)</li> <li>\\(Y\\) has the marginal density \\(f_Y(y)\\) = \\(\\int^{\\infty}_{x = - \\infty} f_{XY}(x,y)dy\\)</li> </ul> <p>Example</p> <p>From the joint PDF \\(f_{XY}(x,y)\\) , you can find the marginal PDF for \\(X\\) (\\(f_X(x)\\)) and  \\(Y\\) (\\(f_Y(y)\\)) separately. \\(f_X(x)\\) would represent the distribution of arrival times , and  \\(f_Y(y)\\) would represent the distribution of spending amounts </p>"},{"location":"STATS2/WEEK%206/Joint%20Continuous%20Random%20Variables/#independence-of-random-variables","title":"Independence of Random Variables","text":"<p>Independence means that the behavior of one random variable does not influence the behavior of the other.</p> <p>\\((X,Y)\\) with joint density \\(f_{XY}(x,y)\\) are independent if </p> \\[ f_{XY}(x,y) = f_X(x)f_Y(y) \\] <p>where \\(f_X(x)\\) and \\(f_Y(y)\\) are marginal densities of \\(X\\) and \\(Y\\) respectively.</p> <p>Example</p> <p>Suppose \\(X\\) represents the temperature in one city,  and \\(Y\\) represents the temperature in another city. If these cities are far apart and have independent weather patterns, then \\(X\\) and \\(Y\\) may be considered independent.\u00a0</p>"},{"location":"STATS2/WEEK%206/Joint%20Continuous%20Random%20Variables/#conditional-density","title":"Conditional Density","text":"<p>Conditional Density describe the probability of one random variable given the other.</p> <p>Let \\((X,Y)\\) be random variables with joint density \\(f_{XY}(x,y)\\). Let \\(f_X(x)\\) and \\(f_Y(y)\\) be the marginal  densities.</p> <ul> <li>For \\(a\\) such that \\(f_X(a) &gt; 0\\) , the conditional density of \\(Y\\) given \\(X=a\\) ,  denoted \\(f_{Y|X=a}(y)\\) , is defined as </li> </ul> \\[ f_{Y|X=a} = \\frac{f_{XY}(a,y)}{f_X(a)} \\] <ul> <li>For \\(b\\) such that \\(f_Y(b) &gt; 0\\) , the conditional density of \\(X\\) given \\(Y=b\\) , denoted \\(f_{X|Y=b}(x)\\) , is defined as </li> </ul> \\[ f_{X|Y=b}(x) = \\frac{f_{XY}(x,b)}{f_Y(b)} \\] <p>Properties of Conditional Density</p> <ul> <li> <p>Both the conditional densities are valid densities in one dimension. So , the \"conditional\" random variables \\((Y|X=a)\\) and \\((X|Y=b)\\) are well defined.</p> </li> <li> <p>\\(\\text{Joint} = \\text{Marginal} \\times \\text{Conditional}\\) , for \\(x=a\\) and \\(y=b\\) such that  \\(f_X(a) &gt; 0\\) and \\(f_Y(b) &gt; 0\\) </p> </li> </ul> \\[ f_{XY}(a,b) = f_X(a)f_{Y|X=a}(b) = f_Y(b)f_{X|Y=b}(a) \\] <p>Example</p> <p>Continuing with the temperature example, you might want to find \\(f_{X|Y}(x|y)\\), which would represent the PDF of temperature in one city  given a specific temperature in the other city. This could help predict temperature changes in one city based  on the observed temperature in the other city.</p>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/","title":"Empirical Distribution and Descriptive Statistics","text":"<p>Let \\(X_1 , X_2 , X_3 .... , X_n \\sim X\\) be iid samples. Let \\(\\#(X_i = t)\\) denote the number  of times \\(t\\) occurs in the samples. The emperical distribution is the discrete distribution with PMF </p> \\[ p(t) = \\frac{\\#(X_i = t)}{n} \\] Is the empirical distribution random? <ul> <li>Yes , it depends on the actual sample instances </li> <li>\\(t\\) and \\(p(t)\\) may change from one sampling to another.</li> <li>Example : 20 \\(\\text{Bernoulli}(p)\\) samples.</li> </ul> <p>Properties of Empirical Distribution</p> <ul> <li>Mean (\\(\\mu\\)) of the distribution.</li> <li>Variance (\\(\\sigma^2\\)) of the distribution.</li> <li>Probability of an event</li> </ul> <p>Note</p> <p>As number of samples increases , the properties of the  emperical distribution should become close to that of the original distribution.</p>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#sample-mean","title":"Sample Mean","text":"<p>Let \\(X_1 , X_2 , ...... X_n\\) be iid samples. The sample mean , denoted \\(\\overline{X}\\) , is defined to be the random variable.</p> \\[\\overline{X} = \\frac{X_1 + X_2 + X_3 + ...... + X_n}{n}\\] <p>Expected Value and Variance</p> \\[E[\\overline{X}] = \\mu , \\text{Var}(\\overline{X}) = \\frac{\\sigma ^2}{n}\\] Properties <p>Expected value of a sample means equals the expected value of mean of distribution </p> <ul> <li>Mean of Distribution: constant real number and not random </li> <li>Sample Mean: random variable with mean equal to distribution mean </li> </ul> <p>Variance of sample mean decreases with \\(n\\) </p> <p>As \\(n\\) increases :-</p> <ul> <li>Variance of sample mean tends to zero </li> <li>The spread of sample mean will decrease </li> <li>Sample mean will take values close the distribution mean</li> </ul>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#sample-variance","title":"Sample Variance","text":"<p>Let \\(X_1 , X_2 , ...... X_n\\) be iid samples. The sample variance, denoted \\(S^2\\) , is defined to be the random variable.</p> \\[S^2 = \\frac{(X_1 - \\overline{X})^2 + (X_2 - \\overline{X})^2 + .... + (X_n - \\overline{X})^2}{n-1}\\] <p>where \\(\\overline{X}\\) is the sample mean.</p> <p>Expected Value of Sample Variance</p> <p>Let \\(X_1 , X_2 , ...... X_n\\) be iid samples whose distribution has a finite variance \\(\\sigma^2\\).  The sample variance \\(S^2\\) has expected value given by </p> \\[E[S^2]=\\sigma^2\\] Properties <p>Expected value of sample variane equals the variance of the distribution </p> <ul> <li>Variance of distribution: constant real number and not random </li> <li>Sample Variance: random variable with mean equal to distribution variance </li> </ul> <p>Values of sample variance , on average , give the variance of the distribution </p> <ul> <li>Variance of sample variance will decrease with the number of samples (generally)</li> <li>As \\(n\\) increases , sample variance takes values close the distribution variance </li> </ul>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#sample-proportion","title":"Sample Proportion","text":"<p>The sample proportion of \\(A\\) , denoted \\(S(A)\\) , is defined as</p> \\[S(A) = \\frac{\\# (X_i \\text{ for which A is true})}{n}\\] <p>Expectation and Variance of Sample Proportion</p> <p>Let \\(X_1 , X_2 , ...... X_n\\) be iid samples whose distribution of \\(X\\). Let \\(A\\) be an event defined using \\(X\\) and let \\(P(A)\\) be the probability of \\(A\\). The sample proportion of \\(A\\) , denoted \\(S(A)\\) ,  has expected value and variance given by</p> \\[E[S(A)] = P(A) , Var(S(A)) = \\frac{P(A)(1 - P(A))}{n}\\] <p>As \\(n\\) increases , values of S(A) will be close to P(A).</p>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#sum-of-independent-random-variables","title":"Sum of Independent Random Variables","text":"<p>Let \\(X_1 , X_2 , ...... X_n\\) be random variables. Let \\(S = X_1 + X_2 +..... + X_n\\) be their sum. Then,</p> \\[E[S] = E[X_1] + E[X_2]+ ..... E[X_n]\\] <p>If \\(X_1 , X_2 ... X_n\\) are pairwise uncorrelated, then</p> \\[Var(S) = Var(X_1) + Var(X_2) + .... Var(X_n)\\] What is Pairwaise Uncorrelated \\[E[X_i X_j] = E[X_i] E[X_j]\\] <p>for all \\(i,j\\) where \\(i \\neq j\\)</p>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#weak-law-of-large-numbers","title":"Weak Law of Large Numbers","text":"\\[X_1 , X_2 ......X_n \\sim \\text{iid }X\\] <p>Let \\(\\mu = E[X]\\) , \\(\\sigma^2 = Var(X)\\)</p> <p>Sample Mean: \\(\\overline{X} =\\frac{X_1 + X_2 + ... X_n}{n}\\)</p> <p>Expected value : \\(\\mu\\) , Variance : \\(\\frac{\\sigma^2}{n}\\)</p>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#weak-law","title":"Weak Law","text":"\\[P(|\\overline{X} - \\mu|&gt; \\delta) \\leq \\frac{\\sigma^2}{n \\delta^2}\\] <p>Note</p> <ul> <li> <p>With Probability more than \\(1 - \\frac{\\sigma^2}{n \\delta^2}\\) lies in \\([\\mu - \\delta , \\mu + \\delta]\\)</p> </li> <li> <p>\\(\\delta &gt; \\frac{\\sigma}{\\sqrt{n}}\\)</p> </li> </ul>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#bernoulli","title":"Bernoulli","text":"<p>For Bernoulli(p) samples </p> \\[1 - \\frac{p(1-p)}{n\\delta^2}\\] <p>sample mean lies in  \\([p - \\delta , p + \\delta]\\)</p>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#discrete-uniform","title":"Discrete Uniform","text":"<p>For \\(\\text{Uniform}\\{-M, .... M\\}\\) samples</p> \\[1 - \\frac{M(M+1)}{3n\\delta^2}\\] <p>sample mean lies in \\([-\\delta , \\delta]\\)</p>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#normal","title":"Normal","text":"<p>For \\(\\text{Normal}(0 , \\sigma^2)\\) </p> \\[1 - \\frac{\\sigma^2}{n\\delta^2}\\] <p>sample mean lies in \\([-\\delta , \\delta]\\)</p>"},{"location":"STATS2/WEEK%207/Empirical%20Distribution%20and%20Descriptive%20Statistics/#continuous-uniform","title":"Continuous Uniform","text":"<p>For \\(\\text{Uniform}[-A , A]\\) samples </p> \\[1 - \\frac{A^2}{3n\\delta^2}\\] <p>sample mean lies in \\([-\\delta , \\delta]\\)</p>"},{"location":"STATS2/WEEK%208/AQ%20Solutions/","title":"Assignment Question Solutions","text":"<p>Warning</p> <ul> <li>Please try to solve the questions on your own first.</li> <li>Thinking that \"I have seen the solutions , I understand everything\" is WRONG. You actually don't understand anything unless you solve questions.</li> <li>For detailed explanations look for posts on discourse or scroll through live lectures.</li> </ul>"},{"location":"STATS2/WEEK%208/AQ%20Solutions/#aq-81","title":"AQ 8.1","text":""},{"location":"STATS2/WEEK%208/AQ%20Solutions/#aq-82","title":"AQ 8.2","text":""},{"location":"STATS2/WEEK%208/AQ%20Solutions/#aq-84","title":"AQ 8.4","text":""},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/","title":"Central Limit Theorem","text":""},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#moment-generating-functions","title":"Moment Generating Functions","text":"<p>Let \\(X\\) be a zero-mean random variable.  The MGF of \\(X\\) , denoted \\(M_X(\\lambda)\\),  is a function from \\(\\mathbb{R} \\to \\mathbb{R}\\) defined as </p> \\[M_X(\\lambda) = E[e^{\\lambda X}]\\] <p>Note</p> <ul> <li>When \\(X\\) is Discrete with PMF \\(f_X\\)</li> </ul> <p>X takes the values \\(\\{x_1 , x_2 , x_3 ....\\}\\)</p> \\[M_X(\\lambda) = f_X(x_1)e^{\\lambda x_1} + f_X(x_2)e^{\\lambda x_2} + ....\\] <ul> <li>When \\(X\\) is continuous with PDF \\(f_X\\) and support \\(T_X\\)</li> </ul> \\[M_{(\\lambda)} = \\int^{}_{x \\in T_X} f_X(x) e^{\\lambda x} dx\\] <p>Example</p> <p>\\(\\mathbf{X \\in \\{\\overset{1/2}{-1} , \\overset{1/4}{0} , \\overset{1/4}{2}\\}}\\)</p> \\[M_X(\\lambda) = 0.5e^{-\\lambda} + 0.25 + 0.25 e^{2 \\lambda}\\] <p>\\(\\newline\\)</p> <p>\\(\\mathbf{M_X(\\lambda) = (1/3)e^{3 \\lambda / 2} + (1/6)e^{-3\\lambda} + (1/8)e^{-\\lambda} + (1/8)e^{\\lambda} + 1/4}\\)</p> \\[X \\sim \\{\\overset{1/6}{-3} , \\overset{1/8}{-1} , \\overset{1/4}{0} , \\overset{1/8}{1} , \\overset{1/3}{3/2}\\}\\] <p>Note</p> <p>\\(\\mathbf{X \\sim Normal(0 , \\sigma^2)}\\)</p> \\[M_X(\\lambda) = e^{\\lambda^2 \\sigma^2 / 2}\\]"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#expectation-of-mgf","title":"Expectation Of MGF","text":"<p>\\(E[e^{\\lambda X}] = E[1 + \\lambda X + \\frac{\\lambda^2}{2!}X^2 + \\frac{\\lambda ^3}{3!}X^3 + ....]\\)</p> <p>\\(\\implies 1 + \\lambda E[X] + \\frac{\\lambda^2}{2!}E[X^2] + \\frac{\\lambda^3}{3!} E[X^3]\\)</p> <ul> <li>If \\(\\mathbf{X \\sim \\text{Normal}(0,\\sigma^2) , M_X(\\lambda) = e^{\\lambda^2 \\sigma^2 / 2}}\\) \\(1 + E[X] + \\frac{\\lambda^2}{2!}E[X^2] + \\frac{\\lambda ^3}{3!}E[X^3]\\) \\(\\implies 1 + \\frac{\\lambda^2}{2!}\\sigma^2 + \\frac{\\lambda^4}{4!}3\\sigma^4\\)</li> </ul> <p>\\(\\implies E[X]=0 , E[X^2] = \\sigma^2 , E[X^3] = 0 , E[X^4] = 3\\sigma^4 ...\\)</p>"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#mgf-of-sample-mean","title":"MGF of Sample Mean","text":"<p>Let \\(X_1 , X_2 .... X_n \\sim \\text{iid }X , M_X(\\lambda) = \\frac{e^{\\lambda/2} + e^{-\\lambda/2}}{2}\\)</p> <ul> <li>Sample Mean : \\(\\overline{X} = (X_1 + X_2 + ... X_n) / n\\)</li> <li>\\(M_{X/n}(\\lambda) = \\frac{e^{\\lambda / 2n} + e^{-\\lambda / 2n}}{2}\\)</li> </ul> \\[M_{\\overline{X}}(\\lambda) = {\\left(\\frac{e^{\\frac{\\lambda}{2n}} + e^{\\frac{\\lambda}{2n}}}{2}\\right)}^n\\]"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#mgf-convergence-at-mathbf1-sqrtn-scaling","title":"MGF convergence at  \\(\\mathbf{1 / \\sqrt{n}}\\) scaling","text":"<p>Let \\(X_1 , X_2 .... X_n \\sim \\text{iid }X , M_X(\\lambda) = \\frac{e^{\\lambda/2} + e^{-\\lambda/2}}{2}\\)</p> <p>\\(E[X]=0 , Var(X) = 1/4\\)</p> <p>Consider \\(Y = (X_1 + X_2 ... + X_n) /  \\sqrt{n}\\)</p> <p>\\(M_{X/\\sqrt{n}}(\\lambda) = \\frac{e^{\\lambda / 2\\sqrt{n}} + e^{-\\lambda / 2\\sqrt{n}}}{2}\\)</p> \\[M_Y(\\lambda) = M_{\\overline{X}}(\\lambda) = {\\left(\\frac{e^{\\frac{\\lambda}{2\\sqrt{n}}} + e^{\\frac{\\lambda}{2\\sqrt{n}}}}{2}\\right)}^n\\]"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#using-clt-to-approximate-probability","title":"Using CLT to approximate probability","text":"\\[X_1 , X_2 , .... X_n \\sim \\overset{iid}{X}\\] <p>Let \\(\\mu = E[X] , \\sigma^2 = Var(X)\\)</p> <p>\\(Y = X_1 + X_2 + .... X_n\\)</p> <p>What is \\(P(Y - n\\mu &gt; \\delta n \\mu)\\) ? </p> \\[Z = \\frac{Y - n\\mu}{\\sqrt{n} \\sigma} \\approx \\text{Normal}(0,1)\\] <p>\\(P(Y-n \\mu &gt; \\delta n \\mu) = P(\\frac{Y - n \\mu}{\\sqrt{n} \\sigma} &gt; \\frac{\\delta \\sqrt{n} \\mu}{\\sigma}) \\approx 1 - F(\\frac{\\delta \\sqrt{n} \\mu}{\\sigma})\\)</p> <p>\\(\\begin{align*} F_{Z}(0.2617) = 0.603, F_{Z}(1.6) = 0.9452, F_{Z}(1.5) = 0.933 \\end{align*}\\)</p>"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#types-of-distributions","title":"Types of Distributions","text":""},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#combination-of-independent-normals","title":"Combination of Independent Normals","text":"<p>Let \\(X_1 , X_2 ... X_n \\sim \\text{independent Normal}\\)</p> <p>Let \\(X_i \\sim \\text{Normal}(\\mu_i ,\\sigma_{i}^{2})\\)</p> <p>Suppose \\(Y = a_1X_1 + a_2X_2 + a_nX_n\\) be a linear combination of independent normals. </p> <p>Then,</p> \\[Y \\sim \\text{Normal}(\\mu , \\sigma^2)\\] <p>where \\(\\mu = E[Y] = a_1\\mu_1 + a_2\\mu_2 + ... + a_n\\mu_n\\)</p> <p>\\(\\sigma^2 = a_{1}^{2}\\sigma_{1}^{2} + a_{2}^{2}\\sigma_{2}^{2} + .... a_{n}^{2}\\sigma_{n}^{2}\\)</p> <p>Therefore Linear combinations of independent normals is normal distribution.</p>"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#gamma-distribution","title":"Gamma Distribution","text":"<p>\\(X \\sim \\text{Gamma}(\\alpha , \\beta)\\) if PDF \\(f_X(s) \\propto x^{\\alpha -1} e^{-\\beta x} , x&gt;0\\)</p> <p>Points to be noted</p> <ul> <li>\\(\\alpha &gt; 0\\) and \\(\\alpha\\) is called the shape parameter</li> <li>\\(\\beta &gt; 0\\) and \\(\\beta\\) is called the rate parameter</li> <li>\\(\\theta = 1/ \\beta\\) and \\(\\theta\\) is called the scale parameter.</li> <li>Sum of n iid \\(\\text{Exp}(\\beta)\\) is \\(\\text{Gamma}(n, \\beta)\\)</li> <li>Square of \\(\\text{Normal}(0 , \\sigma^2)\\) is \\(\\text{Gamma}(\\frac{1}{2} , \\frac{1}{2 \\sigma^2})\\)</li> </ul> <p>Mean: \\(\\mathbf{\\frac{\\alpha}{\\beta}}\\) , Variance: \\(\\mathbf{\\frac{\\mathbf{\\alpha}}{\\beta^2}}\\) </p>"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#cauchy-distribution","title":"Cauchy Distribution","text":"<p>\\(X \\sim \\text{Cauchy}(0, \\alpha^2)\\) if PDF \\(f_X(x) = \\frac{1}{\\pi} \\frac{\\alpha}{\\alpha^2 + (x - \\theta)^2}\\)</p> <p>Note</p> <ul> <li>\\(\\theta\\) is the location parameter</li> <li>\\(\\alpha &gt; 0\\) and \\(\\alpha\\) is called the scale parameter </li> <li>Suppose \\(X , Y \\sim \\text{iid} Normal(0,\\sigma^2)\\). Then,</li> </ul> \\[\\frac{X}{Y} \\sim \\text{Cauchy}(0,1)\\] <p>Mean : undefined , Variance : undefined </p>"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#beta-distribution","title":"Beta Distribution","text":"<p>\\(X \\sim \\text{Beta}(\\alpha , \\beta)\\) if PDF \\(f_X(x) \\propto x^{\\alpha -1}(1- x)^{\\beta -1} , 0 &lt; x &lt; 1\\)</p> <p>Note</p> <ul> <li>\\(\\alpha &gt; 0 , \\beta &gt; 0\\) and both of them are the shape parameters</li> <li>\\(\\text{Beta}(\\alpha ,1)\\) has PDF \\(\\propto x^{\\alpha -1}\\) which is called the power function distribution </li> <li>Suppose \\(X \\sim \\text{Gamma}(\\alpha , 1 / \\theta), Y \\sim \\text{Gamma}(\\beta , 1/\\theta)\\) , then </li> </ul> \\[\\frac{X}{X + Y} \\sim \\text{Beta}(\\alpha , \\beta)\\]"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#plotted-distributions","title":"Plotted Distributions","text":""},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#sample-mean-distribution","title":"Sample Mean Distribution","text":"<p>\\(X_1 , X_2 , .... X_n \\sim \\text{iid Normal}(\\mu , \\sigma^2)\\)</p> <p>\\(\\overline{X} = \\frac{1}{n}X_1 + ... \\frac{1}{n}X_n\\)</p> <p>Sample mean is a linear combination of iid normal random variables </p> \\[\\overline{X} \\sim \\text{Normal}(\\mu , \\sigma^2/n)\\] <p>Mean : \\(E[\\overline{X}] = \\mu\\) , Variance : \\(\\text{Var}(\\overline{X}) = \\sigma^2 /n\\)</p>"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#sum-of-squares-of-normal-samples","title":"Sum of squares of Normal Samples","text":"<p>\\(X_1 , X_2 , .... X_n \\sim \\text{iid Normal}(0 , \\sigma^2)\\)</p> <ul> <li>\\(X_{i}^{2}\\) : \\(\\text{Gamma}(1/2 , 1/2\\sigma^2)\\) , independent</li> <li>Sum of n independent \\(\\text{Gamma}(\\alpha , \\beta)\\) is \\(\\text{Gamma}(n\\alpha , \\beta)\\)</li> </ul> \\[X_{1}^{2} + X_{2}^{2} + X_{3}^{2} + ... + X_{n}^{2} \\sim \\text{Gamma}(\\frac{n}{2} , \\frac{1}{2\\sigma^2})\\]"},{"location":"STATS2/WEEK%208/Central%20Limit%20Theorem/#sample-mean-and-variance-of-normal-samples","title":"Sample Mean and variance of normal samples","text":"<p>Suppose \\(X_1 , X_2 , .... X_n \\sim \\text{iid Normal}(\\mu , \\sigma^2)\\). Then,</p> <ul> <li>\\(\\overline{X} \\sim Normal(\\mu , \\sigma^2 /n)\\)</li> <li>\\(\\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi_{n-1}^{2}\\) , Chi-square with \\(n-1\\) degrees of freedom.</li> <li>\\(\\overline{X}\\text{ and }S^2\\) are independent.</li> </ul>"},{"location":"STATS2/WEEK%209/Parameter%20Estimation/","title":"Parameter Estimation","text":"<ul> <li>It refers to the process of using sample data to make inferences  or estimates about one or more unknown parameters  that characterize a statistical population or probability distribution.</li> <li>It is a function defined on the samples taken. </li> </ul>"},{"location":"STATS2/WEEK%209/Parameter%20Estimation/#estimation-error","title":"Estimation Error","text":"<p>Estimation error is the difference between an estimated/predicted  value and the true/actual value in a  statistical or modeling context. It quantifies the accuracy or  precision of an estimation method, reflecting how closely the estimate aligns with the real-world value.</p> <ul> <li>Let \\(\\theta\\) be the parameter and \\(\\hat{\\theta}\\) be the estimator.</li> </ul> <p>Error: \\(\\hat{\\theta}(X_1 , X_2 .... X_n) - \\theta\\) is a random variable.</p>"},{"location":"STATS2/WEEK%209/Parameter%20Estimation/#bias","title":"Bias","text":"<p>Bias refers to the tendency of a statistical estimator  to systematically overestimate or underestimate a population parameter. </p> <ul> <li>Let \\(X_1 , X_2 , .... X_n \\sim \\text{iid } X\\) , parameter \\(\\theta\\),</li> <li>The bias of the estimator \\(\\hat{\\theta}\\) for a parameter \\(\\theta\\) is denoted as </li> </ul> \\[\\text{Bias}(\\hat{\\theta} , \\theta) = \\text{E}(\\hat{\\theta}) - \\theta = \\text{Error}\\] <p>Unbiased Estimator</p> <p>When Bias/Error is 0 , then the estimator \\(\\hat{\\theta}\\) is said to be unbiased estimator.</p>"},{"location":"STATS2/WEEK%209/Parameter%20Estimation/#risk-squared-error","title":"Risk (Squared Error)","text":"<p>Let \\(X_1 , X_2 , .... X_n \\sim \\text{iid } X\\) , parameter \\(\\theta\\)</p> <p>The squared-error or risk of the estimator \\(\\hat{\\theta}\\) for a parameter \\(\\theta\\) is denoted as</p> \\[\\text{Risk}(\\hat{\\theta}, \\theta) = {E[(\\hat{\\theta} - \\theta)^2]}\\] <ul> <li>Since \\(\\text{Error} = \\hat{\\theta} -\\theta\\) , risk is the expected value of squared error and is also called the mean squared error (MSE).</li> <li>Squared-error risk is the second moment of Error </li> </ul>"},{"location":"STATS2/WEEK%209/Parameter%20Estimation/#variance","title":"Variance","text":"<p>Let \\(X_1 , X_2 , .... X_n \\sim \\text{iid} X\\) , parameter \\(\\theta\\)</p> <p>Variance of Estimator:</p> \\[Var(\\hat{\\theta}) = E[(\\hat{\\theta} - E[\\hat{\\theta}])^2]\\] <p>also variance of error is equal to variance of estimator i.e. \\(Var(\\hat{\\theta}) = Var(Error)\\)</p>"},{"location":"STATS2/WEEK%209/Parameter%20Estimation/#bias-variance-tradeoff","title":"Bias Variance Tradeoff","text":"<p>Let \\(X_1 , X_2 , .... X_n \\sim \\text{iid} X\\) , parameter \\(\\theta\\)</p> \\[\\text{Risk}(\\hat{\\theta} , \\theta) = \\text{Bias}(\\hat{\\theta} , \\theta)^2 + Var(\\hat{\\theta})\\] \\[\\text{Risk} = \\text{E}[\\text{Error}]^2 = \\text{Mean}[\\text{Error}]^2 + \\text{Var}[\\text{Error}]\\]"},{"location":"STATS2/WEEK%209/Parameter%20Estimation/#sample-moments","title":"Sample Moments","text":"\\[X_1 , X_2 , ... X_n \\sim \\text{iid} \\ X\\] <p>Sample Moments:</p> \\[M_k(X_1 , X_2 ...., X_n) = \\frac{1}{n}\\sum^{n}_{i=1}X_{i}^{k}\\]"}]}